{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Shakespeare Sonnets with Deep Learning\n",
    "---\n",
    "Creating a character-level language model trained on William Shakespeare's sonnets.\n",
    "\n",
    "## Data Loading & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.12.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(21)\n",
    "\n",
    "print(\"Numpy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our corpus is composed of all of William Shakespeare's sonnets concatenated into a single text file. The sonnets were retrieved from [shakespeares-sonnets.com](http://www.shakespeares-sonnets.com/all.php). There are a total of 154 sonnets in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 94082 characters\n"
     ]
    }
   ],
   "source": [
    "with open('sonnets.txt', 'r') as f:\n",
    "    data = f.read().lower()\n",
    "\n",
    "print(\"Corpus length: %d characters\" % len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sonnet length: 608.94 characters\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10483e438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize sonnet character length\n",
    "sonnets = data.split('\\n\\n')\n",
    "sonnet_lens = [len(sonnet) for sonnet in sonnets]\n",
    "\n",
    "print('Average sonnet length: %.2f characters' % np.mean(sonnet_lens))\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.bar([i for i in range(1, len(sonnets)+1)], sonnet_lens)\n",
    "plt.title('Number of Characters per sonnet')\n",
    "plt.ylabel('# Characters')\n",
    "plt.xlabel('Sonnets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonnet 145 is Shakespeare's shortest sonnet at 506 characters long while sonnet 11 is the longest with 673 characters. Since the average sonnet length is ~608 characters long when we generate characters later we will generate 600 characters to create 1 sonnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "---\n",
    "Now we will set the maximum length a sequence can have, how many characters to skip when we grab a new sample, and create a vector of targets (the next character in the sequence). The `sentences` variable will hold all our training samples where each sample will be 40 characters from the dataset offset by 3 characters from the previous sample. Here is an example where `maxlen` is 40 and `step` is 3:\n",
    "\n",
    "**Sentence 1:**\n",
    "    \n",
    "    'from fairest creatures we desire increas'\n",
    "\n",
    "**Target 1:**\n",
    "\n",
    "    'e'\n",
    "\n",
    "**Sentence 2:**\n",
    "\n",
    "    'm fairest creatures we desire increase,\\n'\n",
    "\n",
    "**Target 2:**\n",
    "\n",
    "    't'\n",
    "    \n",
    "**Sentence 3:**\n",
    "\n",
    "    'airest creatures we desire increase,\\ntha'\n",
    "\n",
    "**Target 3:**\n",
    "\n",
    "    't'\n",
    "    \n",
    "For context here are the first 100 characters in the corpus:\n",
    "    \n",
    "    'from fairest creatures we desire increase,\\nthat thereby beauty's rose might never die,\\nbut as the ri'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 31348\n",
      "Number of unique characters: 38\n"
     ]
    }
   ],
   "source": [
    "# Max length of each sequence\n",
    "maxlen = 40\n",
    "\n",
    "# Sample new sequence every step characters\n",
    "step = 3\n",
    "\n",
    "sentences = []\n",
    "targets = []\n",
    "\n",
    "# Loop through sonnets and create sequences and associated targets\n",
    "for i in range(0, len(data) - maxlen, step):\n",
    "    sentences.append(data[i:i + maxlen])\n",
    "    targets.append(data[maxlen + i])\n",
    "\n",
    "print(\"Number of sequences:\", len(sentences))\n",
    "\n",
    "# Grab all unique characters in corpus\n",
    "chars = sorted(list(set(data)))\n",
    "print(\"Number of unique characters:\", len(chars))\n",
    "\n",
    "# Dictionary mapping unique character to integer indices\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will vectorize our data into a one-hot encoded tensor of shape **(num_sequences, max_sequence_length, num_characters)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training sequences: (31348, 40, 38)\n",
      "Size of training targets: (31348, 38)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize sequences and targets\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for j, char in enumerate(sentence):\n",
    "        x[i, j, char_indices[char]] = 1\n",
    "    y[i, char_indices[targets[i]]] = 1\n",
    "\n",
    "print(\"Size of training sequences:\", x.shape)\n",
    "print(\"Size of training targets:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "---\n",
    "Here we will build and compile the deep learning model using Keras. The model will consist of 1 LSTM layer with a fully connected layer on top. The output has a softmax activation function applied so the output can be represented as a probability for each character in our list of possible characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               85504     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 38)                4902      \n",
      "=================================================================\n",
      "Total params: 90,406\n",
      "Trainable params: 90,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "optimizer = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will output a probability value for each character possible. Instead of choosing the character with the highest probability, we will reweight the probabilities and sample from them based on a \"temperature\" value. The higher the temperature the more likely a random character will be chosen, the lower the temperature the more deterministic the model will behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    ''' Reweight the predicted probabilities and draw sample from newly created probability distribution. '''\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model will be trained on the text and targets. After training for 1 epoch, a random sequence will be chosen from the training corpus and fed into the model. Using this \"seed text\" we will predict the next 600 characters at different temperatures and store them in different text files locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 947us/step - loss: 3.1130\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 2\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 948us/step - loss: 2.9861\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 3\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 972us/step - loss: 2.9697\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 4\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 960us/step - loss: 2.9458\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 5\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 982us/step - loss: 2.9076\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 6\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 956us/step - loss: 2.8379\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 7\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 963us/step - loss: 2.7362\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 8\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 960us/step - loss: 2.6347\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 9\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 29s 939us/step - loss: 2.5525\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 10\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 962us/step - loss: 2.4932\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 11\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 967us/step - loss: 2.4429\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 12\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 959us/step - loss: 2.4023\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 13\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 964us/step - loss: 2.3674\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 14\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 959us/step - loss: 2.3363\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 15\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 959us/step - loss: 2.3089\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 16\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 29s 930us/step - loss: 2.2830\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 17\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 976us/step - loss: 2.2601\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 18\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 947us/step - loss: 2.2388\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 19\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 984us/step - loss: 2.2208\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 20\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 29s 934us/step - loss: 2.1992\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 21\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 944us/step - loss: 2.1825\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 22\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 959us/step - loss: 2.1669\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 23\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 979us/step - loss: 2.1505\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 24\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 966us/step - loss: 2.1328\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 25\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 1ms/step - loss: 2.1125\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 26\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 976us/step - loss: 2.0955\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 27\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 951us/step - loss: 2.0803\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 28\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 951us/step - loss: 2.0755\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 29\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 964us/step - loss: 2.0540\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 30\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 985us/step - loss: 2.0395\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 31\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 958us/step - loss: 2.0289\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 32\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 970us/step - loss: 2.0178\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 33\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 976us/step - loss: 2.0083\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 34\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 969us/step - loss: 1.9940\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 35\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 970us/step - loss: 1.9850\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 36\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 981us/step - loss: 1.9749\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 37\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 29s 939us/step - loss: 1.9655\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 38\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 974us/step - loss: 1.9572\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 39\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 960us/step - loss: 1.9457\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 40\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 958us/step - loss: 1.9388\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 41\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 968us/step - loss: 1.9285\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 42\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 960us/step - loss: 1.9215\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 43\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 1827s 58ms/step - loss: 1.9142\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 44\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 806s 26ms/step - loss: 1.9066\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 45\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 29s 940us/step - loss: 1.8980\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 46\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 946us/step - loss: 1.8909\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 47\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 965us/step - loss: 1.8846\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 48\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 961us/step - loss: 1.8772\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 49\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 956us/step - loss: 1.8699\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 50\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 965us/step - loss: 1.8633\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 51\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 958us/step - loss: 1.8549\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 52\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 31s 978us/step - loss: 1.8497\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 53\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 964us/step - loss: 1.8420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 54\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 963us/step - loss: 1.8354\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 55\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 947us/step - loss: 1.8295\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 56\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 952us/step - loss: 1.8241\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 57\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 947us/step - loss: 1.8179\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 58\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 965us/step - loss: 1.8112\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 59\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 964us/step - loss: 1.8040\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n",
      "Epoch 60\n",
      "Epoch 1/1\n",
      "31348/31348 [==============================] - 30s 959us/step - loss: 1.7983\n",
      "Temp 0.2 done.\n",
      "Temp 0.5 done.\n",
      "Temp 1.0 done.\n",
      "Temp 1.3 done.\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "\n",
    "loss = []  # Custom history list to save model's loss\n",
    "\n",
    "# Create directory to store generated text\n",
    "base_dir = 'generated_text'\n",
    "if not os.path.isdir(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(\"Epoch\", epoch)\n",
    "    # Fit model for 1 epoch then generate text given a seed.\n",
    "    history = model.fit(x, y, batch_size=128, epochs=1)\n",
    "    loss.append(history.history['loss'][0])\n",
    "    \n",
    "    # Create directory to store text for each epoch\n",
    "    epoch_dir = os.path.join(base_dir, 'epoch_' + str(epoch))\n",
    "    if not os.path.isdir(epoch_dir):\n",
    "        os.mkdir(epoch_dir)\n",
    "    \n",
    "    # Select a random seed text to feed into model and generate text\n",
    "    start_idx = np.random.randint(0, len(data) - maxlen - 1)\n",
    "    seed_text = data[start_idx:start_idx + maxlen]\n",
    "    for temp in [0.2, 0.5, 1.0, 1.3]:\n",
    "        generated_text = seed_text\n",
    "        temp_file = 'epoch' + str(epoch) + '_temp' + str(temp) + '.txt'\n",
    "        file = open(os.path.join(epoch_dir, temp_file), 'w')\n",
    "        file.write(generated_text)\n",
    "        \n",
    "        # Predict and generate 600 characters (approx. 1 sonnet length)\n",
    "        for i in range(600):\n",
    "            # Vectorize generated text\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for j, char in enumerate(generated_text):\n",
    "                sampled[0, j, char_indices[char]] = 1.\n",
    "            \n",
    "            # Predict next character\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            pred_idx = sample(preds, temperature=temp)\n",
    "            next_char = chars[pred_idx]\n",
    "            \n",
    "            # Append predicted character to seed text\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            \n",
    "            # Write to text file\n",
    "            file.write(next_char)\n",
    "        print('Temp ' + str(temp) + \" done.\")\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating New Sonnets\n",
    "---\n",
    "Here we will pick a random seed text from the training data and predict 600 (average sonnet length) new characters using our newly trained model. We will also use a temperature of 0.5 because that gives a good balance between randomness and deterministic behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sonnet(temp):\n",
    "    ''' Given a temperature, generate a new sonnet '''\n",
    "    start_idx = np.random.randint(0, len(data) - maxlen - 1)\n",
    "    new_sonnet = data[start_idx:start_idx + maxlen]\n",
    "    sys.stdout.write(new_sonnet)\n",
    "    for i in range(600):\n",
    "        # Vectorize generated text\n",
    "        sampled = np.zeros((1, maxlen, len(chars)))\n",
    "        for j, char in enumerate(new_sonnet):\n",
    "            sampled[0, j, char_indices[char]] = 1.\n",
    "\n",
    "        # Predict next character\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        pred_idx = sample(preds, temperature=temp)\n",
    "        next_char = chars[pred_idx]\n",
    "\n",
    "        # Append predicted character to seed text\n",
    "        new_sonnet += next_char\n",
    "        new_sonnet = new_sonnet[1:]\n",
    "\n",
    "        # Print to console\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " art blamed shall not be thy defect,\n",
      "for the creves and my mast ponge me for dome.\n",
      "the shald so sweet from be the suring thee,\n",
      "when thou thee art thou do the should dose men wher stinger, and stire the conter the creat,\n",
      "the sal to bing ald the with sheed all and,\n",
      "and hace the mine love the sor dear thing,\n",
      "to may thas the ort in thee that heart cheant;\n",
      "the ssorl so seare the of the woul thou shate all thee worth thee fart o thee,\n",
      "for my nes the stire the hear whing i tree.\n",
      "\n",
      "his it she proon where my semer the still greet,\n",
      "and the mes preas the sum the burt of thee,\n",
      "what the se for more the eve the soul so thee.\n",
      "\n",
      "wher hat the stare ma"
     ]
    }
   ],
   "source": [
    "# Generate new sonnets at 0.5 temperature\n",
    "generate_sonnet(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sake lay on me this cross:\n",
      "but here's the stree the sweet with the seart,\n",
      "and the stare the see my see wher the store,\n",
      "the should the stire the stree the sur thee,\n",
      "and the still the san the stare the see be the store,\n",
      "and i st me for me of the stee the sered\n",
      "my the ere the sor the spee when the seet,\n",
      "the so the sor more the sere the sweet steee.\n",
      "the prough the sure the sell in the sell\n",
      "when the the ere wher hand the sweet shath the see the sered\n",
      "and the store the sweet wher hath the sered the see the seed\n",
      "and the stire the seres wher shat thou shat the sere the see the seet steee,\n",
      "the sor the ser the spore the sure the see,\n",
      "the sor"
     ]
    }
   ],
   "source": [
    "# Generate new sonnets at 0.2 temperature\n",
    "generate_sonnet(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the model's output above it learns to format the sonnet correctly most of the time and seems to have learned to separate words with spaces which is impressive since this is a character-level language model. Something interesting it does is it adds punctuation to the end of most lines which is exactly what Shakespeare does in his sonnets. The output where the temperature is 0.2 has a lot of repetition in it. It is probably entering a loop where it sees some sequence of characters before it and predicts the same characters over and over again. This is evident in the last few lines where words like \"see the seed\" and \"the sor\" and \"and the\" appear frequently. Although this behaviour can be expected with such a low temperature. There is not much change to the probability distribution after reweighting the model's outputs.\n",
    "\n",
    "The first example at temperature 0.5 has more word variety but also more spelling mistakes due to the fact that there is more randomness involved in choosing the next character.\n",
    "\n",
    "Below the temperature is higher meaning that there will be more random guessing for the next character which explains why there are a lot of spelling mistakes and bizarre words. I think 0.5 is a good temperature for resampling probabilities because too high (1.0 and up) will cause the model to output lot of random letters and will end up being a jumbled mess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "then, dear friend, and i assure ye,\n",
      "even, he strmins bmire heal ber)eng thou, shagl thou, fedl thou, to may ther's demine,\n",
      "he race an buwt ghin to thou thow weath repr;sing my fun,\n",
      "not ha loo hou and owe lovers for eyer dome\n",
      "the sporce ay more in then to not were piepsent withs owh bres,\n",
      "whenche for he sable whar beauty; swmer' ariss sthem stall, mar by yfoul,\n",
      "whore ched othestrus be that whight dooun,\n",
      "with re bace mone all swill kide sugh and adaradt\n",
      "hat mis po you leve the noul ancus me mean\n",
      "beeet fear shelus were)y my nevire the wronkt';;\n",
      "chence aixe of when gaaguugh and mumi's;\n",
      "with that you theer is ad of rence pulld,\n",
      "thy lood,"
     ]
    }
   ],
   "source": [
    "# Generate new sonnet with 1.0 temp\n",
    "generate_sonnet(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d2d09b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot model loss over epochs\n",
    "plt.plot([i for i in range(1, epochs+1)], loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will save the final model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('shakespeare_sonnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things To Try\n",
    "---\n",
    "1. Stack recurrent layers\n",
    "2. Add bidirectional lstm layers\n",
    "3. Change maximum length of sequences (`maxlen` variable)\n",
    "4. Change step size (`step` variable)\n",
    "5. Train over longer epochs\n",
    "6. Change number of lstm units\n",
    "7. Experiment with different optimizers (rmsprop, adam)\n",
    "8. Try word-level language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load model\n",
    "model = load_model('shakespeare_sonnet_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
