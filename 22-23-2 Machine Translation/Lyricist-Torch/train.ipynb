{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\SLEEPY~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.363 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the latest pre-trained model is pre_trained_65.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sleepyard\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\nn\\functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder输入: ['用', '音乐', '来', '灌醉', '你']\n",
      "decoder输入: ['<go>', '你', '就是', '海滩', '下', '那', '的', '乌', '克', '丽丽', '<eos>']\n",
      "target目标: ['你', '就是', '海滩', '下', '那', '的', '乌', '克', '<unk>', '<eos>']\n",
      "预测结果: ['我', '是', '海滩', '你', '过', '的', '乌', '克', '<eos>', '<eos>']\n",
      "attention:\n",
      " tensor([[6.0580e-02, 6.8272e-03, 5.4618e-04, 1.8878e-01, 7.4326e-01],\n",
      "        [1.8312e-04, 7.1510e-04, 5.2871e-03, 5.5486e-01, 4.3896e-01],\n",
      "        [4.3742e-01, 2.7922e-01, 2.9881e-02, 1.6357e-01, 8.9908e-02],\n",
      "        [8.8267e-02, 1.3518e-02, 5.9371e-02, 8.1810e-02, 7.5703e-01],\n",
      "        [8.1265e-03, 1.5040e-02, 2.3202e-03, 1.0928e-01, 8.6524e-01],\n",
      "        [3.7515e-02, 1.0766e-01, 1.3278e-02, 3.2054e-01, 5.2100e-01],\n",
      "        [5.6107e-02, 1.0699e-01, 7.7887e-03, 4.3476e-02, 7.8564e-01],\n",
      "        [1.5016e-01, 4.1788e-01, 1.1053e-02, 6.1271e-02, 3.5963e-01],\n",
      "        [1.6342e-02, 3.0133e-01, 1.7151e-02, 5.6748e-02, 6.0843e-01],\n",
      "        [6.2812e-02, 1.0233e-01, 1.0939e-02, 6.5414e-02, 7.5851e-01],\n",
      "        [7.1934e-03, 1.1691e-02, 1.0860e-02, 3.6648e-01, 6.0378e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 65 step 100 loss: 3.206904344558716\n",
      "epoch 65 step 200 loss: 3.209260802268982\n",
      "epoch 65 step 300 loss: 3.2299308013916015\n",
      "epoch 65 step 400 loss: 3.249065511226654\n",
      "epoch 65 step 500 loss: 3.2247260999679566\n",
      "epoch 65 step 600 loss: 3.2309531450271605\n",
      "epoch 65 step 700 loss: 3.2549207043647765\n",
      "epoch 65 step 800 loss: 3.2714685654640197\n",
      "epoch 65 step 900 loss: 3.2609957027435303\n",
      "epoch 65 step 1000 loss: 3.2916054010391234\n",
      "epoch 65 step 1100 loss: 3.287225787639618\n",
      "epoch 65 step 1200 loss: 3.2771573567390444\n",
      "epoch 65 step 1300 loss: 3.2633043193817137\n",
      "epoch 65 step 1400 loss: 3.2974532675743102\n",
      "epoch 65 step 1500 loss: 3.3135189628601074\n",
      "epoch 65 step 1600 loss: 3.335911285877228\n",
      "epoch 65 step 1700 loss: 3.304849851131439\n",
      "current lr: 0.00049\n",
      "encoder输入: ['但', '求', '凭', '这', '阙', '歌']\n",
      "decoder输入: ['<go>', '谢谢', '你', '风雨', '内', '<eos>']\n",
      "target目标: ['谢谢', '你', '风雨', '内', '<eos>']\n",
      "预测结果: ['谢谢', '你', '风雨', '内', '<eos>']\n",
      "attention:\n",
      " tensor([[4.0228e-04, 8.4866e-05, 4.8048e-03, 4.1394e-02, 2.4499e-01, 7.0832e-01],\n",
      "        [9.4407e-03, 2.0854e-02, 3.3321e-02, 2.3898e-02, 5.1435e-01, 3.9814e-01],\n",
      "        [1.4131e-03, 7.5222e-04, 4.9595e-02, 4.3719e-02, 2.6559e-01, 6.3893e-01],\n",
      "        [6.2259e-04, 4.7997e-05, 9.6246e-04, 1.4724e-02, 4.7025e-02, 9.3662e-01],\n",
      "        [9.5532e-04, 5.9327e-05, 2.7836e-03, 3.1799e-03, 1.6809e-01, 8.2493e-01],\n",
      "        [1.8351e-03, 2.5758e-04, 5.5048e-03, 5.4057e-02, 1.1010e-01, 8.2825e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 66 step 100 loss: 3.2252274465560915\n",
      "epoch 66 step 200 loss: 3.223414876461029\n",
      "epoch 66 step 300 loss: 3.2201440143585205\n",
      "epoch 66 step 400 loss: 3.2312557172775267\n",
      "epoch 66 step 500 loss: 3.2268676924705506\n",
      "epoch 66 step 600 loss: 3.256691906452179\n",
      "epoch 66 step 700 loss: 3.271795537471771\n",
      "epoch 66 step 800 loss: 3.269540922641754\n",
      "epoch 66 step 900 loss: 3.262529993057251\n",
      "epoch 66 step 1000 loss: 3.2656004500389098\n",
      "epoch 66 step 1100 loss: 3.2737737035751344\n",
      "epoch 66 step 1200 loss: 3.276184928417206\n",
      "epoch 66 step 1300 loss: 3.3066086769104004\n",
      "epoch 66 step 1400 loss: 3.29512610912323\n",
      "epoch 66 step 1500 loss: 3.2854584431648255\n",
      "epoch 66 step 1600 loss: 3.3001645827293395\n",
      "epoch 66 step 1700 loss: 3.3083722805976867\n",
      "encoder输入: ['感情', '需要', '经营', '懂', '这点', '道理']\n",
      "decoder输入: ['<go>', '可', '开始', '需要', '自信', '我', '没有', '自信', '<eos>']\n",
      "target目标: ['可', '开始', '需要', '自信', '我', '没有', '自信', '<eos>']\n",
      "预测结果: ['不要', '知道', '怎样', '什么', '<eos>', '不', '<eos>', '<eos>']\n",
      "attention:\n",
      " tensor([[0.0333, 0.2814, 0.4912, 0.1915, 0.0012, 0.0014],\n",
      "        [0.0065, 0.2350, 0.3167, 0.4204, 0.0160, 0.0055],\n",
      "        [0.0145, 0.2817, 0.1166, 0.1777, 0.2544, 0.1552],\n",
      "        [0.0065, 0.0373, 0.2659, 0.5409, 0.1073, 0.0422],\n",
      "        [0.0008, 0.0374, 0.0913, 0.2771, 0.1625, 0.4308],\n",
      "        [0.0202, 0.1236, 0.0680, 0.6258, 0.0895, 0.0730],\n",
      "        [0.0073, 0.0456, 0.2406, 0.6461, 0.0425, 0.0178],\n",
      "        [0.0058, 0.0368, 0.0989, 0.4853, 0.2711, 0.1020],\n",
      "        [0.2162, 0.0647, 0.0903, 0.5927, 0.0260, 0.0100]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 67 step 100 loss: 3.178326587677002\n",
      "epoch 67 step 200 loss: 3.150625922679901\n",
      "epoch 67 step 300 loss: 3.1974848651885988\n",
      "epoch 67 step 400 loss: 3.2093605494499204\n",
      "epoch 67 step 500 loss: 3.206279776096344\n",
      "epoch 67 step 600 loss: 3.2220248079299925\n",
      "epoch 67 step 700 loss: 3.2170581817626953\n",
      "epoch 67 step 800 loss: 3.2208346629142763\n",
      "epoch 67 step 900 loss: 3.2542825961112976\n",
      "epoch 67 step 1000 loss: 3.251136999130249\n",
      "epoch 67 step 1100 loss: 3.25920515537262\n",
      "epoch 67 step 1200 loss: 3.2466234946250916\n",
      "epoch 67 step 1300 loss: 3.2622446608543396\n",
      "epoch 67 step 1400 loss: 3.287722227573395\n",
      "epoch 67 step 1500 loss: 3.2923322892189026\n",
      "epoch 67 step 1600 loss: 3.2912578272819517\n",
      "epoch 67 step 1700 loss: 3.2855344247817992\n",
      "current lr: 0.00048019999999999996\n",
      "encoder输入: ['忙', '的', '累倒']\n",
      "decoder输入: ['<go>', '连', '哭', '的', '时间', '都', '没有', '最好', '<eos>']\n",
      "target目标: ['连', '哭', '的', '时间', '都', '没有', '最好', '<eos>']\n",
      "预测结果: ['想', '哭', '的', '人', '都', '不', '<eos>', '<eos>']\n",
      "attention:\n",
      " tensor([[0.0581, 0.8112, 0.1307],\n",
      "        [0.0020, 0.0020, 0.9960],\n",
      "        [0.3126, 0.3693, 0.3181],\n",
      "        [0.0532, 0.0074, 0.9394],\n",
      "        [0.8268, 0.1076, 0.0656],\n",
      "        [0.5537, 0.0370, 0.4092],\n",
      "        [0.2807, 0.0412, 0.6781],\n",
      "        [0.6268, 0.2171, 0.1561],\n",
      "        [0.9616, 0.0083, 0.0301]], grad_fn=<SelectBackward0>)\n",
      "epoch 68 step 100 loss: 3.1901675701141357\n",
      "epoch 68 step 200 loss: 3.1844792103767396\n",
      "epoch 68 step 300 loss: 3.196811957359314\n",
      "epoch 68 step 400 loss: 3.220264146327972\n",
      "epoch 68 step 500 loss: 3.21655166387558\n",
      "epoch 68 step 600 loss: 3.2227866435050965\n",
      "epoch 68 step 700 loss: 3.222372806072235\n",
      "epoch 68 step 800 loss: 3.2294408082962036\n",
      "epoch 68 step 900 loss: 3.250974729061127\n",
      "epoch 68 step 1000 loss: 3.2444990563392637\n",
      "epoch 68 step 1100 loss: 3.252587604522705\n",
      "epoch 68 step 1200 loss: 3.2526334500312806\n",
      "epoch 68 step 1300 loss: 3.2510746812820432\n",
      "epoch 68 step 1400 loss: 3.267501814365387\n",
      "epoch 68 step 1500 loss: 3.2557728815078737\n",
      "epoch 68 step 1600 loss: 3.29175448179245\n",
      "epoch 68 step 1700 loss: 3.2846035242080687\n",
      "encoder输入: ['这', '一刻', '你', '给', '我', '的', '泪', '或', '快乐']\n",
      "decoder输入: ['<go>', '都', '是', '最', '美好', '的', '旧', '时光', '<eos>']\n",
      "target目标: ['都', '是', '最', '美好', '的', '旧', '时光', '<eos>']\n",
      "预测结果: ['都', '是', '最', '美好', '的', '旧', '时光', '<eos>']\n",
      "attention:\n",
      " tensor([[7.4410e-01, 1.0601e-01, 8.5613e-03, 6.8483e-03, 5.0568e-02, 1.8566e-02,\n",
      "         6.7552e-03, 2.4570e-02, 3.4024e-02],\n",
      "        [1.0305e-02, 3.9695e-02, 1.0586e-01, 2.6773e-02, 1.3095e-01, 9.3307e-02,\n",
      "         3.5856e-02, 1.7009e-01, 3.8717e-01],\n",
      "        [3.3707e-03, 2.0201e-03, 8.4719e-03, 1.3175e-02, 8.6881e-04, 2.7924e-03,\n",
      "         4.3763e-02, 9.8952e-03, 9.1564e-01],\n",
      "        [1.8246e-01, 5.0044e-02, 5.0486e-02, 3.9261e-03, 7.8139e-04, 1.1481e-03,\n",
      "         4.0940e-02, 1.2573e-02, 6.5764e-01],\n",
      "        [6.1500e-02, 8.2304e-02, 2.7744e-03, 3.0327e-03, 2.0005e-03, 1.4204e-02,\n",
      "         1.2140e-01, 1.4193e-01, 5.7086e-01],\n",
      "        [1.1880e-01, 7.0528e-02, 5.3130e-02, 2.2126e-02, 1.1182e-02, 1.9490e-02,\n",
      "         7.4960e-02, 9.3106e-02, 5.3668e-01],\n",
      "        [5.2828e-01, 2.5982e-01, 4.9894e-02, 1.0363e-02, 8.6837e-03, 2.4376e-02,\n",
      "         1.1727e-02, 3.3372e-02, 7.3485e-02],\n",
      "        [4.0774e-02, 3.0118e-02, 4.4795e-02, 5.8569e-03, 1.7694e-02, 1.5184e-02,\n",
      "         4.1940e-01, 9.0003e-02, 3.3618e-01],\n",
      "        [2.2130e-02, 1.2001e-02, 7.5114e-03, 1.3850e-03, 1.3484e-03, 9.7102e-03,\n",
      "         3.8518e-02, 1.0219e-01, 8.0520e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 69 step 100 loss: 3.1486265325546263\n",
      "epoch 69 step 200 loss: 3.14504590511322\n",
      "epoch 69 step 300 loss: 3.1613442397117613\n",
      "epoch 69 step 400 loss: 3.1773490929603576\n",
      "epoch 69 step 500 loss: 3.1829152798652647\n",
      "epoch 69 step 600 loss: 3.1973659133911134\n",
      "epoch 69 step 700 loss: 3.217585952281952\n",
      "epoch 69 step 800 loss: 3.2198460936546325\n",
      "epoch 69 step 900 loss: 3.2173239755630494\n",
      "epoch 69 step 1000 loss: 3.242100737094879\n",
      "epoch 69 step 1100 loss: 3.235880744457245\n",
      "epoch 69 step 1200 loss: 3.2476137614250185\n",
      "epoch 69 step 1300 loss: 3.220693769454956\n",
      "epoch 69 step 1400 loss: 3.2275238919258116\n",
      "epoch 69 step 1500 loss: 3.2522156333923338\n",
      "epoch 69 step 1600 loss: 3.2673468661308287\n",
      "epoch 69 step 1700 loss: 3.2505112624168397\n",
      "current lr: 0.00047059599999999994\n",
      "encoder输入: ['年少', '的', '壮志', '雄心', '至今', '还', '觉得', '豪情万丈']\n",
      "decoder输入: ['<go>', '少年', '强', '那', '中国', '一定', '也', '很棒', '<eos>']\n",
      "target目标: ['少年', '强', '那', '中国', '一定', '也', '很棒', '<eos>']\n",
      "预测结果: ['少年', '的', '桥段', '中国', '一定', '也', '很棒', '<eos>']\n",
      "attention:\n",
      " tensor([[4.4858e-04, 1.2995e-02, 1.0796e-03, 6.7057e-03, 3.5444e-02, 2.1021e-01,\n",
      "         4.5610e-01, 2.7702e-01],\n",
      "        [8.3313e-03, 1.6872e-01, 2.2511e-02, 3.1765e-02, 1.2991e-01, 9.8147e-02,\n",
      "         2.2523e-01, 3.1538e-01],\n",
      "        [3.3537e-05, 3.9231e-04, 1.1421e-03, 4.1177e-02, 1.6999e-01, 3.9109e-01,\n",
      "         3.7195e-01, 2.4226e-02],\n",
      "        [8.1949e-04, 1.2049e-02, 1.0915e-02, 4.2440e-02, 6.4778e-02, 2.1080e-01,\n",
      "         3.8409e-01, 2.7410e-01],\n",
      "        [1.0787e-03, 4.0585e-03, 1.7326e-03, 1.9827e-02, 1.9263e-02, 8.7628e-02,\n",
      "         2.4220e-01, 6.2422e-01],\n",
      "        [1.1629e-03, 1.1475e-03, 8.3501e-03, 3.1844e-02, 3.8667e-03, 9.0696e-03,\n",
      "         2.5489e-01, 6.8966e-01],\n",
      "        [3.4498e-03, 5.9240e-03, 8.5848e-03, 2.5329e-02, 1.0068e-01, 1.5308e-01,\n",
      "         2.8544e-01, 4.1752e-01],\n",
      "        [4.1979e-02, 6.1810e-03, 5.5565e-03, 1.4609e-02, 2.6398e-02, 3.9663e-01,\n",
      "         3.9199e-01, 1.1666e-01],\n",
      "        [3.8500e-05, 6.9952e-05, 2.0378e-04, 3.1922e-03, 6.3456e-03, 8.6869e-02,\n",
      "         7.3879e-01, 1.6449e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 70 step 100 loss: 3.173034358024597\n",
      "epoch 70 step 200 loss: 3.1598968529701232\n",
      "epoch 70 step 300 loss: 3.1684240436553956\n",
      "epoch 70 step 400 loss: 3.174343903064728\n",
      "epoch 70 step 500 loss: 3.175631856918335\n",
      "epoch 70 step 600 loss: 3.216744179725647\n",
      "epoch 70 step 700 loss: 3.1853064703941345\n",
      "epoch 70 step 800 loss: 3.19114387512207\n",
      "epoch 70 step 900 loss: 3.224274833202362\n",
      "epoch 70 step 1000 loss: 3.2043054628372194\n",
      "epoch 70 step 1100 loss: 3.2446174144744875\n",
      "epoch 70 step 1200 loss: 3.2886895036697386\n",
      "epoch 70 step 1300 loss: 3.233530704975128\n",
      "epoch 70 step 1400 loss: 3.2297393107414245\n",
      "epoch 70 step 1500 loss: 3.2593107485771178\n",
      "epoch 70 step 1600 loss: 3.235080587863922\n",
      "epoch 70 step 1700 loss: 3.27261846780777\n",
      "encoder输入: ['古老', '的', '情节']\n",
      "decoder输入: ['<go>', '时间', '在', '倒', '回', '<eos>']\n",
      "target目标: ['时间', '在', '倒', '回', '<eos>']\n",
      "预测结果: ['我', '在', '你', '着', '<eos>']\n",
      "attention:\n",
      " tensor([[0.0722, 0.1290, 0.7988],\n",
      "        [0.1545, 0.2157, 0.6298],\n",
      "        [0.3590, 0.1124, 0.5286],\n",
      "        [0.9528, 0.0329, 0.0143],\n",
      "        [0.4963, 0.2719, 0.2318],\n",
      "        [0.1047, 0.0222, 0.8731]], grad_fn=<SelectBackward0>)\n",
      "epoch 71 step 100 loss: 3.149012451171875\n",
      "epoch 71 step 200 loss: 3.114779372215271\n",
      "epoch 71 step 300 loss: 3.1327006030082702\n",
      "epoch 71 step 400 loss: 3.1242283058166502\n",
      "epoch 71 step 500 loss: 3.1641595721244813\n",
      "epoch 71 step 600 loss: 3.1667439413070677\n",
      "epoch 71 step 700 loss: 3.1715116405487063\n",
      "epoch 71 step 800 loss: 3.2170572113990783\n",
      "epoch 71 step 900 loss: 3.2102988243103026\n",
      "epoch 71 step 1000 loss: 3.1883666205406187\n",
      "epoch 71 step 1100 loss: 3.225934386253357\n",
      "epoch 71 step 1200 loss: 3.212011911869049\n",
      "epoch 71 step 1300 loss: 3.211844117641449\n",
      "epoch 71 step 1400 loss: 3.2117743134498595\n",
      "epoch 71 step 1500 loss: 3.238308680057526\n",
      "epoch 71 step 1600 loss: 3.2658992195129395\n",
      "epoch 71 step 1700 loss: 3.250460307598114\n",
      "current lr: 0.0004611840799999999\n",
      "encoder输入: ['无', '伴', '无', '眠', '夜', '店', '独', '醉', '骤', '听', '是', '你', '呼吸', '气息']\n",
      "decoder输入: ['<go>', '疑', '幻', '似', '真', '像', '透', '梦', '里', '又', '再', '遇上', '心中', '背影', '<eos>']\n",
      "target目标: ['疑', '幻', '似', '真', '像', '透', '梦', '里', '又', '再', '遇上', '心中', '背影', '<eos>']\n",
      "预测结果: ['疑', '旧日', '更深', '飞', '已', '最初', '梦', '里', '似', '再', '等', '<eos>', '<eos>', '<eos>']\n",
      "attention:\n",
      " tensor([[7.8793e-03, 5.7854e-03, 2.2116e-02, 2.4928e-02, 3.5004e-02, 3.5835e-01,\n",
      "         2.0005e-02, 2.7803e-02, 2.6292e-02, 2.9291e-02, 8.2680e-02, 5.0700e-02,\n",
      "         1.0314e-01, 2.0603e-01],\n",
      "        [7.8337e-04, 2.2280e-04, 2.2171e-03, 2.1129e-03, 3.5987e-03, 1.2181e-01,\n",
      "         5.4328e-03, 3.7200e-04, 1.4258e-03, 1.2211e-02, 8.3376e-02, 1.4575e-01,\n",
      "         2.2410e-01, 3.9659e-01],\n",
      "        [4.7724e-04, 3.1422e-03, 9.1741e-03, 3.9311e-02, 5.4513e-02, 5.0166e-01,\n",
      "         1.8985e-02, 1.2618e-02, 1.9115e-02, 3.6106e-02, 5.7935e-02, 2.1838e-02,\n",
      "         7.4861e-02, 1.5026e-01],\n",
      "        [2.5898e-05, 4.7182e-05, 4.4347e-04, 4.6036e-03, 4.8410e-03, 1.1690e-02,\n",
      "         2.3974e-03, 2.2440e-03, 1.3091e-03, 1.0234e-02, 5.5800e-02, 7.7285e-02,\n",
      "         3.5307e-01, 4.7601e-01],\n",
      "        [4.5176e-03, 1.1047e-03, 5.1073e-03, 9.2447e-03, 2.1238e-03, 1.8651e-01,\n",
      "         2.8400e-02, 1.0411e-02, 8.7186e-03, 4.9769e-02, 1.2270e-01, 1.1976e-01,\n",
      "         1.3312e-01, 3.1851e-01],\n",
      "        [9.7019e-05, 8.6293e-05, 1.3795e-04, 1.4241e-04, 7.6924e-05, 1.7962e-03,\n",
      "         6.1394e-04, 7.6645e-04, 1.4340e-03, 9.5147e-03, 8.0493e-03, 2.3330e-02,\n",
      "         3.2441e-01, 6.2954e-01],\n",
      "        [2.5253e-04, 4.4139e-04, 5.3655e-03, 4.6490e-02, 4.5099e-02, 1.6324e-01,\n",
      "         7.6930e-03, 6.6380e-03, 1.0666e-02, 6.9066e-02, 2.4406e-01, 1.2737e-01,\n",
      "         1.0136e-01, 1.7226e-01],\n",
      "        [4.3804e-03, 6.9974e-03, 1.5944e-01, 7.7515e-02, 1.0532e-01, 2.7304e-01,\n",
      "         2.7116e-02, 1.3103e-02, 7.3212e-03, 1.4060e-02, 1.1250e-02, 1.0738e-02,\n",
      "         4.8372e-02, 2.4135e-01],\n",
      "        [1.1456e-02, 3.4973e-02, 3.3455e-02, 2.5271e-02, 1.1326e-02, 4.8508e-02,\n",
      "         3.6746e-02, 4.8487e-02, 2.7131e-02, 2.3915e-02, 3.7488e-02, 3.6678e-02,\n",
      "         1.0783e-01, 5.1673e-01],\n",
      "        [2.5521e-02, 2.5747e-03, 3.5201e-03, 6.5311e-03, 3.0637e-03, 9.3947e-02,\n",
      "         3.3044e-02, 4.1465e-02, 9.1933e-03, 8.4348e-03, 3.6105e-03, 2.1139e-02,\n",
      "         3.1448e-01, 4.3348e-01],\n",
      "        [4.8665e-03, 2.3131e-03, 1.9636e-03, 9.0277e-03, 4.4115e-03, 7.9332e-02,\n",
      "         8.3846e-02, 8.8259e-02, 2.3797e-02, 1.3941e-02, 3.1332e-03, 1.5877e-02,\n",
      "         2.6114e-01, 4.0809e-01],\n",
      "        [4.1139e-01, 1.3332e-01, 9.3659e-03, 5.6640e-03, 2.5945e-03, 3.5856e-02,\n",
      "         4.4905e-02, 2.4671e-02, 2.9143e-03, 6.3826e-03, 4.9153e-03, 3.1973e-02,\n",
      "         9.7458e-02, 1.8859e-01],\n",
      "        [5.6174e-02, 5.2441e-02, 8.9629e-04, 5.0586e-04, 3.2243e-04, 4.0186e-03,\n",
      "         7.7927e-03, 7.9967e-03, 4.4410e-03, 2.2493e-02, 1.4497e-02, 8.3329e-02,\n",
      "         3.1692e-01, 4.2817e-01],\n",
      "        [8.9126e-03, 8.2604e-03, 1.8467e-03, 1.1509e-03, 4.5658e-03, 4.2798e-02,\n",
      "         2.3398e-02, 1.6897e-02, 1.8646e-02, 8.7080e-02, 2.2544e-02, 6.7764e-02,\n",
      "         2.0910e-01, 4.8703e-01],\n",
      "        [6.0002e-02, 8.7444e-02, 1.9825e-02, 1.0784e-02, 1.2198e-02, 3.9364e-02,\n",
      "         1.1080e-01, 5.1396e-02, 7.4633e-03, 8.3390e-03, 2.6843e-03, 3.6043e-02,\n",
      "         2.0851e-01, 3.4515e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 72 step 100 loss: 3.1476082158088685\n",
      "epoch 72 step 200 loss: 3.1431954288482666\n",
      "epoch 72 step 300 loss: 3.154702684879303\n",
      "epoch 72 step 400 loss: 3.1334853100776674\n",
      "epoch 72 step 500 loss: 3.1613179779052736\n",
      "epoch 72 step 600 loss: 3.188859531879425\n",
      "epoch 72 step 700 loss: 3.187905693054199\n",
      "epoch 72 step 800 loss: 3.200006892681122\n",
      "epoch 72 step 900 loss: 3.2056124925613405\n",
      "epoch 72 step 1000 loss: 3.211925754547119\n",
      "epoch 72 step 1100 loss: 3.227992374897003\n",
      "epoch 72 step 1200 loss: 3.212050988674164\n",
      "epoch 72 step 1300 loss: 3.2077906036376955\n",
      "epoch 72 step 1400 loss: 3.2079879236221314\n",
      "epoch 72 step 1500 loss: 3.219334673881531\n",
      "epoch 72 step 1600 loss: 3.2484578323364257\n",
      "epoch 72 step 1700 loss: 3.2354468274116517\n",
      "encoder输入: ['也许', '一生', '只得', '这', '运气']\n",
      "decoder输入: ['<go>', '才', '令', '我会', '不', '哭', '不', '笑', '<eos>']\n",
      "target目标: ['才', '令', '我会', '不', '哭', '不', '笑', '<eos>']\n",
      "预测结果: ['仍', '令', '我', '再', '改', '不', '去', '<eos>']\n",
      "attention:\n",
      " tensor([[0.0984, 0.0114, 0.0245, 0.1714, 0.6942],\n",
      "        [0.0023, 0.0055, 0.0408, 0.0120, 0.9393],\n",
      "        [0.0030, 0.0030, 0.0259, 0.1159, 0.8522],\n",
      "        [0.1580, 0.0141, 0.0769, 0.0521, 0.6989],\n",
      "        [0.0049, 0.0014, 0.0753, 0.0196, 0.8988],\n",
      "        [0.9141, 0.0208, 0.0134, 0.0040, 0.0477],\n",
      "        [0.0377, 0.0879, 0.7098, 0.0319, 0.1328],\n",
      "        [0.5668, 0.0835, 0.0913, 0.0260, 0.2323],\n",
      "        [0.1877, 0.1166, 0.5207, 0.0459, 0.1291]], grad_fn=<SelectBackward0>)\n",
      "epoch 73 step 100 loss: 3.1417718076705934\n",
      "epoch 73 step 200 loss: 3.1034726238250734\n",
      "epoch 73 step 300 loss: 3.1528185915946962\n",
      "epoch 73 step 400 loss: 3.1136669898033142\n",
      "epoch 73 step 500 loss: 3.130599274635315\n",
      "epoch 73 step 600 loss: 3.150942630767822\n",
      "epoch 73 step 700 loss: 3.1517523193359374\n",
      "epoch 73 step 800 loss: 3.1637881779670716\n",
      "epoch 73 step 900 loss: 3.1893453931808473\n",
      "epoch 73 step 1000 loss: 3.2196747422218324\n",
      "epoch 73 step 1100 loss: 3.2001958799362185\n",
      "epoch 73 step 1200 loss: 3.202335479259491\n",
      "epoch 73 step 1300 loss: 3.1878092861175538\n",
      "epoch 73 step 1400 loss: 3.2017736554145815\n",
      "epoch 73 step 1500 loss: 3.214712643623352\n",
      "epoch 73 step 1600 loss: 3.2051866483688354\n",
      "epoch 73 step 1700 loss: 3.1960562658309937\n",
      "current lr: 0.0004519603983999999\n",
      "encoder输入: ['无数', '夜', '我', '如', '泥醉', '人', '感觉', '更累']\n",
      "decoder输入: ['<go>', '也许', '你', '不会', '知', '在', '远方', '心醉', '是', '谁', '<eos>']\n",
      "target目标: ['也许', '你', '不会', '知', '在', '远方', '心醉', '是', '谁', '<eos>']\n",
      "预测结果: ['你', '你', '是', '懂', '<eos>', '我', '是', '<eos>', '谁', '<eos>']\n",
      "attention:\n",
      " tensor([[0.2015, 0.0414, 0.0596, 0.1606, 0.1395, 0.1338, 0.1893, 0.0743],\n",
      "        [0.0352, 0.0379, 0.0227, 0.0079, 0.0127, 0.3913, 0.4139, 0.0783],\n",
      "        [0.0051, 0.0050, 0.0084, 0.0598, 0.0261, 0.5039, 0.2068, 0.1849],\n",
      "        [0.0683, 0.0484, 0.0361, 0.0055, 0.0419, 0.1912, 0.2655, 0.3431],\n",
      "        [0.0201, 0.0159, 0.1176, 0.2281, 0.0352, 0.0302, 0.1540, 0.3988],\n",
      "        [0.1761, 0.0082, 0.0036, 0.0029, 0.0339, 0.2332, 0.2933, 0.2489],\n",
      "        [0.3625, 0.0962, 0.0107, 0.0313, 0.0308, 0.1061, 0.1261, 0.2364],\n",
      "        [0.0274, 0.0173, 0.0587, 0.2893, 0.1292, 0.0911, 0.0743, 0.3128],\n",
      "        [0.0115, 0.0428, 0.0065, 0.0267, 0.0281, 0.2637, 0.4522, 0.1686],\n",
      "        [0.0021, 0.0209, 0.0131, 0.0276, 0.0122, 0.3428, 0.4511, 0.1301],\n",
      "        [0.0934, 0.0931, 0.0669, 0.0496, 0.0075, 0.0711, 0.2037, 0.4148]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 74 step 100 loss: 3.127092132568359\n",
      "epoch 74 step 200 loss: 3.108858687877655\n",
      "epoch 74 step 300 loss: 3.136737794876099\n",
      "epoch 74 step 400 loss: 3.1464165830612183\n",
      "epoch 74 step 500 loss: 3.147129578590393\n",
      "epoch 74 step 600 loss: 3.1476144051551818\n",
      "epoch 74 step 700 loss: 3.1893574237823485\n",
      "epoch 74 step 800 loss: 3.184568696022034\n",
      "epoch 74 step 900 loss: 3.1782513546943663\n",
      "epoch 74 step 1000 loss: 3.17335613489151\n",
      "epoch 74 step 1100 loss: 3.1749366235733034\n",
      "epoch 74 step 1200 loss: 3.1863369154930115\n",
      "epoch 74 step 1300 loss: 3.205487759113312\n",
      "epoch 74 step 1400 loss: 3.220659921169281\n",
      "epoch 74 step 1500 loss: 3.218808355331421\n",
      "epoch 74 step 1600 loss: 3.198385012149811\n",
      "epoch 74 step 1700 loss: 3.2087871074676513\n",
      "encoder输入: ['太', '容易', '来', '的', '就', '不', '理睬']\n",
      "decoder输入: ['<go>', '其实', '谁', '不想', '遇见', '真', '爱', '<eos>']\n",
      "target目标: ['其实', '谁', '不想', '遇见', '真', '爱', '<eos>']\n",
      "预测结果: ['我', '谁', '都', '<eos>', '你', '爱', '<eos>']\n",
      "attention:\n",
      " tensor([[6.5234e-01, 1.3777e-01, 1.0066e-01, 8.2501e-03, 2.1188e-02, 1.9346e-02,\n",
      "         6.0444e-02],\n",
      "        [6.1331e-02, 3.7992e-02, 6.5523e-02, 7.6834e-02, 1.4110e-01, 1.1298e-01,\n",
      "         5.0424e-01],\n",
      "        [4.5276e-01, 2.5250e-02, 2.7677e-02, 5.9122e-02, 1.4769e-01, 2.6300e-01,\n",
      "         2.4501e-02],\n",
      "        [9.5028e-03, 1.3558e-03, 5.1122e-04, 3.5430e-02, 5.8052e-01, 3.4875e-01,\n",
      "         2.3931e-02],\n",
      "        [1.5828e-02, 8.9289e-03, 3.3650e-01, 1.5146e-01, 1.3284e-01, 1.8335e-01,\n",
      "         1.7109e-01],\n",
      "        [3.4949e-01, 1.2233e-02, 5.5416e-02, 4.0452e-02, 2.3262e-01, 2.5042e-01,\n",
      "         5.9368e-02],\n",
      "        [2.8242e-01, 2.1493e-02, 3.0811e-02, 1.0590e-01, 6.4604e-02, 4.1466e-01,\n",
      "         8.0110e-02],\n",
      "        [1.6267e-02, 1.4501e-03, 1.1289e-03, 2.4494e-03, 7.9510e-02, 3.6266e-01,\n",
      "         5.3653e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 75 step 100 loss: 3.0969226241111754\n",
      "epoch 75 step 200 loss: 3.069190797805786\n",
      "epoch 75 step 300 loss: 3.1157026267051697\n",
      "epoch 75 step 400 loss: 3.1238504028320313\n",
      "epoch 75 step 500 loss: 3.1143225836753845\n",
      "epoch 75 step 600 loss: 3.140495502948761\n",
      "epoch 75 step 700 loss: 3.1241497921943666\n",
      "epoch 75 step 800 loss: 3.1515265822410585\n",
      "epoch 75 step 900 loss: 3.1629223561286928\n",
      "epoch 75 step 1000 loss: 3.1664468097686767\n",
      "epoch 75 step 1100 loss: 3.1733409571647644\n",
      "epoch 75 step 1200 loss: 3.195259997844696\n",
      "epoch 75 step 1300 loss: 3.17609840631485\n",
      "epoch 75 step 1400 loss: 3.198887960910797\n",
      "epoch 75 step 1500 loss: 3.1932754635810854\n",
      "epoch 75 step 1600 loss: 3.189477059841156\n",
      "epoch 75 step 1700 loss: 3.209077355861664\n",
      "current lr: 0.0004429211904319999\n",
      "encoder输入: ['无言', '独', '上', '西楼']\n",
      "decoder输入: ['<go>', '月', '如', '钩', '<eos>']\n",
      "target目标: ['月', '如', '钩', '<eos>']\n",
      "预测结果: ['月', '如', '钩', '<eos>']\n",
      "attention:\n",
      " tensor([[1.0973e-01, 7.6643e-02, 7.2914e-01, 8.4487e-02],\n",
      "        [1.3969e-02, 8.1688e-04, 7.5960e-01, 2.2562e-01],\n",
      "        [1.7239e-03, 3.2711e-04, 6.9203e-01, 3.0592e-01],\n",
      "        [1.7889e-02, 1.9025e-01, 3.2454e-01, 4.6733e-01],\n",
      "        [1.9322e-02, 5.5623e-03, 4.5390e-01, 5.2122e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 76 step 100 loss: 3.091601028442383\n",
      "epoch 76 step 200 loss: 3.097458629608154\n",
      "epoch 76 step 300 loss: 3.1257336807250975\n",
      "epoch 76 step 400 loss: 3.111766312122345\n",
      "epoch 76 step 500 loss: 3.133766577243805\n",
      "epoch 76 step 600 loss: 3.1203678965568544\n",
      "epoch 76 step 700 loss: 3.1616037559509276\n",
      "epoch 76 step 800 loss: 3.1713528728485105\n",
      "epoch 76 step 900 loss: 3.1745501232147215\n",
      "epoch 76 step 1000 loss: 3.1607745480537415\n",
      "epoch 76 step 1100 loss: 3.1808860874176026\n",
      "epoch 76 step 1200 loss: 3.170264756679535\n",
      "epoch 76 step 1300 loss: 3.1651297330856325\n",
      "epoch 76 step 1400 loss: 3.1847780632972715\n",
      "epoch 76 step 1500 loss: 3.1970209503173828\n",
      "epoch 76 step 1600 loss: 3.179034898281097\n",
      "epoch 76 step 1700 loss: 3.180373241901398\n",
      "encoder输入: ['迷路', '了', '在', '这', '城市', '的', '森林']\n",
      "decoder输入: ['<go>', '感觉得到', '却', '又', '无法', '抗拒', '<eos>']\n",
      "target目标: ['感觉得到', '却', '又', '无法', '抗拒', '<eos>']\n",
      "预测结果: ['感觉得到', '身边', '又', '无法', '抗拒', '<eos>']\n",
      "attention:\n",
      " tensor([[6.0249e-01, 1.7520e-02, 2.5333e-02, 1.6036e-01, 5.9218e-02, 2.5028e-02,\n",
      "         1.1004e-01],\n",
      "        [4.6647e-01, 1.4322e-02, 8.2436e-02, 8.5220e-02, 2.5539e-02, 7.4264e-02,\n",
      "         2.5175e-01],\n",
      "        [2.5266e-01, 5.1050e-03, 5.6859e-02, 1.8124e-01, 9.3971e-02, 1.6772e-01,\n",
      "         2.4244e-01],\n",
      "        [4.7062e-01, 2.6817e-04, 4.7391e-03, 3.3075e-02, 2.0902e-01, 8.0383e-02,\n",
      "         2.0190e-01],\n",
      "        [9.0623e-01, 7.6827e-04, 4.3115e-04, 1.5134e-03, 1.3395e-02, 5.2864e-03,\n",
      "         7.2372e-02],\n",
      "        [3.0891e-01, 8.1285e-04, 5.6642e-03, 9.2884e-03, 6.3216e-03, 1.9373e-01,\n",
      "         4.7528e-01],\n",
      "        [1.0576e-01, 3.5654e-05, 5.7018e-03, 5.3578e-03, 2.0402e-01, 2.1216e-02,\n",
      "         6.5791e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 77 step 100 loss: 3.0939563035964968\n",
      "epoch 77 step 200 loss: 3.0784380078315734\n",
      "epoch 77 step 300 loss: 3.0927872467041015\n",
      "epoch 77 step 400 loss: 3.0731667494773864\n",
      "epoch 77 step 500 loss: 3.0997824263572693\n",
      "epoch 77 step 600 loss: 3.089726254940033\n",
      "epoch 77 step 700 loss: 3.1331150245666506\n",
      "epoch 77 step 800 loss: 3.146707100868225\n",
      "epoch 77 step 900 loss: 3.1216568994522094\n",
      "epoch 77 step 1000 loss: 3.1529254603385923\n",
      "epoch 77 step 1100 loss: 3.1618506002426146\n",
      "epoch 77 step 1200 loss: 3.1427497100830077\n",
      "epoch 77 step 1300 loss: 3.1730200386047365\n",
      "epoch 77 step 1400 loss: 3.1560822200775145\n",
      "epoch 77 step 1500 loss: 3.180867147445679\n",
      "epoch 77 step 1600 loss: 3.178730788230896\n",
      "epoch 77 step 1700 loss: 3.1941222739219666\n",
      "current lr: 0.0004340627666233599\n",
      "encoder输入: ['人', '离别', '了', '但', '如', '仍然', '一起']\n",
      "decoder输入: ['<go>', '因为', '你', '我', '再', '不', '记挂', '名', '和', '利', '<eos>']\n",
      "target目标: ['因为', '你', '我', '再', '不', '记挂', '名', '和', '利', '<eos>']\n",
      "预测结果: ['我', '我', '我', '都', '给', '记挂', '<eos>', '行', '利', '<eos>']\n",
      "attention:\n",
      " tensor([[3.0772e-01, 3.2751e-01, 8.0481e-02, 1.0353e-01, 6.0124e-02, 9.2387e-02,\n",
      "         2.8240e-02],\n",
      "        [6.8451e-02, 9.8447e-02, 1.2195e-02, 3.5102e-02, 4.9717e-01, 1.7946e-01,\n",
      "         1.0917e-01],\n",
      "        [5.4321e-02, 5.4404e-03, 1.1302e-02, 5.3418e-02, 4.8590e-01, 1.6615e-01,\n",
      "         2.2347e-01],\n",
      "        [5.3936e-02, 2.0506e-01, 1.0048e-01, 1.4938e-01, 7.6310e-02, 3.4763e-01,\n",
      "         6.7201e-02],\n",
      "        [1.6827e-02, 6.8513e-02, 4.4072e-02, 1.6308e-01, 3.8877e-01, 1.6519e-01,\n",
      "         1.5355e-01],\n",
      "        [3.3780e-01, 4.1140e-01, 1.7313e-02, 3.0284e-02, 4.3856e-02, 4.1353e-02,\n",
      "         1.1799e-01],\n",
      "        [5.2757e-01, 8.1765e-02, 1.7068e-01, 8.8888e-02, 8.6512e-02, 1.8302e-02,\n",
      "         2.6280e-02],\n",
      "        [8.1523e-01, 1.2640e-01, 3.0422e-02, 1.1506e-02, 5.1465e-04, 3.9063e-03,\n",
      "         1.2023e-02],\n",
      "        [5.9481e-01, 4.1823e-02, 1.2164e-01, 3.8830e-02, 2.6498e-02, 9.4570e-02,\n",
      "         8.1832e-02],\n",
      "        [9.9213e-01, 6.6244e-03, 1.8306e-04, 1.5870e-04, 2.5932e-04, 1.5636e-04,\n",
      "         4.9104e-04],\n",
      "        [1.0846e-01, 7.9686e-01, 4.7541e-03, 5.8795e-03, 1.2458e-02, 2.9711e-02,\n",
      "         4.1873e-02]], grad_fn=<SelectBackward0>)\n",
      "epoch 78 step 100 loss: 3.0774738502502443\n",
      "epoch 78 step 200 loss: 3.076309416294098\n",
      "epoch 78 step 300 loss: 3.1150690507888794\n",
      "epoch 78 step 400 loss: 3.0984505653381347\n",
      "epoch 78 step 500 loss: 3.1189412760734556\n",
      "epoch 78 step 600 loss: 3.12298047542572\n",
      "epoch 78 step 700 loss: 3.1304275155067445\n",
      "epoch 78 step 800 loss: 3.141317894458771\n",
      "epoch 78 step 900 loss: 3.1310994386672975\n",
      "epoch 78 step 1000 loss: 3.152657310962677\n",
      "epoch 78 step 1100 loss: 3.1622017073631286\n",
      "epoch 78 step 1200 loss: 3.16671359539032\n",
      "epoch 78 step 1300 loss: 3.1495244216918947\n",
      "epoch 78 step 1400 loss: 3.172580668926239\n",
      "epoch 78 step 1500 loss: 3.1475394773483276\n",
      "epoch 78 step 1600 loss: 3.162775535583496\n",
      "epoch 78 step 1700 loss: 3.1698702430725096\n",
      "encoder输入: ['在', '那日', '分手', '你', '讲', '过']\n",
      "decoder输入: ['<go>', '爱', '她', '更', '多', '<eos>']\n",
      "target目标: ['爱', '她', '更', '多', '<eos>']\n",
      "预测结果: ['爱', '你', '<eos>', '多', '<eos>']\n",
      "attention:\n",
      " tensor([[0.3218, 0.2579, 0.0081, 0.0116, 0.0418, 0.3589],\n",
      "        [0.3158, 0.3765, 0.0759, 0.0056, 0.0080, 0.2181],\n",
      "        [0.4078, 0.0989, 0.0260, 0.0378, 0.1133, 0.3162],\n",
      "        [0.2634, 0.1916, 0.0326, 0.0397, 0.2276, 0.2450],\n",
      "        [0.2661, 0.3750, 0.0531, 0.0903, 0.1410, 0.0746],\n",
      "        [0.3127, 0.4882, 0.0347, 0.0436, 0.1020, 0.0188]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 79 step 100 loss: 3.1028176808357237\n",
      "epoch 79 step 200 loss: 3.0494883704185485\n",
      "epoch 79 step 300 loss: 3.0821394109725953\n",
      "epoch 79 step 400 loss: 3.071674416065216\n",
      "epoch 79 step 500 loss: 3.0807880115509034\n",
      "epoch 79 step 600 loss: 3.119105758666992\n",
      "epoch 79 step 700 loss: 3.1062459325790406\n",
      "epoch 79 step 800 loss: 3.112299709320068\n",
      "epoch 79 step 900 loss: 3.1161183524131775\n",
      "epoch 79 step 1000 loss: 3.1190970087051393\n",
      "epoch 79 step 1100 loss: 3.1217320156097412\n",
      "epoch 79 step 1200 loss: 3.1412577724456785\n",
      "epoch 79 step 1300 loss: 3.1360922932624815\n",
      "epoch 79 step 1400 loss: 3.14340439081192\n",
      "epoch 79 step 1500 loss: 3.173523745536804\n",
      "epoch 79 step 1600 loss: 3.1534000062942504\n",
      "epoch 79 step 1700 loss: 3.185480208396912\n",
      "current lr: 0.00042538151129089267\n",
      "encoder输入: ['明日', '复明', '日', '哪', '需', '堆砌', '节目', '燃烧']\n",
      "decoder输入: ['<go>', '你', '不', '差', '差一点', '比', '浸浴', '重要', '<eos>']\n",
      "target目标: ['你', '不', '差', '差一点', '比', '<unk>', '重要', '<eos>']\n",
      "预测结果: ['再', '要', '开心', '唯', '坏', '我', '<eos>', '<eos>']\n",
      "attention:\n",
      " tensor([[2.0753e-01, 6.1477e-02, 1.4065e-01, 2.3625e-01, 1.1917e-01, 4.1034e-02,\n",
      "         1.0197e-01, 9.1924e-02],\n",
      "        [1.8028e-01, 2.0593e-01, 7.3109e-02, 9.6277e-02, 1.6032e-01, 4.6648e-02,\n",
      "         1.4610e-01, 9.1335e-02],\n",
      "        [4.0872e-03, 1.7822e-04, 1.1003e-05, 9.6976e-05, 1.8164e-03, 1.6117e-02,\n",
      "         2.0689e-01, 7.7080e-01],\n",
      "        [7.7013e-01, 1.8747e-01, 9.4278e-03, 4.5324e-04, 8.5074e-04, 1.1487e-03,\n",
      "         1.3720e-02, 1.6800e-02],\n",
      "        [6.9059e-01, 1.8384e-01, 1.9681e-02, 2.1726e-03, 1.8487e-03, 7.5305e-04,\n",
      "         6.6379e-02, 3.4738e-02],\n",
      "        [1.6153e-01, 1.0869e-02, 1.2984e-04, 8.6214e-05, 1.4691e-03, 2.5943e-03,\n",
      "         3.5787e-01, 4.6545e-01],\n",
      "        [1.7965e-02, 4.9659e-03, 1.8387e-03, 1.2445e-03, 1.1849e-02, 6.1141e-03,\n",
      "         6.8615e-01, 2.6988e-01],\n",
      "        [7.1377e-02, 6.9929e-02, 5.9306e-03, 9.3772e-03, 2.6685e-02, 4.9172e-02,\n",
      "         4.8987e-01, 2.7766e-01],\n",
      "        [6.3323e-02, 2.0070e-03, 1.2128e-02, 3.7213e-02, 1.1664e-02, 2.0025e-02,\n",
      "         2.6971e-01, 5.8393e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 80 step 100 loss: 3.1003199863433837\n",
      "epoch 80 step 200 loss: 3.0569297170639036\n",
      "epoch 80 step 300 loss: 3.0931974148750303\n",
      "epoch 80 step 400 loss: 3.059415948390961\n",
      "epoch 80 step 500 loss: 3.09708505153656\n",
      "epoch 80 step 600 loss: 3.1081175351142885\n",
      "epoch 80 step 700 loss: 3.108091378211975\n",
      "epoch 80 step 800 loss: 3.1103221130371095\n",
      "epoch 80 step 900 loss: 3.14128080368042\n",
      "epoch 80 step 1000 loss: 3.1089532351493836\n",
      "epoch 80 step 1100 loss: 3.128493535518646\n",
      "epoch 80 step 1200 loss: 3.12817489862442\n",
      "epoch 80 step 1300 loss: 3.151802833080292\n",
      "epoch 80 step 1400 loss: 3.127303783893585\n",
      "epoch 80 step 1500 loss: 3.154299216270447\n",
      "epoch 80 step 1600 loss: 3.1662653923034667\n",
      "epoch 80 step 1700 loss: 3.1595012855529787\n",
      "encoder输入: ['惊险', '哀怨', '动作', '爱情']\n",
      "decoder输入: ['<go>', '在', '刹那', '随时', '放映', '<eos>']\n",
      "target目标: ['在', '刹那', '随时', '放映', '<eos>']\n",
      "预测结果: ['还', '我心', '开始', '放映', '<eos>']\n",
      "attention:\n",
      " tensor([[3.8875e-02, 1.1034e-01, 6.0990e-01, 2.4088e-01],\n",
      "        [4.9504e-04, 1.0882e-02, 6.6456e-01, 3.2406e-01],\n",
      "        [7.0197e-03, 4.2377e-02, 1.8037e-01, 7.7024e-01],\n",
      "        [2.7241e-03, 9.1327e-02, 1.7765e-01, 7.2830e-01],\n",
      "        [8.7882e-03, 7.0148e-03, 4.4955e-01, 5.3465e-01],\n",
      "        [6.9590e-02, 2.3857e-02, 4.6292e-01, 4.4363e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 81 step 100 loss: 3.0728352856636048\n",
      "epoch 81 step 200 loss: 3.047854173183441\n",
      "epoch 81 step 300 loss: 3.0646770071983336\n",
      "epoch 81 step 400 loss: 3.0473995637893676\n",
      "epoch 81 step 500 loss: 3.076894986629486\n",
      "epoch 81 step 600 loss: 3.0862334847450255\n",
      "epoch 81 step 700 loss: 3.1149704384803774\n",
      "epoch 81 step 800 loss: 3.081800379753113\n",
      "epoch 81 step 900 loss: 3.107953577041626\n",
      "epoch 81 step 1000 loss: 3.116881947517395\n",
      "epoch 81 step 1100 loss: 3.105742268562317\n",
      "epoch 81 step 1200 loss: 3.1216926836967467\n",
      "epoch 81 step 1300 loss: 3.1187845277786255\n",
      "epoch 81 step 1400 loss: 3.1322135090827943\n",
      "epoch 81 step 1500 loss: 3.141445605754852\n",
      "epoch 81 step 1600 loss: 3.142770035266876\n",
      "epoch 81 step 1700 loss: 3.145228705406189\n",
      "current lr: 0.0004168738810650748\n",
      "encoder输入: ['看', '曙光', '天色', '悲哀']\n",
      "decoder输入: ['<go>', '是', '两颗', '心想', '恋', '欠', '未来', '<eos>']\n",
      "target目标: ['是', '两颗', '心想', '恋', '欠', '未来', '<eos>']\n",
      "预测结果: ['我', '两颗', '千亿', '恋', '着', '你', '<eos>']\n",
      "attention:\n",
      " tensor([[0.2464, 0.0501, 0.2464, 0.4570],\n",
      "        [0.0017, 0.0353, 0.4288, 0.5343],\n",
      "        [0.0233, 0.1323, 0.4129, 0.4315],\n",
      "        [0.1443, 0.0082, 0.3057, 0.5418],\n",
      "        [0.3976, 0.0812, 0.4242, 0.0969],\n",
      "        [0.3389, 0.3928, 0.1855, 0.0828],\n",
      "        [0.0615, 0.0196, 0.7372, 0.1817],\n",
      "        [0.0048, 0.0226, 0.6635, 0.3091]], grad_fn=<SelectBackward0>)\n",
      "epoch 82 step 100 loss: 3.0624947810173033\n",
      "epoch 82 step 200 loss: 3.0708399176597596\n",
      "epoch 82 step 300 loss: 3.0484278082847593\n",
      "epoch 82 step 400 loss: 3.077856171131134\n",
      "epoch 82 step 500 loss: 3.1072741198539733\n",
      "epoch 82 step 600 loss: 3.058836555480957\n",
      "epoch 82 step 700 loss: 3.1081090664863584\n",
      "epoch 82 step 800 loss: 3.082693266868591\n",
      "epoch 82 step 900 loss: 3.0874702024459837\n",
      "epoch 82 step 1000 loss: 3.117690541744232\n",
      "epoch 82 step 1100 loss: 3.1020319294929504\n",
      "epoch 82 step 1200 loss: 3.1341128087043764\n",
      "epoch 82 step 1300 loss: 3.1204003882408142\n",
      "epoch 82 step 1400 loss: 3.128819990158081\n",
      "epoch 82 step 1500 loss: 3.138149061203003\n",
      "epoch 82 step 1600 loss: 3.151998610496521\n",
      "epoch 82 step 1700 loss: 3.142446689605713\n",
      "encoder输入: ['爱', '你', '想', '你']\n",
      "decoder输入: ['<go>', '情意', '太', '真挚', '<eos>']\n",
      "target目标: ['情意', '太', '真挚', '<eos>']\n",
      "预测结果: ['我', '爱', '深', '<eos>']\n",
      "attention:\n",
      " tensor([[0.8522, 0.0325, 0.0572, 0.0581],\n",
      "        [0.9625, 0.0017, 0.0301, 0.0057],\n",
      "        [0.8524, 0.1166, 0.0182, 0.0128],\n",
      "        [0.9691, 0.0040, 0.0027, 0.0242],\n",
      "        [0.7813, 0.0587, 0.0866, 0.0734]], grad_fn=<SelectBackward0>)\n",
      "epoch 83 step 100 loss: 3.027409336566925\n",
      "epoch 83 step 200 loss: 3.024411919116974\n",
      "epoch 83 step 300 loss: 3.047876825332642\n",
      "epoch 83 step 400 loss: 3.0612028098106383\n",
      "epoch 83 step 500 loss: 3.0651739692687987\n",
      "epoch 83 step 600 loss: 3.0578780484199526\n",
      "epoch 83 step 700 loss: 3.089502069950104\n",
      "epoch 83 step 800 loss: 3.096360001564026\n",
      "epoch 83 step 900 loss: 3.102017889022827\n",
      "epoch 83 step 1000 loss: 3.094353437423706\n",
      "epoch 83 step 1100 loss: 3.093834848403931\n",
      "epoch 83 step 1200 loss: 3.115650155544281\n",
      "epoch 83 step 1300 loss: 3.1061512184143067\n",
      "epoch 83 step 1400 loss: 3.0940063071250914\n",
      "epoch 83 step 1500 loss: 3.1333964347839354\n",
      "epoch 83 step 1600 loss: 3.1170108413696287\n",
      "epoch 83 step 1700 loss: 3.1299973011016844\n",
      "current lr: 0.00040853640344377327\n",
      "encoder输入: ['属于', '你', '的', '一切都是', '美丽']\n",
      "decoder输入: ['<go>', '我', '相信', '只有', '真心', '能', '永远', '<eos>']\n",
      "target目标: ['我', '相信', '只有', '真心', '能', '永远', '<eos>']\n",
      "预测结果: ['我', '要', '每', '你', '<eos>', '明白', '<eos>']\n",
      "attention:\n",
      " tensor([[0.4542, 0.1650, 0.1366, 0.0979, 0.1464],\n",
      "        [0.0436, 0.4953, 0.1872, 0.2105, 0.0635],\n",
      "        [0.9026, 0.0627, 0.0112, 0.0174, 0.0061],\n",
      "        [0.1577, 0.5827, 0.1239, 0.0391, 0.0966],\n",
      "        [0.5704, 0.2325, 0.0727, 0.0776, 0.0467],\n",
      "        [0.4056, 0.5641, 0.0115, 0.0042, 0.0145],\n",
      "        [0.2395, 0.1211, 0.0410, 0.2352, 0.3631],\n",
      "        [0.1932, 0.0951, 0.0055, 0.1764, 0.5298]], grad_fn=<SelectBackward0>)\n",
      "epoch 84 step 100 loss: 3.0342342329025267\n",
      "epoch 84 step 200 loss: 3.0406905031204223\n",
      "epoch 84 step 300 loss: 3.045989496707916\n",
      "epoch 84 step 400 loss: 3.0449851751327515\n",
      "epoch 84 step 500 loss: 3.091404800415039\n",
      "epoch 84 step 600 loss: 3.0531143021583556\n",
      "epoch 84 step 700 loss: 3.0553940391540526\n",
      "epoch 84 step 800 loss: 3.0943970227241517\n",
      "epoch 84 step 900 loss: 3.0923984336853025\n",
      "epoch 84 step 1000 loss: 3.1117606115341188\n",
      "epoch 84 step 1100 loss: 3.0903518843650817\n",
      "epoch 84 step 1200 loss: 3.115209059715271\n",
      "epoch 84 step 1300 loss: 3.120223922729492\n",
      "epoch 84 step 1400 loss: 3.1185764145851134\n",
      "epoch 84 step 1500 loss: 3.1383069491386415\n",
      "epoch 84 step 1600 loss: 3.126682231426239\n",
      "epoch 84 step 1700 loss: 3.1058830308914183\n",
      "encoder输入: ['余生', '请', '你', '指教']\n",
      "decoder输入: ['<go>', '自古', '大将', '咬着唇', '完成', '战事', '<eos>']\n",
      "target目标: ['自古', '<unk>', '<unk>', '完成', '<unk>', '<eos>']\n",
      "预测结果: ['自古', '共', '与', '你', '<eos>', '<eos>']\n",
      "attention:\n",
      " tensor([[0.6461, 0.2520, 0.0212, 0.0806],\n",
      "        [0.5406, 0.0636, 0.0161, 0.3797],\n",
      "        [0.4890, 0.1484, 0.3326, 0.0300],\n",
      "        [0.1826, 0.0453, 0.0451, 0.7269],\n",
      "        [0.0213, 0.0162, 0.0029, 0.9596],\n",
      "        [0.0955, 0.0401, 0.0610, 0.8034],\n",
      "        [0.0225, 0.0061, 0.0148, 0.9566]], grad_fn=<SelectBackward0>)\n",
      "epoch 85 step 100 loss: 3.0110541915893556\n",
      "epoch 85 step 200 loss: 3.012236490249634\n",
      "epoch 85 step 300 loss: 3.038961911201477\n",
      "epoch 85 step 400 loss: 3.042759563922882\n",
      "epoch 85 step 500 loss: 3.056375346183777\n",
      "epoch 85 step 600 loss: 3.0237648820877077\n",
      "epoch 85 step 700 loss: 3.053634855747223\n",
      "epoch 85 step 800 loss: 3.07419664144516\n",
      "epoch 85 step 900 loss: 3.0608156609535215\n",
      "epoch 85 step 1000 loss: 3.079307343959808\n",
      "epoch 85 step 1100 loss: 3.1065803933143616\n",
      "epoch 85 step 1200 loss: 3.051291003227234\n",
      "epoch 85 step 1300 loss: 3.0916149640083312\n",
      "epoch 85 step 1400 loss: 3.119244062900543\n",
      "epoch 85 step 1500 loss: 3.1089598321914673\n",
      "epoch 85 step 1600 loss: 3.142869749069214\n",
      "epoch 85 step 1700 loss: 3.1182427287101744\n",
      "current lr: 0.0004003656753748978\n",
      "encoder输入: ['用力', '推开', '你']\n",
      "decoder输入: ['<go>', '我', '依然', '留下', '<eos>']\n",
      "target目标: ['我', '依然', '留下', '<eos>']\n",
      "预测结果: ['让', '不想', '永远', '我']\n",
      "attention:\n",
      " tensor([[0.0332, 0.6726, 0.2942],\n",
      "        [0.1537, 0.3848, 0.4615],\n",
      "        [0.0785, 0.3430, 0.5786],\n",
      "        [0.1325, 0.5336, 0.3338],\n",
      "        [0.3779, 0.4683, 0.1538]], grad_fn=<SelectBackward0>)\n",
      "epoch 86 step 100 loss: 3.0236308407783508\n",
      "epoch 86 step 200 loss: 3.009192581176758\n",
      "epoch 86 step 300 loss: 3.0384472942352296\n",
      "epoch 86 step 400 loss: 3.0464168071746824\n",
      "epoch 86 step 500 loss: 3.06602201461792\n",
      "epoch 86 step 600 loss: 3.061878893375397\n",
      "epoch 86 step 700 loss: 3.077510313987732\n",
      "epoch 86 step 800 loss: 3.0853631711006164\n",
      "epoch 86 step 900 loss: 3.060067203044891\n",
      "epoch 86 step 1000 loss: 3.0770892238616945\n",
      "epoch 86 step 1100 loss: 3.0806130456924437\n",
      "epoch 86 step 1200 loss: 3.085281903743744\n",
      "epoch 86 step 1300 loss: 3.097107021808624\n",
      "epoch 86 step 1400 loss: 3.11915855884552\n",
      "epoch 86 step 1500 loss: 3.084274296760559\n",
      "epoch 86 step 1600 loss: 3.0931729102134704\n",
      "epoch 86 step 1700 loss: 3.096420645713806\n",
      "encoder输入: ['机器', '的', '声音', '继续', '呼唤']\n",
      "decoder输入: ['<go>', '在', '网路', '的', '海洋', '找', '不到', '<eos>']\n",
      "target目标: ['在', '<unk>', '的', '海洋', '找', '不到', '<eos>']\n",
      "预测结果: ['我', '你', '的', '世界', '上', '个', '<eos>']\n",
      "attention:\n",
      " tensor([[0.5197, 0.3095, 0.1176, 0.0409, 0.0123],\n",
      "        [0.0203, 0.0347, 0.7711, 0.1633, 0.0108],\n",
      "        [0.6107, 0.0914, 0.0570, 0.1574, 0.0836],\n",
      "        [0.6340, 0.1158, 0.1718, 0.0601, 0.0184],\n",
      "        [0.1885, 0.0282, 0.0436, 0.1402, 0.5995],\n",
      "        [0.0848, 0.0702, 0.3393, 0.3719, 0.1338],\n",
      "        [0.0669, 0.0130, 0.4844, 0.2012, 0.2346],\n",
      "        [0.3709, 0.3018, 0.1422, 0.0529, 0.1323]], grad_fn=<SelectBackward0>)\n",
      "epoch 87 step 100 loss: 3.0231044602394106\n",
      "epoch 87 step 200 loss: 2.9776314234733583\n",
      "epoch 87 step 300 loss: 2.9923046326637266\n",
      "epoch 87 step 400 loss: 3.0207813215255737\n",
      "epoch 87 step 500 loss: 3.0154310035705567\n",
      "epoch 87 step 600 loss: 3.057333917617798\n",
      "epoch 87 step 700 loss: 3.043594253063202\n",
      "epoch 87 step 800 loss: 3.0371041774749754\n",
      "epoch 87 step 900 loss: 3.058300642967224\n",
      "epoch 87 step 1000 loss: 3.0901459145545958\n",
      "epoch 87 step 1100 loss: 3.069793186187744\n",
      "epoch 87 step 1200 loss: 3.089453499317169\n",
      "epoch 87 step 1300 loss: 3.106426615715027\n",
      "epoch 87 step 1400 loss: 3.0707970118522643\n",
      "epoch 87 step 1500 loss: 3.08197762966156\n",
      "epoch 87 step 1600 loss: 3.106204323768616\n",
      "epoch 87 step 1700 loss: 3.0884354066848756\n",
      "current lr: 0.00039235836186739986\n",
      "encoder输入: ['我', '将', '收拾', '行囊', '只', '为', '离开']\n",
      "decoder输入: ['<go>', '离开', '你', '离开', '自己', '<eos>']\n",
      "target目标: ['离开', '你', '离开', '自己', '<eos>']\n",
      "预测结果: ['离开', '你', '离开', '自己', '<eos>']\n",
      "attention:\n",
      " tensor([[0.0249, 0.0079, 0.1525, 0.0829, 0.2123, 0.2594, 0.2602],\n",
      "        [0.0363, 0.0019, 0.1635, 0.1594, 0.0658, 0.2934, 0.2798],\n",
      "        [0.0265, 0.0047, 0.0379, 0.0718, 0.2912, 0.2001, 0.3679],\n",
      "        [0.0492, 0.0037, 0.0695, 0.0330, 0.0559, 0.1556, 0.6331],\n",
      "        [0.0838, 0.0257, 0.1172, 0.0958, 0.3881, 0.1389, 0.1505],\n",
      "        [0.0727, 0.0209, 0.2689, 0.0457, 0.1732, 0.0240, 0.3946]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 88 step 100 loss: 3.023404924869537\n",
      "epoch 88 step 200 loss: 3.0006337785720825\n",
      "epoch 88 step 300 loss: 3.004159400463104\n",
      "epoch 88 step 400 loss: 3.03631751537323\n",
      "epoch 88 step 500 loss: 3.0255034804344176\n",
      "epoch 88 step 600 loss: 3.0547341752052306\n",
      "epoch 88 step 700 loss: 3.0396601152420044\n",
      "epoch 88 step 800 loss: 3.0767820405960085\n",
      "epoch 88 step 900 loss: 3.067979233264923\n",
      "epoch 88 step 1000 loss: 3.0518102192878724\n",
      "epoch 88 step 1100 loss: 3.0472229599952696\n",
      "epoch 88 step 1200 loss: 3.08663788318634\n",
      "epoch 88 step 1300 loss: 3.0755226850509643\n",
      "epoch 88 step 1400 loss: 3.0931382966041565\n",
      "epoch 88 step 1500 loss: 3.083975307941437\n",
      "epoch 88 step 1600 loss: 3.094033806324005\n",
      "epoch 88 step 1700 loss: 3.1113899755477905\n",
      "encoder输入: ['生', '似', '梦', '始终', '会', '深', '叹', '喟']\n",
      "decoder输入: ['<go>', '要是', '你', '我', '一生', '都', '不', '老', '的话', '<eos>']\n",
      "target目标: ['要是', '你', '我', '一生', '都', '不', '老', '的话', '<eos>']\n",
      "预测结果: ['要是', '你', '我', '一生', '都', '不', '老', '的话', '<eos>']\n",
      "attention:\n",
      " tensor([[5.8436e-01, 9.9805e-02, 3.5617e-03, 1.2835e-02, 3.9394e-02, 4.0138e-02,\n",
      "         1.7191e-02, 2.0272e-01],\n",
      "        [3.0594e-01, 5.9019e-02, 6.3582e-03, 8.7665e-02, 1.1299e-01, 2.2115e-01,\n",
      "         9.8725e-02, 1.0816e-01],\n",
      "        [1.0100e-02, 5.7894e-03, 9.2644e-03, 6.8480e-02, 2.0011e-01, 5.4080e-01,\n",
      "         1.0540e-01, 6.0048e-02],\n",
      "        [1.8887e-03, 7.3275e-03, 9.5503e-03, 3.0564e-02, 1.2474e-01, 1.8192e-01,\n",
      "         8.7588e-02, 5.5642e-01],\n",
      "        [2.4061e-01, 1.6265e-02, 7.0388e-03, 4.5440e-03, 5.2622e-02, 1.7737e-01,\n",
      "         1.4654e-01, 3.5501e-01],\n",
      "        [7.2985e-01, 4.8178e-03, 3.8601e-04, 1.2007e-02, 3.0123e-02, 6.4477e-02,\n",
      "         8.3909e-02, 7.4426e-02],\n",
      "        [3.6876e-02, 2.7909e-03, 1.0769e-04, 8.1751e-04, 8.8560e-03, 1.7110e-01,\n",
      "         5.7703e-02, 7.2175e-01],\n",
      "        [6.2587e-01, 1.8833e-01, 6.8419e-03, 8.9685e-03, 6.0191e-03, 5.7465e-02,\n",
      "         4.4953e-02, 6.1556e-02],\n",
      "        [3.3432e-01, 1.8734e-02, 7.4006e-04, 5.3750e-02, 8.2321e-02, 3.4867e-01,\n",
      "         7.4624e-02, 8.6844e-02],\n",
      "        [1.6437e-01, 1.0263e-02, 7.0229e-04, 1.1457e-02, 3.9766e-03, 4.2965e-02,\n",
      "         3.8203e-02, 7.2806e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 89 step 100 loss: 3.0123058772087097\n",
      "epoch 89 step 200 loss: 2.9782169818878175\n",
      "epoch 89 step 300 loss: 3.0004224514961244\n",
      "epoch 89 step 400 loss: 3.023426630496979\n",
      "epoch 89 step 500 loss: 3.0205864095687867\n",
      "epoch 89 step 600 loss: 3.0172026991844176\n",
      "epoch 89 step 700 loss: 3.0298217296600343\n",
      "epoch 89 step 800 loss: 3.038238546848297\n",
      "epoch 89 step 900 loss: 3.035229814052582\n",
      "epoch 89 step 1000 loss: 3.0390542721748353\n",
      "epoch 89 step 1100 loss: 3.052030165195465\n",
      "epoch 89 step 1200 loss: 3.065620973110199\n",
      "epoch 89 step 1300 loss: 3.0709445428848268\n",
      "epoch 89 step 1400 loss: 3.064006052017212\n",
      "epoch 89 step 1500 loss: 3.0707426404953004\n",
      "epoch 89 step 1600 loss: 3.084723725318909\n",
      "epoch 89 step 1700 loss: 3.096074154376984\n",
      "current lr: 0.00038451119463005185\n",
      "encoder输入: ['爱', '不是', '口号', '够', '炫', '就', '好']\n",
      "decoder输入: ['<go>', '不要', '不要', '的', '爱', '到', '你', '求饶', '<eos>']\n",
      "target目标: ['不要', '不要', '的', '爱', '到', '你', '求饶', '<eos>']\n",
      "预测结果: ['爱', '不要', '说', '我', '我', '我', '求饶', '<eos>']\n",
      "attention:\n",
      " tensor([[1.6660e-01, 2.9353e-01, 1.6275e-01, 2.3195e-01, 2.1132e-02, 8.3023e-02,\n",
      "         4.1013e-02],\n",
      "        [2.0962e-01, 3.7141e-01, 8.2481e-02, 1.0231e-01, 3.0176e-02, 1.0581e-01,\n",
      "         9.8193e-02],\n",
      "        [2.1875e-01, 1.1206e-01, 2.4718e-01, 1.7275e-01, 5.8984e-02, 1.2949e-01,\n",
      "         6.0780e-02],\n",
      "        [1.4232e-02, 3.3708e-03, 6.8005e-02, 1.5679e-01, 2.4962e-01, 3.9753e-01,\n",
      "         1.1045e-01],\n",
      "        [2.0569e-02, 2.7538e-03, 1.0568e-03, 1.7593e-02, 1.1402e-01, 6.2125e-01,\n",
      "         2.2276e-01],\n",
      "        [3.2170e-01, 2.6306e-02, 3.5562e-02, 1.5919e-01, 2.3217e-01, 1.7043e-01,\n",
      "         5.4654e-02],\n",
      "        [3.0234e-02, 3.6657e-03, 8.7399e-02, 4.3081e-02, 9.2124e-02, 6.0452e-01,\n",
      "         1.3898e-01],\n",
      "        [1.7998e-02, 9.4333e-04, 1.5821e-02, 4.6654e-02, 9.9296e-02, 6.1188e-01,\n",
      "         2.0741e-01],\n",
      "        [1.7955e-02, 3.9020e-04, 1.1648e-02, 1.1616e-01, 3.1857e-01, 3.5282e-01,\n",
      "         1.8246e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 90 step 100 loss: 3.0149555921554567\n",
      "epoch 90 step 200 loss: 3.01003879070282\n",
      "epoch 90 step 300 loss: 2.9935643577575686\n",
      "epoch 90 step 400 loss: 3.007927300930023\n",
      "epoch 90 step 500 loss: 3.020457162857056\n",
      "epoch 90 step 600 loss: 3.050760769844055\n",
      "epoch 90 step 700 loss: 3.051566867828369\n",
      "epoch 90 step 800 loss: 3.0317694640159605\n",
      "epoch 90 step 900 loss: 3.041348607540131\n",
      "epoch 90 step 1000 loss: 3.06299129486084\n",
      "epoch 90 step 1100 loss: 3.0337285137176515\n",
      "epoch 90 step 1200 loss: 3.041547882556915\n",
      "epoch 90 step 1300 loss: 3.049792447090149\n",
      "epoch 90 step 1400 loss: 3.0669963717460633\n",
      "epoch 90 step 1500 loss: 3.0686298036575317\n",
      "epoch 90 step 1600 loss: 3.097066764831543\n",
      "epoch 90 step 1700 loss: 3.0762152314186095\n",
      "encoder输入: ['这', '趟', '旅行', '若', '算', '开心']\n",
      "decoder输入: ['<go>', '亦', '是', '无', '负', '这', '一生', '<eos>']\n",
      "target目标: ['亦', '是', '无', '负', '这', '一生', '<eos>']\n",
      "预测结果: ['亦', '是', '我', '负', '<eos>', '一生', '<eos>']\n",
      "attention:\n",
      " tensor([[0.0155, 0.0030, 0.0210, 0.3238, 0.3415, 0.2952],\n",
      "        [0.0325, 0.1340, 0.0670, 0.0215, 0.6387, 0.1064],\n",
      "        [0.2688, 0.0131, 0.0821, 0.0544, 0.0556, 0.5260],\n",
      "        [0.0171, 0.0058, 0.8047, 0.0107, 0.0363, 0.1253],\n",
      "        [0.0580, 0.0625, 0.0568, 0.0336, 0.4977, 0.2914],\n",
      "        [0.3408, 0.0986, 0.3675, 0.0191, 0.1370, 0.0371],\n",
      "        [0.3666, 0.0761, 0.4094, 0.1072, 0.0171, 0.0236],\n",
      "        [0.1449, 0.0775, 0.0921, 0.1006, 0.3212, 0.2636]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 91 step 100 loss: 2.9728499007225038\n",
      "epoch 91 step 200 loss: 2.961220667362213\n",
      "epoch 91 step 300 loss: 2.9999722409248353\n",
      "epoch 91 step 400 loss: 2.999633629322052\n",
      "epoch 91 step 500 loss: 2.984134635925293\n",
      "epoch 91 step 600 loss: 3.019039843082428\n",
      "epoch 91 step 700 loss: 3.012216730117798\n",
      "epoch 91 step 800 loss: 3.020054898262024\n",
      "epoch 91 step 900 loss: 3.053728952407837\n",
      "epoch 91 step 1000 loss: 3.0351299953460695\n",
      "epoch 91 step 1100 loss: 3.046529688835144\n",
      "epoch 91 step 1200 loss: 3.0598292899131776\n",
      "epoch 91 step 1300 loss: 3.06379025220871\n",
      "epoch 91 step 1400 loss: 3.053436286449432\n",
      "epoch 91 step 1500 loss: 3.062259404659271\n",
      "epoch 91 step 1600 loss: 3.0604490542411806\n",
      "epoch 91 step 1700 loss: 3.085463054180145\n",
      "current lr: 0.0003768209707374508\n",
      "encoder输入: ['是', '追忆', '的', '趣味']\n",
      "decoder输入: ['<go>', '明天', '当', '我', '想起', '你', '<eos>']\n",
      "target目标: ['明天', '当', '我', '想起', '你', '<eos>']\n",
      "预测结果: ['你', '当', '我', '想起', '你', '<eos>']\n",
      "attention:\n",
      " tensor([[0.9289, 0.0271, 0.0089, 0.0351],\n",
      "        [0.2912, 0.0237, 0.0320, 0.6531],\n",
      "        [0.0162, 0.0039, 0.0669, 0.9130],\n",
      "        [0.0015, 0.0012, 0.0397, 0.9576],\n",
      "        [0.0081, 0.0043, 0.0102, 0.9774],\n",
      "        [0.2566, 0.0512, 0.0310, 0.6611],\n",
      "        [0.0686, 0.0420, 0.0236, 0.8657]], grad_fn=<SelectBackward0>)\n",
      "epoch 92 step 100 loss: 3.0033747863769533\n",
      "epoch 92 step 200 loss: 2.9758976984024046\n",
      "epoch 92 step 300 loss: 2.9910595560073854\n",
      "epoch 92 step 400 loss: 2.9762175822257997\n",
      "epoch 92 step 500 loss: 3.0161764669418334\n",
      "epoch 92 step 600 loss: 3.0256266927719118\n",
      "epoch 92 step 700 loss: 3.0184216403961184\n",
      "epoch 92 step 800 loss: 3.030759422779083\n",
      "epoch 92 step 900 loss: 2.9984891486167906\n",
      "epoch 92 step 1000 loss: 3.02146377325058\n",
      "epoch 92 step 1100 loss: 3.0311639738082885\n",
      "epoch 92 step 1200 loss: 3.0507656383514403\n",
      "epoch 92 step 1300 loss: 3.0609915471076965\n",
      "epoch 92 step 1400 loss: 3.070124936103821\n",
      "epoch 92 step 1500 loss: 3.0741362977027893\n",
      "epoch 92 step 1600 loss: 3.080588712692261\n",
      "epoch 92 step 1700 loss: 3.061796123981476\n",
      "encoder输入: ['其实', '我', '喜欢', '热热闹闹']\n",
      "decoder输入: ['<go>', '当', '心情', '乱糟糟', '我', '沉默', '不', '言', '笑', '<eos>']\n",
      "target目标: ['当', '心情', '<unk>', '我', '沉默', '不', '言', '笑', '<eos>']\n",
      "预测结果: ['都', '我', '太', '<eos>', '觉得', '不', '快乐', '<eos>', '<eos>']\n",
      "attention:\n",
      " tensor([[0.5594, 0.0588, 0.1087, 0.2731],\n",
      "        [0.0231, 0.0287, 0.3949, 0.5533],\n",
      "        [0.0449, 0.0009, 0.4189, 0.5352],\n",
      "        [0.1517, 0.0088, 0.3850, 0.4545],\n",
      "        [0.3225, 0.1068, 0.3767, 0.1940],\n",
      "        [0.3968, 0.1538, 0.1009, 0.3484],\n",
      "        [0.7787, 0.0487, 0.0421, 0.1306],\n",
      "        [0.0303, 0.0656, 0.0802, 0.8238],\n",
      "        [0.8777, 0.0785, 0.0106, 0.0333],\n",
      "        [0.1004, 0.0214, 0.0816, 0.7966]], grad_fn=<SelectBackward0>)\n",
      "epoch 93 step 100 loss: 2.9607510948181153\n",
      "epoch 93 step 200 loss: 2.970190052986145\n",
      "epoch 93 step 300 loss: 2.9678709006309507\n",
      "epoch 93 step 400 loss: 2.993307373523712\n",
      "epoch 93 step 500 loss: 2.984983170032501\n",
      "epoch 93 step 600 loss: 3.0059807300567627\n",
      "epoch 93 step 700 loss: 3.0195491814613344\n",
      "epoch 93 step 800 loss: 3.014567184448242\n",
      "epoch 93 step 900 loss: 3.0375311589241027\n",
      "epoch 93 step 1000 loss: 3.0259771084785463\n",
      "epoch 93 step 1100 loss: 3.0204221272468565\n",
      "epoch 93 step 1200 loss: 3.0346235036849976\n",
      "epoch 93 step 1300 loss: 3.03944709777832\n",
      "epoch 93 step 1400 loss: 3.0461825037002566\n",
      "epoch 93 step 1500 loss: 3.017049939632416\n",
      "epoch 93 step 1600 loss: 3.0581652998924254\n",
      "epoch 93 step 1700 loss: 3.0659538674354554\n",
      "current lr: 0.0003692845513227018\n",
      "encoder输入: ['卖', '馄饨']\n",
      "decoder输入: ['<go>', '卖', '馄饨', '呀', '卖', '馄饨', '<eos>']\n",
      "target目标: ['卖', '馄饨', '呀', '卖', '馄饨', '<eos>']\n",
      "预测结果: ['卖', '馄饨', '<eos>', '<eos>', '馄饨', '<eos>']\n",
      "attention:\n",
      " tensor([[0.0507, 0.9493],\n",
      "        [0.0106, 0.9894],\n",
      "        [0.0975, 0.9025],\n",
      "        [0.0181, 0.9819],\n",
      "        [0.0044, 0.9956],\n",
      "        [0.0624, 0.9376],\n",
      "        [0.0436, 0.9564]], grad_fn=<SelectBackward0>)\n",
      "epoch 94 step 100 loss: 2.9718937373161314\n",
      "epoch 94 step 200 loss: 2.975558204650879\n",
      "epoch 94 step 300 loss: 2.9870099091529845\n",
      "epoch 94 step 400 loss: 2.991753587722778\n",
      "epoch 94 step 500 loss: 3.01561306476593\n",
      "epoch 94 step 600 loss: 3.0199680709838868\n",
      "epoch 94 step 700 loss: 2.9908341097831728\n",
      "epoch 94 step 800 loss: 3.032357428073883\n",
      "epoch 94 step 900 loss: 3.023216550350189\n",
      "epoch 94 step 1000 loss: 3.020989570617676\n",
      "epoch 94 step 1100 loss: 3.0265791845321655\n",
      "epoch 94 step 1200 loss: 3.0328833937644957\n",
      "epoch 94 step 1300 loss: 3.0153869819641113\n",
      "epoch 94 step 1400 loss: 3.028971815109253\n",
      "epoch 94 step 1500 loss: 3.04740939617157\n",
      "epoch 94 step 1600 loss: 3.039672031402588\n",
      "epoch 94 step 1700 loss: 3.0676130199432374\n",
      "encoder输入: ['天', '一半', ' ', '地', '一半']\n",
      "decoder输入: ['<go>', '远方', '是', '谁', '在', '歌唱', '<eos>']\n",
      "target目标: ['远方', '是', '谁', '在', '歌唱', '<eos>']\n",
      "预测结果: ['我', '的', '谁', '在', '这里', '<eos>']\n",
      "attention:\n",
      " tensor([[5.5420e-01, 1.3870e-01, 1.7825e-01, 1.0319e-01, 2.5655e-02],\n",
      "        [6.7902e-02, 8.4065e-02, 4.0476e-01, 3.5637e-01, 8.6908e-02],\n",
      "        [1.9156e-02, 6.5596e-04, 3.5407e-01, 5.0892e-01, 1.1720e-01],\n",
      "        [6.5165e-01, 6.7345e-02, 1.3372e-01, 9.5145e-02, 5.2144e-02],\n",
      "        [3.9725e-01, 2.2559e-02, 5.4102e-02, 3.8438e-01, 1.4171e-01],\n",
      "        [4.7875e-01, 8.3823e-02, 1.8007e-01, 1.2085e-01, 1.3650e-01],\n",
      "        [8.6863e-01, 4.6114e-02, 4.1594e-02, 3.6554e-02, 7.1086e-03]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 95 step 100 loss: 2.935333127975464\n",
      "epoch 95 step 200 loss: 2.956248445510864\n",
      "epoch 95 step 300 loss: 2.9574147200584413\n",
      "epoch 95 step 400 loss: 2.9740162301063537\n",
      "epoch 95 step 500 loss: 2.9915411639213563\n",
      "epoch 95 step 600 loss: 3.0019705295562744\n",
      "epoch 95 step 700 loss: 2.9831185150146484\n",
      "epoch 95 step 800 loss: 3.0063348627090454\n",
      "epoch 95 step 900 loss: 3.012729208469391\n",
      "epoch 95 step 1000 loss: 3.011859357357025\n",
      "epoch 95 step 1100 loss: 3.0328529024124147\n",
      "epoch 95 step 1200 loss: 3.022233130931854\n",
      "epoch 95 step 1300 loss: 3.0136981129646303\n",
      "epoch 95 step 1400 loss: 3.0332131385803223\n",
      "epoch 95 step 1500 loss: 3.028436586856842\n",
      "epoch 95 step 1600 loss: 3.039960422515869\n",
      "epoch 95 step 1700 loss: 3.0509234714508056\n",
      "current lr: 0.00036189886029624774\n",
      "encoder输入: ['诈', '作', '似', '你', '要', '听', '这', '情话']\n",
      "decoder输入: ['<go>', '诈', '作', '似', '要', '听', '这话', '<eos>']\n",
      "target目标: ['诈', '作', '似', '要', '听', '<unk>', '<eos>']\n",
      "预测结果: ['诈', '作', '似', '是', '断', '你', '<eos>']\n",
      "attention:\n",
      " tensor([[2.8674e-01, 7.5161e-02, 3.3622e-02, 1.5699e-01, 1.5101e-01, 1.7527e-01,\n",
      "         7.2744e-02, 4.8454e-02],\n",
      "        [2.9755e-02, 4.1198e-04, 8.7853e-04, 4.8786e-01, 2.9088e-01, 7.1990e-02,\n",
      "         5.8809e-02, 5.9421e-02],\n",
      "        [1.1862e-03, 4.3591e-06, 5.2749e-04, 1.7107e-01, 1.6063e-01, 9.5320e-02,\n",
      "         3.9449e-01, 1.7677e-01],\n",
      "        [9.4743e-05, 7.5164e-07, 7.5546e-05, 3.9520e-02, 1.4651e-01, 1.6433e-01,\n",
      "         4.6757e-01, 1.8191e-01],\n",
      "        [1.5300e-02, 4.9648e-04, 2.6922e-03, 9.6903e-02, 1.0058e-01, 2.6586e-01,\n",
      "         4.0813e-01, 1.1004e-01],\n",
      "        [4.4715e-01, 5.7862e-03, 2.3662e-03, 7.8290e-02, 4.1191e-02, 1.0710e-01,\n",
      "         2.3858e-01, 7.9544e-02],\n",
      "        [5.9722e-01, 6.3423e-03, 8.8368e-04, 4.7131e-03, 8.3197e-03, 2.6895e-01,\n",
      "         8.2858e-02, 3.0714e-02],\n",
      "        [2.2263e-02, 1.3669e-03, 2.3281e-04, 7.4552e-03, 6.1217e-03, 1.2179e-01,\n",
      "         4.4598e-01, 3.9479e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 96 step 100 loss: 2.9777025055885313\n",
      "epoch 96 step 200 loss: 2.9399964690208433\n",
      "epoch 96 step 300 loss: 2.967595899105072\n",
      "epoch 96 step 400 loss: 2.986771080493927\n",
      "epoch 96 step 500 loss: 2.998023200035095\n",
      "epoch 96 step 600 loss: 2.9950572538375853\n",
      "epoch 96 step 700 loss: 3.004447901248932\n",
      "epoch 96 step 800 loss: 2.9897849893569948\n",
      "epoch 96 step 900 loss: 3.0064043378829957\n",
      "epoch 96 step 1000 loss: 3.0090204286575317\n",
      "epoch 96 step 1100 loss: 2.9870807933807373\n",
      "epoch 96 step 1200 loss: 3.0309869289398192\n",
      "epoch 96 step 1300 loss: 3.0180270743370055\n",
      "epoch 96 step 1400 loss: 3.0237663054466246\n",
      "epoch 96 step 1500 loss: 3.0316749024391174\n",
      "epoch 96 step 1600 loss: 3.053883664608002\n",
      "epoch 96 step 1700 loss: 3.043800687789917\n",
      "encoder输入: ['互相', '去', '引导', '来', '伸手', '拥抱']\n",
      "decoder输入: ['<go>', '舞蹈', '亦', '胜', '于', '动粗', '<eos>']\n",
      "target目标: ['舞蹈', '亦', '胜', '于', '<unk>', '<eos>']\n",
      "预测结果: ['舞蹈', '里', '胜', '成', '樽', '<eos>']\n",
      "attention:\n",
      " tensor([[1.6418e-03, 9.2789e-03, 7.4584e-03, 6.6905e-02, 1.1468e-01, 8.0004e-01],\n",
      "        [4.0103e-03, 4.9050e-04, 8.4923e-02, 3.7883e-01, 2.2299e-01, 3.0876e-01],\n",
      "        [4.9582e-03, 5.1287e-03, 1.2755e-02, 4.3716e-02, 4.5708e-02, 8.8773e-01],\n",
      "        [8.5196e-01, 6.0761e-02, 1.4111e-02, 3.8333e-02, 1.8342e-02, 1.6492e-02],\n",
      "        [3.6654e-03, 7.9519e-03, 4.9000e-02, 2.4913e-02, 1.8099e-01, 7.3347e-01],\n",
      "        [1.4823e-02, 1.4757e-02, 5.4073e-02, 4.1076e-03, 3.4182e-02, 8.7806e-01],\n",
      "        [1.1207e-04, 1.1049e-04, 9.0333e-03, 1.1341e-03, 1.2566e-02, 9.7704e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 97 step 100 loss: 2.960288953781128\n",
      "epoch 97 step 200 loss: 2.92507737159729\n",
      "epoch 97 step 300 loss: 2.9698874044418333\n",
      "epoch 97 step 400 loss: 2.9402676844596862\n",
      "epoch 97 step 500 loss: 2.9646846318244933\n",
      "epoch 97 step 600 loss: 2.975601875782013\n",
      "epoch 97 step 700 loss: 2.9893954300880434\n",
      "epoch 97 step 800 loss: 2.995880515575409\n",
      "epoch 97 step 900 loss: 2.9796632432937624\n",
      "epoch 97 step 1000 loss: 3.0005397987365723\n",
      "epoch 97 step 1100 loss: 3.01096529006958\n",
      "epoch 97 step 1200 loss: 2.993171982765198\n",
      "epoch 97 step 1300 loss: 3.021755802631378\n",
      "epoch 97 step 1400 loss: 3.0465815448760987\n",
      "epoch 97 step 1500 loss: 3.012668607234955\n",
      "epoch 97 step 1600 loss: 3.041543438434601\n",
      "epoch 97 step 1700 loss: 3.031123068332672\n",
      "current lr: 0.0003546608830903228\n",
      "encoder输入: ['不理', '路遥', '或', '路', '黑']\n",
      "decoder输入: ['<go>', '都', '根据', '爱', '出发', '<eos>']\n",
      "target目标: ['都', '根据', '爱', '出发', '<eos>']\n",
      "预测结果: ['都', '根据', '爱', '出发', '<eos>']\n",
      "attention:\n",
      " tensor([[0.6749, 0.0596, 0.0915, 0.0307, 0.1434],\n",
      "        [0.0186, 0.0040, 0.0974, 0.0856, 0.7944],\n",
      "        [0.0034, 0.0044, 0.0614, 0.0166, 0.9142],\n",
      "        [0.2577, 0.0167, 0.0256, 0.0170, 0.6830],\n",
      "        [0.0091, 0.0010, 0.0083, 0.0813, 0.9002],\n",
      "        [0.1465, 0.0684, 0.0216, 0.1621, 0.6013]], grad_fn=<SelectBackward0>)\n",
      "epoch 98 step 100 loss: 2.9844699811935427\n",
      "epoch 98 step 200 loss: 2.962751054763794\n",
      "epoch 98 step 300 loss: 2.9586775398254392\n",
      "epoch 98 step 400 loss: 2.9731014370918274\n",
      "epoch 98 step 500 loss: 2.98891987323761\n",
      "epoch 98 step 600 loss: 2.9799899744987486\n",
      "epoch 98 step 700 loss: 2.9809425044059754\n",
      "epoch 98 step 800 loss: 2.9788409662246704\n",
      "epoch 98 step 900 loss: 2.9697183060646055\n",
      "epoch 98 step 1000 loss: 2.994225249290466\n",
      "epoch 98 step 1100 loss: 2.995514748096466\n",
      "epoch 98 step 1200 loss: 3.0034783363342283\n",
      "epoch 98 step 1300 loss: 3.008654546737671\n",
      "epoch 98 step 1400 loss: 3.0145215821266174\n",
      "epoch 98 step 1500 loss: 2.999642152786255\n",
      "epoch 98 step 1600 loss: 3.0361205554008484\n",
      "epoch 98 step 1700 loss: 3.0481908392906187\n",
      "encoder输入: ['是', '一种', '安全', '让', '我', '得到', '睡眠']\n",
      "decoder输入: ['<go>', '是', '一种', '妥协', '变成', '一种', '浪费', '<eos>']\n",
      "target目标: ['是', '一种', '妥协', '变成', '一种', '浪费', '<eos>']\n",
      "预测结果: ['是', '一种', '妥协', '让', '一种', '浪费', '<eos>']\n",
      "attention:\n",
      " tensor([[4.2687e-01, 4.1055e-02, 1.2658e-01, 6.2960e-02, 1.9628e-02, 1.7633e-01,\n",
      "         1.4657e-01],\n",
      "        [6.7294e-03, 1.8771e-02, 6.1072e-01, 4.0221e-02, 2.0224e-02, 1.1780e-02,\n",
      "         2.9155e-01],\n",
      "        [3.1701e-03, 2.3316e-03, 7.0514e-02, 5.6642e-01, 1.0380e-01, 2.5691e-02,\n",
      "         2.2808e-01],\n",
      "        [2.7912e-01, 4.2777e-02, 6.2584e-02, 5.6847e-02, 4.3157e-02, 3.3807e-01,\n",
      "         1.7744e-01],\n",
      "        [2.7543e-02, 2.9318e-02, 5.2344e-03, 6.1839e-03, 3.5974e-02, 4.6865e-01,\n",
      "         4.2710e-01],\n",
      "        [5.9345e-04, 5.9347e-03, 1.2192e-02, 1.5900e-02, 1.2541e-01, 5.8359e-02,\n",
      "         7.8161e-01],\n",
      "        [1.2612e-01, 5.1915e-02, 4.4788e-02, 1.2157e-01, 8.8662e-02, 2.5137e-01,\n",
      "         3.1558e-01],\n",
      "        [1.0659e-02, 3.1616e-03, 1.6376e-02, 5.9125e-03, 7.1828e-02, 6.0195e-02,\n",
      "         8.3187e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 99 step 100 loss: 2.9288095951080324\n",
      "epoch 99 step 200 loss: 2.9288074517250062\n",
      "epoch 99 step 300 loss: 2.953039047718048\n",
      "epoch 99 step 400 loss: 2.930614128112793\n",
      "epoch 99 step 500 loss: 2.955894181728363\n",
      "epoch 99 step 600 loss: 2.9619076800346376\n",
      "epoch 99 step 700 loss: 2.966757528781891\n",
      "epoch 99 step 800 loss: 2.9787043356895446\n",
      "epoch 99 step 900 loss: 2.9775202250480652\n",
      "epoch 99 step 1000 loss: 3.006672053337097\n",
      "epoch 99 step 1100 loss: 2.9811976838111875\n",
      "epoch 99 step 1200 loss: 2.983212180137634\n",
      "epoch 99 step 1300 loss: 2.992186813354492\n",
      "epoch 99 step 1400 loss: 3.0145253920555115\n",
      "epoch 99 step 1500 loss: 3.021314182281494\n",
      "epoch 99 step 1600 loss: 3.029716441631317\n",
      "epoch 99 step 1700 loss: 3.0376523184776305\n",
      "current lr: 0.00034756766542851634\n",
      "encoder输入: ['年轻', '的', '人们', '消逝', '在', '白桦林']\n",
      "decoder输入: ['<go>', '长长的', '路', '呀', '就要', '到', '尽头', '<eos>']\n",
      "target目标: ['长长的', '路', '呀', '就要', '到', '尽头', '<eos>']\n",
      "预测结果: ['我', '翅膀', '的', '没', '走', '海边', '<eos>']\n",
      "attention:\n",
      " tensor([[0.2518, 0.0744, 0.0560, 0.0560, 0.4604, 0.1014],\n",
      "        [0.0798, 0.4158, 0.2008, 0.2313, 0.0453, 0.0269],\n",
      "        [0.0031, 0.0225, 0.0258, 0.0745, 0.5440, 0.3302],\n",
      "        [0.5022, 0.1527, 0.0317, 0.0160, 0.1755, 0.1218],\n",
      "        [0.1478, 0.0494, 0.0257, 0.1485, 0.3120, 0.3166],\n",
      "        [0.1888, 0.0561, 0.1319, 0.0527, 0.2702, 0.3004],\n",
      "        [0.0181, 0.0232, 0.0228, 0.0414, 0.2752, 0.6193],\n",
      "        [0.0239, 0.0135, 0.0080, 0.0341, 0.2579, 0.6627]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 100 step 100 loss: 2.9528048539161684\n",
      "epoch 100 step 200 loss: 2.9369875311851503\n",
      "epoch 100 step 300 loss: 2.942941174507141\n",
      "epoch 100 step 400 loss: 2.952206921577454\n",
      "epoch 100 step 500 loss: 2.947975306510925\n",
      "epoch 100 step 600 loss: 2.9436341071128846\n",
      "epoch 100 step 700 loss: 2.96046044588089\n",
      "epoch 100 step 800 loss: 2.9936004948616026\n",
      "epoch 100 step 900 loss: 2.9775194764137267\n",
      "epoch 100 step 1000 loss: 2.979258134365082\n",
      "epoch 100 step 1100 loss: 3.003116931915283\n",
      "epoch 100 step 1200 loss: 3.0161413288116456\n",
      "epoch 100 step 1300 loss: 3.010411219596863\n",
      "epoch 100 step 1400 loss: 3.0247555065155027\n",
      "epoch 100 step 1500 loss: 2.9940504026412964\n",
      "epoch 100 step 1600 loss: 3.0081771397590638\n",
      "epoch 100 step 1700 loss: 3.01769513130188\n"
     ]
    }
   ],
   "source": [
    "%run pretrain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine tune:果味VC\n",
      "the latest pre-trained model is pre_trained_100.pkl\n",
      "current lr: 0.00049\n",
      "encoder输入: ['今天', '是', '我', '仅', '有', '的', '时间']\n",
      "decoder输入: ['<go>', '只', '想', '让', '你', '看见', '<eos>']\n",
      "target目标: ['只', '想', '让', '你', '看见', '<eos>']\n",
      "预测结果: ['就', '怪', '给', '我', '走进', '<eos>']\n",
      "attention:\n",
      " tensor([[1.4539e-01, 4.5323e-01, 9.8325e-02, 6.8567e-02, 7.8672e-02, 9.4255e-02,\n",
      "         6.1564e-02],\n",
      "        [2.1552e-01, 2.8486e-02, 2.5662e-02, 4.0326e-04, 1.8938e-03, 2.1950e-02,\n",
      "         7.0608e-01],\n",
      "        [1.0507e-01, 1.1845e-01, 1.4266e-01, 1.1328e-02, 8.0684e-02, 1.1004e-01,\n",
      "         4.3178e-01],\n",
      "        [3.0657e-01, 2.6326e-02, 8.1965e-02, 2.5562e-02, 5.6993e-02, 1.9656e-01,\n",
      "         3.0602e-01],\n",
      "        [8.6273e-02, 4.2171e-01, 2.8374e-02, 1.3539e-02, 9.2261e-02, 1.6900e-01,\n",
      "         1.8885e-01],\n",
      "        [4.7399e-01, 1.0125e-01, 1.0375e-02, 9.7308e-04, 1.4167e-02, 2.1560e-02,\n",
      "         3.7768e-01],\n",
      "        [6.1339e-01, 2.1209e-01, 1.2599e-02, 8.0403e-04, 4.3212e-03, 7.1483e-02,\n",
      "         8.5313e-02]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00048019999999999996\n",
      "current lr: 0.00047059599999999994\n",
      "encoder输入: ['是', '怎么', '叫', '你']\n",
      "decoder输入: ['<go>', '我', '带', '着', '你', '去', '看', '海', '<eos>']\n",
      "target目标: ['我', '带', '着', '你', '去', '看', '海', '<eos>']\n",
      "预测结果: ['我', '的', '着', '你', '走', '看', '海', '<eos>']\n",
      "attention:\n",
      " tensor([[0.7013, 0.1748, 0.0585, 0.0654],\n",
      "        [0.0200, 0.1803, 0.2436, 0.5561],\n",
      "        [0.6215, 0.0435, 0.1202, 0.2149],\n",
      "        [0.6254, 0.3241, 0.0228, 0.0277],\n",
      "        [0.4283, 0.4778, 0.0773, 0.0167],\n",
      "        [0.8904, 0.0855, 0.0134, 0.0107],\n",
      "        [0.9367, 0.0117, 0.0011, 0.0505],\n",
      "        [0.2121, 0.4600, 0.0093, 0.3185],\n",
      "        [0.0182, 0.0097, 0.0064, 0.9657]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.0004611840799999999\n",
      "current lr: 0.0004519603983999999\n",
      "current lr: 0.0004429211904319999\n",
      "encoder输入: ['还', '没有', '被', '发现']\n",
      "decoder输入: ['<go>', '如果', '<eos>']\n",
      "target目标: ['如果', '<eos>']\n",
      "预测结果: ['却', '你']\n",
      "attention:\n",
      " tensor([[0.7312, 0.1528, 0.0657, 0.0504],\n",
      "        [0.1471, 0.0383, 0.2365, 0.5781],\n",
      "        [0.2247, 0.0343, 0.2591, 0.4820]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.0004340627666233599\n",
      "current lr: 0.00042538151129089267\n",
      "encoder输入: ['所谓', '的', '失去', '我们', '都', '曾经', '失去']\n",
      "decoder输入: ['<go>', '遗忘', '中', '途经', '将', '到', '的', '海景', '<eos>']\n",
      "target目标: ['遗忘', '中', '<unk>', '将', '到', '的', '<unk>', '<eos>']\n",
      "预测结果: ['所有', '了', '逐渐', '的', '悲伤', '的', '相遇', '<eos>']\n",
      "attention:\n",
      " tensor([[0.3676, 0.3572, 0.0283, 0.0543, 0.0350, 0.1214, 0.0361],\n",
      "        [0.1518, 0.1056, 0.0608, 0.3439, 0.2153, 0.0682, 0.0544],\n",
      "        [0.5485, 0.1485, 0.0672, 0.0806, 0.0737, 0.0194, 0.0620],\n",
      "        [0.0730, 0.1539, 0.0949, 0.0560, 0.1679, 0.1624, 0.2919],\n",
      "        [0.4123, 0.1198, 0.3762, 0.0219, 0.0140, 0.0316, 0.0242],\n",
      "        [0.0812, 0.0316, 0.0245, 0.0321, 0.1607, 0.2470, 0.4229],\n",
      "        [0.0092, 0.0069, 0.2234, 0.0967, 0.2843, 0.1777, 0.2018],\n",
      "        [0.0019, 0.0021, 0.0283, 0.1315, 0.3071, 0.1538, 0.3751],\n",
      "        [0.0591, 0.0064, 0.0271, 0.3368, 0.0892, 0.4044, 0.0770]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "current lr: 0.0004168738810650748\n",
      "current lr: 0.00040853640344377327\n",
      "current lr: 0.0004003656753748978\n",
      "encoder输入: ['繁华', '的', '夜']\n",
      "decoder输入: ['<go>', '失眠', '的', '街', '<eos>']\n",
      "target目标: ['失眠', '的', '街', '<eos>']\n",
      "预测结果: ['失眠', '的', '街', '<eos>']\n",
      "attention:\n",
      " tensor([[0.3943, 0.5613, 0.0445],\n",
      "        [0.1456, 0.5479, 0.3065],\n",
      "        [0.5224, 0.4691, 0.0085],\n",
      "        [0.3218, 0.5568, 0.1214],\n",
      "        [0.6990, 0.2689, 0.0321]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00039235836186739986\n",
      "current lr: 0.00038451119463005185\n",
      "encoder输入: ['你', '没', '放弃', '我']\n",
      "decoder输入: ['<go>', '不', '坚定', '的', '心', '<eos>']\n",
      "target目标: ['不', '坚定', '的', '心', '<eos>']\n",
      "预测结果: ['指引', '坚定', '的', '心', '<eos>']\n",
      "attention:\n",
      " tensor([[9.4975e-02, 2.2538e-02, 8.0952e-01, 7.2964e-02],\n",
      "        [9.7543e-03, 2.7223e-05, 9.8734e-01, 2.8759e-03],\n",
      "        [8.7343e-01, 2.8996e-03, 7.9876e-02, 4.3790e-02],\n",
      "        [9.7428e-01, 3.0486e-03, 2.0731e-02, 1.9413e-03],\n",
      "        [1.2899e-01, 1.8405e-02, 8.3716e-01, 1.5451e-02],\n",
      "        [7.6316e-01, 1.7405e-03, 1.6667e-01, 6.8430e-02]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "current lr: 0.0003768209707374508\n",
      "current lr: 0.0003692845513227018\n",
      "current lr: 0.00036189886029624774\n",
      "encoder输入: ['十月', '的', '保守派']\n",
      "decoder输入: ['<go>', '一个', '诙谐', '的', '主义', '让', '你', '燃烧', '<eos>']\n",
      "target目标: ['一个', '<unk>', '的', '主义', '让', '你', '燃烧', '<eos>']\n",
      "预测结果: ['一个', '人', '的', '主义', '让', '你', '燃烧', '<eos>']\n",
      "attention:\n",
      " tensor([[0.9080, 0.0212, 0.0708],\n",
      "        [0.0198, 0.0103, 0.9699],\n",
      "        [0.8765, 0.0960, 0.0275],\n",
      "        [0.4934, 0.1249, 0.3817],\n",
      "        [0.9694, 0.0246, 0.0061],\n",
      "        [0.0423, 0.0274, 0.9303],\n",
      "        [0.9333, 0.0348, 0.0319],\n",
      "        [0.0875, 0.0127, 0.8998],\n",
      "        [0.5968, 0.0167, 0.3864]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.0003546608830903228\n",
      "current lr: 0.00034756766542851634\n",
      "encoder输入: ['被', '柔光', '包围', '中']\n",
      "decoder输入: ['<go>', '你', '的', '呼吸', '怎么', '能够', '听不清', '<eos>']\n",
      "target目标: ['你', '的', '呼吸', '怎么', '能够', '听不清', '<eos>']\n",
      "预测结果: ['你', '的', '呼吸', '怎么', '能够', '听不清', '<eos>']\n",
      "attention:\n",
      " tensor([[0.2262, 0.1796, 0.3343, 0.2599],\n",
      "        [0.2185, 0.0561, 0.1095, 0.6160],\n",
      "        [0.0421, 0.0295, 0.7879, 0.1404],\n",
      "        [0.9184, 0.0510, 0.0176, 0.0130],\n",
      "        [0.3412, 0.4970, 0.0794, 0.0824],\n",
      "        [0.9094, 0.0207, 0.0316, 0.0383],\n",
      "        [0.0797, 0.2046, 0.4260, 0.2897],\n",
      "        [0.2528, 0.1468, 0.0489, 0.5515]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.000340616312119946\n",
      "current lr: 0.0003338039858775471\n",
      "current lr: 0.0003271279061599962\n",
      "encoder输入: ['从未', '开始', '失去', '意义']\n",
      "decoder输入: ['<go>', '日出', '之前', '<eos>']\n",
      "target目标: ['日出', '之前', '<eos>']\n",
      "预测结果: ['日出', '之前', '<eos>']\n",
      "attention:\n",
      " tensor([[5.3746e-01, 3.3463e-01, 1.4949e-03, 1.2642e-01],\n",
      "        [5.4019e-01, 4.5375e-01, 2.8831e-03, 3.1752e-03],\n",
      "        [1.3259e-01, 2.7414e-02, 4.7251e-02, 7.9274e-01],\n",
      "        [8.6436e-01, 8.1346e-03, 8.5603e-04, 1.2665e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00032058534803679624\n",
      "current lr: 0.0003141736410760603\n",
      "encoder输入: ['谈', '过', '很多', '梦想']\n",
      "decoder输入: ['<go>', '也许', '再次', '相见', '<eos>']\n",
      "target目标: ['也许', '再次', '相见', '<eos>']\n",
      "预测结果: ['也许', '再次', '相见', '<eos>']\n",
      "attention:\n",
      " tensor([[9.9070e-01, 7.2358e-03, 3.6452e-04, 1.7042e-03],\n",
      "        [2.0531e-02, 2.4231e-02, 3.5373e-01, 6.0150e-01],\n",
      "        [9.3888e-02, 1.1005e-02, 1.4915e-03, 8.9362e-01],\n",
      "        [9.9095e-01, 4.4496e-03, 7.3434e-05, 4.5250e-03],\n",
      "        [9.5843e-01, 1.5695e-02, 6.2327e-04, 2.5249e-02]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "current lr: 0.0003078901682545391\n",
      "current lr: 0.00030173236488944833\n",
      "current lr: 0.00029569771759165936\n",
      "encoder输入: ['爱', '终', '有', '一天', '会', '拯救', '我', '所有', '恐惧']\n",
      "decoder输入: ['<go>', '就', '像', '你', '对', '我', '期待', '的', '一样', '<eos>']\n",
      "target目标: ['就', '像', '你', '对', '我', '期待', '的', '一样', '<eos>']\n",
      "预测结果: ['就', '像', '你', '对', '我', '期待', '的', '一样', '<eos>']\n",
      "attention:\n",
      " tensor([[2.4100e-02, 5.8853e-02, 1.9855e-01, 7.2114e-03, 3.1144e-02, 5.2793e-01,\n",
      "         4.9097e-02, 3.4357e-02, 6.8756e-02],\n",
      "        [2.9189e-02, 1.6390e-03, 6.1240e-04, 3.3094e-02, 1.7693e-03, 5.2954e-01,\n",
      "         1.0974e-01, 3.6953e-02, 2.5746e-01],\n",
      "        [6.6721e-03, 2.8123e-04, 1.3656e-04, 9.2261e-03, 1.6681e-02, 5.6943e-01,\n",
      "         1.3271e-02, 6.0603e-02, 3.2370e-01],\n",
      "        [9.8768e-03, 3.1554e-02, 2.3816e-02, 1.1039e-02, 3.1297e-02, 4.2114e-01,\n",
      "         6.0954e-02, 8.0505e-02, 3.2982e-01],\n",
      "        [1.6380e-03, 6.4599e-04, 4.0569e-03, 3.3804e-03, 3.2668e-02, 7.1720e-01,\n",
      "         1.5148e-01, 4.2032e-02, 4.6901e-02],\n",
      "        [8.9866e-01, 5.9898e-02, 2.6620e-02, 3.1447e-03, 3.1513e-03, 2.9144e-03,\n",
      "         3.0071e-03, 8.4777e-04, 1.7563e-03],\n",
      "        [2.7166e-01, 2.9014e-01, 5.9386e-02, 3.3088e-03, 3.0351e-02, 1.0773e-01,\n",
      "         1.4996e-01, 3.6846e-02, 5.0616e-02],\n",
      "        [1.2782e-02, 4.3232e-02, 2.0924e-03, 8.1421e-02, 4.3387e-02, 7.4193e-01,\n",
      "         9.4457e-03, 1.3340e-02, 5.2368e-02],\n",
      "        [1.2444e-01, 3.6677e-02, 7.0210e-02, 1.4401e-01, 7.7840e-02, 3.6946e-01,\n",
      "         8.9557e-02, 4.1414e-02, 4.6398e-02],\n",
      "        [4.0295e-01, 9.2389e-03, 4.1200e-03, 8.9583e-03, 1.6069e-02, 2.8751e-01,\n",
      "         1.9035e-01, 2.5314e-02, 5.5484e-02]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00028978376323982616\n",
      "current lr: 0.00028398808797502965\n",
      "encoder输入: ['光亮', '虽', '黯淡', '不', '独自', '等待']\n",
      "decoder输入: ['<go>', '生命', '之', '花', '把', '我们', '照亮', '<eos>']\n",
      "target目标: ['生命', '之', '花', '把', '我们', '照亮', '<eos>']\n",
      "预测结果: ['生命', '之', '花', '把', '我们', '照亮', '<eos>']\n",
      "attention:\n",
      " tensor([[0.0114, 0.0058, 0.0151, 0.2135, 0.6841, 0.0701],\n",
      "        [0.0424, 0.0951, 0.2481, 0.1520, 0.2469, 0.2154],\n",
      "        [0.2216, 0.7129, 0.0112, 0.0074, 0.0322, 0.0148],\n",
      "        [0.8687, 0.1055, 0.0038, 0.0016, 0.0069, 0.0136],\n",
      "        [0.4073, 0.4533, 0.0102, 0.0733, 0.0315, 0.0243],\n",
      "        [0.3104, 0.4184, 0.1232, 0.0911, 0.0412, 0.0157],\n",
      "        [0.0060, 0.0019, 0.0014, 0.0043, 0.4233, 0.5631],\n",
      "        [0.0426, 0.2929, 0.0910, 0.0856, 0.3569, 0.1310]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00027830832621552904\n",
      "current lr: 0.00027274215969121844\n",
      "current lr: 0.00026728731649739405\n",
      "encoder输入: ['陌生', '的', '眼睛']\n",
      "decoder输入: ['<go>', '在', '柔光', '世界', '中', '<eos>']\n",
      "target目标: ['在', '<unk>', '世界', '中', '<eos>']\n",
      "预测结果: ['在', '我', '世界', '中', '<eos>']\n",
      "attention:\n",
      " tensor([[0.8234, 0.1603, 0.0163],\n",
      "        [0.0115, 0.0121, 0.9764],\n",
      "        [0.2967, 0.5622, 0.1411],\n",
      "        [0.9599, 0.0118, 0.0283],\n",
      "        [0.1375, 0.0447, 0.8178],\n",
      "        [0.8835, 0.0716, 0.0449]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00026194157016744615\n",
      "current lr: 0.00025670273876409724\n",
      "encoder输入: ['无限', '空间', '空间', '空间']\n",
      "decoder输入: ['<go>', '她', '笑', '的', '好', '灿烂', '<eos>']\n",
      "target目标: ['她', '笑', '的', '好', '灿烂', '<eos>']\n",
      "预测结果: ['她', '笑', '的', '好', '灿烂', '<eos>']\n",
      "attention:\n",
      " tensor([[0.6165, 0.1215, 0.1946, 0.0674],\n",
      "        [0.0028, 0.1783, 0.6126, 0.2062],\n",
      "        [0.7621, 0.0881, 0.0839, 0.0659],\n",
      "        [0.3482, 0.1227, 0.3782, 0.1510],\n",
      "        [0.3773, 0.1371, 0.0632, 0.4224],\n",
      "        [0.0073, 0.0494, 0.1753, 0.7679],\n",
      "        [0.3866, 0.1005, 0.2745, 0.2383]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00025156868398881527\n",
      "current lr: 0.00024653731030903895\n",
      "current lr: 0.00024160656410285818\n",
      "encoder输入: ['在', '你', '世界']\n",
      "decoder输入: ['<go>', '让', '我', '消失', '已', '来不及', '<eos>']\n",
      "target目标: ['让', '我', '消失', '已', '来不及', '<eos>']\n",
      "预测结果: ['让', '我', '消失', '已', '来不及', '<eos>']\n",
      "attention:\n",
      " tensor([[0.9406, 0.0533, 0.0062],\n",
      "        [0.4225, 0.0764, 0.5011],\n",
      "        [0.0636, 0.0324, 0.9039],\n",
      "        [0.0032, 0.0174, 0.9794],\n",
      "        [0.1310, 0.4256, 0.4434],\n",
      "        [0.3023, 0.0127, 0.6850],\n",
      "        [0.6138, 0.1357, 0.2505]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00023677443282080102\n",
      "current lr: 0.000232038944164385\n",
      "encoder输入: ['键入', '希望', '在', '我', '的', '心里']\n",
      "decoder输入: ['<go>', '躺', '在', '被', '你', '装饰', '的', '房间', '<eos>']\n",
      "target目标: ['躺', '在', '被', '你', '装饰', '的', '房间', '<eos>']\n",
      "预测结果: ['躺', '在', '被', '你', '装饰', '的', '房间', '<eos>']\n",
      "attention:\n",
      " tensor([[4.2873e-01, 6.9160e-02, 1.2498e-02, 7.7751e-02, 9.4134e-02, 3.1773e-01],\n",
      "        [7.6292e-01, 8.9567e-02, 9.4752e-03, 6.9336e-02, 6.7747e-03, 6.1930e-02],\n",
      "        [6.8435e-03, 3.1793e-04, 1.6846e-03, 5.0346e-03, 5.3777e-02, 9.3234e-01],\n",
      "        [8.7903e-03, 1.7683e-03, 1.3435e-03, 7.9079e-03, 8.0517e-02, 8.9967e-01],\n",
      "        [3.9002e-01, 1.9132e-02, 6.9853e-02, 3.8538e-02, 2.4075e-02, 4.5838e-01],\n",
      "        [1.3101e-01, 3.9096e-03, 4.4511e-03, 4.8935e-02, 5.9794e-02, 7.5190e-01],\n",
      "        [1.7623e-01, 5.0104e-02, 9.6407e-03, 4.5869e-02, 5.1258e-02, 6.6690e-01],\n",
      "        [9.1912e-02, 8.3257e-03, 7.2230e-04, 2.1209e-02, 2.6240e-02, 8.5159e-01],\n",
      "        [8.1802e-01, 6.9726e-02, 1.3392e-02, 2.4605e-02, 3.7566e-02, 3.6696e-02]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "current lr: 0.0002273981652810973\n",
      "current lr: 0.00022285020197547535\n",
      "current lr: 0.00021839319793596584\n",
      "encoder输入: ['迷失', '在', '彼此', '的', '路']\n",
      "decoder输入: ['<go>', '我', '带', '着', '你', '去', '看', '海', '<eos>']\n",
      "target目标: ['我', '带', '着', '你', '去', '看', '海', '<eos>']\n",
      "预测结果: ['我', '带', '着', '你', '去', '看', '海', '<eos>']\n",
      "attention:\n",
      " tensor([[0.6400, 0.1568, 0.0564, 0.0197, 0.1272],\n",
      "        [0.8438, 0.0135, 0.0603, 0.0039, 0.0785],\n",
      "        [0.6178, 0.2462, 0.0686, 0.0044, 0.0631],\n",
      "        [0.2320, 0.1097, 0.3071, 0.0208, 0.3303],\n",
      "        [0.1637, 0.2419, 0.1632, 0.0567, 0.3746],\n",
      "        [0.2728, 0.0707, 0.1508, 0.0588, 0.4469],\n",
      "        [0.9079, 0.0225, 0.0089, 0.0030, 0.0577],\n",
      "        [0.1151, 0.0108, 0.0704, 0.0831, 0.7205],\n",
      "        [0.7249, 0.0250, 0.1075, 0.0261, 0.1165]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00021402533397724653\n",
      "current lr: 0.0002097448272977016\n",
      "encoder输入: ['也许', '分开', '之前']\n",
      "decoder输入: ['<go>', '谈', '过', '很多', '梦想', '<eos>']\n",
      "target目标: ['谈', '过', '很多', '梦想', '<eos>']\n",
      "预测结果: ['谈', '过', '很多', '梦想', '<eos>']\n",
      "attention:\n",
      " tensor([[0.6538, 0.3168, 0.0294],\n",
      "        [0.0313, 0.0256, 0.9430],\n",
      "        [0.1882, 0.3544, 0.4574],\n",
      "        [0.8253, 0.1337, 0.0410],\n",
      "        [0.0121, 0.8095, 0.1784],\n",
      "        [0.8325, 0.1418, 0.0257]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00020554993075174756\n",
      "current lr: 0.00020143893213671262\n",
      "current lr: 0.00019741015349397837\n",
      "encoder输入: ['神', '的', '声响']\n",
      "decoder输入: ['<go>', '神', '的', '<eos>']\n",
      "target目标: ['神', '的', '<eos>']\n",
      "预测结果: ['神', '的', '<eos>']\n",
      "attention:\n",
      " tensor([[0.1571, 0.0031, 0.8398],\n",
      "        [0.9243, 0.0298, 0.0459],\n",
      "        [0.0946, 0.0066, 0.8987],\n",
      "        [0.8460, 0.0616, 0.0923]], grad_fn=<SelectBackward0>)\n",
      "current lr: 0.0001934619504240988\n",
      "current lr: 0.0001895927114156168\n",
      "encoder输入: ['再见', '孤独', '的', '心']\n",
      "decoder输入: ['<go>', '只', '为', '遇见', '你', '<eos>']\n",
      "target目标: ['只', '为', '遇见', '你', '<eos>']\n",
      "预测结果: ['再见', '为', '遇见', '你', '<eos>']\n",
      "attention:\n",
      " tensor([[8.8964e-01, 2.6829e-02, 7.1158e-02, 1.2374e-02],\n",
      "        [1.9892e-04, 6.1062e-04, 1.0439e-01, 8.9480e-01],\n",
      "        [1.0956e-02, 3.5629e-02, 8.9188e-01, 6.1538e-02],\n",
      "        [3.7516e-05, 1.2428e-04, 1.9795e-01, 8.0189e-01],\n",
      "        [1.5572e-01, 9.0859e-02, 5.5096e-02, 6.9833e-01],\n",
      "        [5.0549e-01, 2.9620e-01, 4.2017e-02, 1.5629e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "current lr: 0.00018580085718730447\n",
      "current lr: 0.00018208484004355837\n",
      "current lr: 0.0001784431432426872\n",
      "encoder输入: ['被', '天使', '的', '眼']\n",
      "decoder输入: ['<go>', '看见', '<eos>']\n",
      "target目标: ['看见', '<eos>']\n",
      "预测结果: ['看见', '<eos>']\n",
      "attention:\n",
      " tensor([[0.1438, 0.0060, 0.0695, 0.7807],\n",
      "        [0.0107, 0.0060, 0.0127, 0.9706],\n",
      "        [0.0234, 0.0095, 0.0960, 0.8711]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "%run supervc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "fine tune:邓丽君\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\SLEEPY~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.853 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the latest pre-trained model is pre_trained_100.pkl\n",
      "current lr: 0.00049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sleepyard\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\nn\\functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder输入: ['飞翔', '呀', '飞翔']\n",
      "decoder输入: ['<go>', '飞', '在', '蓝天', '上', '<eos>']\n",
      "target目标: ['飞', '在', '蓝天', '上', '<eos>']\n",
      "预测结果: ['飞', '在', '原野', '上', '<eos>']\n",
      "attention:\n",
      " tensor([[9.0089e-03, 2.8596e-04, 9.9071e-01],\n",
      "        [5.4079e-02, 5.0684e-02, 8.9524e-01],\n",
      "        [3.3382e-02, 2.4813e-02, 9.4181e-01],\n",
      "        [1.9501e-01, 1.2797e-01, 6.7701e-01],\n",
      "        [8.9923e-01, 2.5456e-02, 7.5313e-02],\n",
      "        [8.0023e-01, 1.3270e-02, 1.8650e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 0 step 5 loss: 2.7469042778015136\n",
      "epoch 0 step 10 loss: 2.220359373092651\n",
      "epoch 0 step 15 loss: 2.250010633468628\n",
      "epoch 0 step 20 loss: 2.214658784866333\n",
      "epoch 0 step 25 loss: 2.2631035327911375\n",
      "epoch 0 step 30 loss: 2.1634090900421143\n",
      "epoch 0 step 35 loss: 2.175160551071167\n",
      "epoch 0 step 40 loss: 2.139564800262451\n",
      "epoch 0 step 45 loss: 2.1763768672943113\n",
      "epoch 1 step 5 loss: 2.3385539770126345\n",
      "epoch 1 step 10 loss: 1.8997028827667237\n",
      "epoch 1 step 15 loss: 1.936851191520691\n",
      "epoch 1 step 20 loss: 1.9050029516220093\n",
      "epoch 1 step 25 loss: 1.9805632829666138\n",
      "epoch 1 step 30 loss: 1.8989370584487915\n",
      "epoch 1 step 35 loss: 1.9140663146972656\n",
      "epoch 1 step 40 loss: 1.921443271636963\n",
      "epoch 1 step 45 loss: 1.9511813640594482\n",
      "current lr: 0.00048019999999999996\n",
      "epoch 2 step 5 loss: 2.237473750114441\n",
      "epoch 2 step 10 loss: 1.8010414361953735\n",
      "epoch 2 step 15 loss: 1.7832820653915404\n",
      "epoch 2 step 20 loss: 1.8087833881378175\n",
      "epoch 2 step 25 loss: 1.8216389417648315\n",
      "epoch 2 step 30 loss: 1.7958399295806884\n",
      "epoch 2 step 35 loss: 1.783083176612854\n",
      "epoch 2 step 40 loss: 1.7620805025100708\n",
      "epoch 2 step 45 loss: 1.7313842296600341\n",
      "epoch 3 step 5 loss: 1.9469867467880249\n",
      "epoch 3 step 10 loss: 1.6248185157775878\n",
      "epoch 3 step 15 loss: 1.6074706315994263\n",
      "epoch 3 step 20 loss: 1.6503446102142334\n",
      "epoch 3 step 25 loss: 1.66711585521698\n",
      "epoch 3 step 30 loss: 1.6522639036178588\n",
      "epoch 3 step 35 loss: 1.6326060533523559\n",
      "epoch 3 step 40 loss: 1.6150268077850343\n",
      "epoch 3 step 45 loss: 1.6062904357910157\n",
      "current lr: 0.00047059599999999994\n",
      "epoch 4 step 5 loss: 1.8620172977447509\n",
      "epoch 4 step 10 loss: 1.4992229223251343\n",
      "epoch 4 step 15 loss: 1.637107539176941\n",
      "epoch 4 step 20 loss: 1.5624674081802368\n",
      "epoch 4 step 25 loss: 1.5653669357299804\n",
      "epoch 4 step 30 loss: 1.5559032201766967\n",
      "epoch 4 step 35 loss: 1.474683928489685\n",
      "epoch 4 step 40 loss: 1.5404448747634887\n",
      "epoch 4 step 45 loss: 1.5620481014251708\n",
      "encoder输入: ['悲', '也好', '喜', '也好']\n",
      "decoder输入: ['<go>', '每天', '找到', '新', '发现', '<eos>']\n",
      "target目标: ['每天', '找到', '新', '发现', '<eos>']\n",
      "预测结果: ['每天', '找到', '新', '发现', '<eos>']\n",
      "attention:\n",
      " tensor([[0.0192, 0.0303, 0.3100, 0.6405],\n",
      "        [0.0070, 0.0109, 0.0195, 0.9626],\n",
      "        [0.0303, 0.0055, 0.0181, 0.9461],\n",
      "        [0.0648, 0.0026, 0.0025, 0.9300],\n",
      "        [0.0210, 0.0067, 0.0237, 0.9486],\n",
      "        [0.8143, 0.0741, 0.0061, 0.1054]], grad_fn=<SelectBackward0>)\n",
      "epoch 5 step 5 loss: 1.7257058382034303\n",
      "epoch 5 step 10 loss: 1.370365309715271\n",
      "epoch 5 step 15 loss: 1.4422994375228881\n",
      "epoch 5 step 20 loss: 1.3777332067489625\n",
      "epoch 5 step 25 loss: 1.4714322805404663\n",
      "epoch 5 step 30 loss: 1.4449229478836059\n",
      "epoch 5 step 35 loss: 1.3765891075134278\n",
      "epoch 5 step 40 loss: 1.4234536647796632\n",
      "epoch 5 step 45 loss: 1.4578492641448975\n",
      "current lr: 0.0004611840799999999\n",
      "epoch 6 step 5 loss: 1.6020875930786134\n",
      "epoch 6 step 10 loss: 1.3464017629623413\n",
      "epoch 6 step 15 loss: 1.3454567193984985\n",
      "epoch 6 step 20 loss: 1.3926747560501098\n",
      "epoch 6 step 25 loss: 1.3528658390045165\n",
      "epoch 6 step 30 loss: 1.3241694450378418\n",
      "epoch 6 step 35 loss: 1.4192519664764405\n",
      "epoch 6 step 40 loss: 1.4094186305999756\n",
      "epoch 6 step 45 loss: 1.353997802734375\n",
      "epoch 7 step 5 loss: 1.4997470378875732\n",
      "epoch 7 step 10 loss: 1.256478476524353\n",
      "epoch 7 step 15 loss: 1.2683655977249146\n",
      "epoch 7 step 20 loss: 1.2751980781555177\n",
      "epoch 7 step 25 loss: 1.243510365486145\n",
      "epoch 7 step 30 loss: 1.2727383136749268\n",
      "epoch 7 step 35 loss: 1.2641716480255127\n",
      "epoch 7 step 40 loss: 1.2590733766555786\n",
      "epoch 7 step 45 loss: 1.2611881256103517\n",
      "current lr: 0.0004519603983999999\n",
      "epoch 8 step 5 loss: 1.4597301483154297\n",
      "epoch 8 step 10 loss: 1.3008676528930665\n",
      "epoch 8 step 15 loss: 1.2192901849746705\n",
      "epoch 8 step 20 loss: 1.2259720802307128\n",
      "epoch 8 step 25 loss: 1.164675760269165\n",
      "epoch 8 step 30 loss: 1.203044629096985\n",
      "epoch 8 step 35 loss: 1.1972294330596924\n",
      "epoch 8 step 40 loss: 1.2021392583847046\n",
      "epoch 8 step 45 loss: 1.242800235748291\n",
      "epoch 9 step 5 loss: 1.2997658967971801\n",
      "epoch 9 step 10 loss: 1.1340123891830445\n",
      "epoch 9 step 15 loss: 1.1373805284500123\n",
      "epoch 9 step 20 loss: 1.1233407974243164\n",
      "epoch 9 step 25 loss: 1.1213033676147461\n",
      "epoch 9 step 30 loss: 1.109356665611267\n",
      "epoch 9 step 35 loss: 1.1546616554260254\n",
      "epoch 9 step 40 loss: 1.1438844203948975\n",
      "epoch 9 step 45 loss: 1.159673810005188\n",
      "current lr: 0.0004429211904319999\n",
      "encoder输入: ['放', '阮', '孤单', '守', '家门']\n",
      "decoder输入: ['<go>', '未', '食', '未', '捆', '脚', '手软', '<eos>']\n",
      "target目标: ['未', '食', '未', '<unk>', '脚', '<unk>', '<eos>']\n",
      "预测结果: ['未', '食', '未', '离', '脚', '起', '<eos>']\n",
      "attention:\n",
      " tensor([[1.2463e-04, 1.6322e-02, 1.9530e-03, 3.1190e-01, 6.6970e-01],\n",
      "        [3.4066e-03, 9.4200e-01, 8.8929e-04, 5.0992e-02, 2.7078e-03],\n",
      "        [1.9948e-05, 5.0009e-04, 4.4066e-04, 6.8078e-02, 9.3096e-01],\n",
      "        [8.3175e-03, 7.1821e-01, 4.0457e-02, 1.4945e-01, 8.3567e-02],\n",
      "        [3.3497e-04, 1.0284e-03, 5.9148e-04, 7.7610e-02, 9.2044e-01],\n",
      "        [3.7270e-03, 9.1077e-04, 1.1574e-03, 3.2676e-01, 6.6744e-01],\n",
      "        [2.8516e-03, 6.2052e-03, 6.3443e-03, 2.5402e-01, 7.3058e-01],\n",
      "        [1.7392e-04, 2.3147e-03, 2.2195e-03, 5.7788e-01, 4.1741e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 10 step 5 loss: 1.2722095251083374\n",
      "epoch 10 step 10 loss: 1.0383030891418457\n",
      "epoch 10 step 15 loss: 1.070310854911804\n",
      "epoch 10 step 20 loss: 1.1031306266784668\n",
      "epoch 10 step 25 loss: 1.0925480604171753\n",
      "epoch 10 step 30 loss: 1.1263532161712646\n",
      "epoch 10 step 35 loss: 1.1374746441841126\n",
      "epoch 10 step 40 loss: 1.1295489549636841\n",
      "epoch 10 step 45 loss: 1.139661431312561\n",
      "epoch 11 step 5 loss: 1.1976268529891967\n",
      "epoch 11 step 10 loss: 1.0315976858139038\n",
      "epoch 11 step 15 loss: 0.978800368309021\n",
      "epoch 11 step 20 loss: 1.0026239514350892\n",
      "epoch 11 step 25 loss: 1.026983118057251\n",
      "epoch 11 step 30 loss: 0.9841574907302857\n",
      "epoch 11 step 35 loss: 1.0479451417922974\n",
      "epoch 11 step 40 loss: 1.0685116052627563\n",
      "epoch 11 step 45 loss: 1.0876879215240478\n",
      "current lr: 0.0004340627666233599\n",
      "epoch 12 step 5 loss: 1.14838764667511\n",
      "epoch 12 step 10 loss: 0.9557790756225586\n",
      "epoch 12 step 15 loss: 0.9841347694396972\n",
      "epoch 12 step 20 loss: 1.014534831047058\n",
      "epoch 12 step 25 loss: 0.9981400728225708\n",
      "epoch 12 step 30 loss: 1.0420133590698242\n",
      "epoch 12 step 35 loss: 1.0151974439620972\n",
      "epoch 12 step 40 loss: 1.0233186483383179\n",
      "epoch 12 step 45 loss: 0.9895713806152344\n",
      "epoch 13 step 5 loss: 1.1139559864997863\n",
      "epoch 13 step 10 loss: 0.8883788824081421\n",
      "epoch 13 step 15 loss: 0.9402516961097718\n",
      "epoch 13 step 20 loss: 0.9170053243637085\n",
      "epoch 13 step 25 loss: 0.918091332912445\n",
      "epoch 13 step 30 loss: 0.9630348563194275\n",
      "epoch 13 step 35 loss: 0.9481424689292908\n",
      "epoch 13 step 40 loss: 0.9021030902862549\n",
      "epoch 13 step 45 loss: 0.9450644493103028\n",
      "current lr: 0.00042538151129089267\n",
      "epoch 14 step 5 loss: 1.0579944849014282\n",
      "epoch 14 step 10 loss: 0.8912136435508728\n",
      "epoch 14 step 15 loss: 0.9097618818283081\n",
      "epoch 14 step 20 loss: 0.9340009450912475\n",
      "epoch 14 step 25 loss: 0.8863759875297547\n",
      "epoch 14 step 30 loss: 0.9095105767250061\n",
      "epoch 14 step 35 loss: 0.915355670452118\n",
      "epoch 14 step 40 loss: 0.9023993849754334\n",
      "epoch 14 step 45 loss: 0.9361928462982178\n",
      "encoder输入: ['我', '的', '心', '呀', '你', '的', '心']\n",
      "decoder输入: ['<go>', '早已', '有', '默契', '<eos>']\n",
      "target目标: ['早已', '有', '默契', '<eos>']\n",
      "预测结果: ['早已', '同', '默契', '<eos>']\n",
      "attention:\n",
      " tensor([[3.8524e-03, 2.5997e-03, 1.8667e-02, 7.1740e-04, 2.5445e-03, 5.4894e-02,\n",
      "         9.1673e-01],\n",
      "        [1.6112e-03, 9.0311e-04, 4.5093e-03, 1.5742e-03, 1.0632e-03, 7.6107e-03,\n",
      "         9.8273e-01],\n",
      "        [7.7849e-01, 2.0301e-03, 1.1264e-03, 1.7610e-02, 4.8811e-03, 1.3510e-02,\n",
      "         1.8235e-01],\n",
      "        [2.7026e-01, 5.6266e-02, 6.6816e-02, 2.5950e-02, 1.7302e-02, 9.1229e-02,\n",
      "         4.7218e-01],\n",
      "        [3.8861e-01, 5.1039e-02, 7.0082e-03, 6.4068e-03, 1.7533e-02, 1.5576e-01,\n",
      "         3.7364e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 15 step 5 loss: 1.0185158610343934\n",
      "epoch 15 step 10 loss: 0.8245204448699951\n",
      "epoch 15 step 15 loss: 0.8368561387062072\n",
      "epoch 15 step 20 loss: 0.8577284932136535\n",
      "epoch 15 step 25 loss: 0.8862134099006653\n",
      "epoch 15 step 30 loss: 0.8516370058059692\n",
      "epoch 15 step 35 loss: 0.806943929195404\n",
      "epoch 15 step 40 loss: 0.8594597935676574\n",
      "epoch 15 step 45 loss: 0.8632351756095886\n",
      "current lr: 0.0004168738810650748\n",
      "epoch 16 step 5 loss: 0.940185296535492\n",
      "epoch 16 step 10 loss: 0.7856105089187622\n",
      "epoch 16 step 15 loss: 0.8476034045219422\n",
      "epoch 16 step 20 loss: 0.7958881497383118\n",
      "epoch 16 step 25 loss: 0.8631768345832824\n",
      "epoch 16 step 30 loss: 0.8446651101112366\n",
      "epoch 16 step 35 loss: 0.8277655601501465\n",
      "epoch 16 step 40 loss: 0.8382946014404297\n",
      "epoch 16 step 45 loss: 0.8495585918426514\n",
      "epoch 17 step 5 loss: 0.9173285245895386\n",
      "epoch 17 step 10 loss: 0.7839865565299988\n",
      "epoch 17 step 15 loss: 0.7654644846916199\n",
      "epoch 17 step 20 loss: 0.7832000136375428\n",
      "epoch 17 step 25 loss: 0.7896813869476318\n",
      "epoch 17 step 30 loss: 0.7478782892227173\n",
      "epoch 17 step 35 loss: 0.7694036841392518\n",
      "epoch 17 step 40 loss: 0.7696034908294678\n",
      "epoch 17 step 45 loss: 0.7971452236175537\n",
      "current lr: 0.00040853640344377327\n",
      "epoch 18 step 5 loss: 0.8926185369491577\n",
      "epoch 18 step 10 loss: 0.7464258670806885\n",
      "epoch 18 step 15 loss: 0.7270982980728149\n",
      "epoch 18 step 20 loss: 0.748445451259613\n",
      "epoch 18 step 25 loss: 0.7521296620368958\n",
      "epoch 18 step 30 loss: 0.7831686496734619\n",
      "epoch 18 step 35 loss: 0.7810258626937866\n",
      "epoch 18 step 40 loss: 0.7910533428192139\n",
      "epoch 18 step 45 loss: 0.7539661407470704\n",
      "epoch 19 step 5 loss: 0.8419165134429931\n",
      "epoch 19 step 10 loss: 0.6838400840759278\n",
      "epoch 19 step 15 loss: 0.7213018536567688\n",
      "epoch 19 step 20 loss: 0.690281081199646\n",
      "epoch 19 step 25 loss: 0.7046011924743653\n",
      "epoch 19 step 30 loss: 0.7131011486053467\n",
      "epoch 19 step 35 loss: 0.731184720993042\n",
      "epoch 19 step 40 loss: 0.6997455716133117\n",
      "epoch 19 step 45 loss: 0.7266208052635192\n",
      "current lr: 0.0004003656753748978\n",
      "encoder输入: ['是', '你', '撩动', '我', '的', '情']\n",
      "decoder输入: ['<go>', '轻风', '来看', '湖水', '<eos>']\n",
      "target目标: ['轻风', '来看', '湖水', '<eos>']\n",
      "预测结果: ['轻风', '来看', '湖水', '<eos>']\n",
      "attention:\n",
      " tensor([[7.2395e-01, 1.8890e-01, 2.8917e-02, 1.0925e-02, 3.8851e-02, 8.4606e-03],\n",
      "        [2.7314e-02, 2.3161e-04, 4.1918e-01, 5.2550e-02, 4.6440e-01, 3.6325e-02],\n",
      "        [1.9572e-02, 3.8244e-03, 1.1663e-01, 5.1751e-01, 3.3769e-01, 4.7779e-03],\n",
      "        [1.3752e-01, 1.1839e-03, 3.9333e-02, 3.0915e-01, 4.8070e-01, 3.2120e-02],\n",
      "        [1.5317e-02, 2.7315e-03, 3.1484e-02, 1.4722e-02, 2.9080e-01, 6.4494e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 20 step 5 loss: 0.8141307353973388\n",
      "epoch 20 step 10 loss: 0.6853789806365966\n",
      "epoch 20 step 15 loss: 0.703454566001892\n",
      "epoch 20 step 20 loss: 0.6578395128250122\n",
      "epoch 20 step 25 loss: 0.7285184741020203\n",
      "epoch 20 step 30 loss: 0.7207530260086059\n",
      "epoch 20 step 35 loss: 0.7091516613960266\n",
      "epoch 20 step 40 loss: 0.7006537556648255\n",
      "epoch 20 step 45 loss: 0.7190386295318604\n",
      "epoch 21 step 5 loss: 0.7847437739372254\n",
      "epoch 21 step 10 loss: 0.648455274105072\n",
      "epoch 21 step 15 loss: 0.660726261138916\n",
      "epoch 21 step 20 loss: 0.6455188870429993\n",
      "epoch 21 step 25 loss: 0.6367697358131409\n",
      "epoch 21 step 30 loss: 0.637548291683197\n",
      "epoch 21 step 35 loss: 0.685378348827362\n",
      "epoch 21 step 40 loss: 0.6657189965248108\n",
      "epoch 21 step 45 loss: 0.6702958464622497\n",
      "current lr: 0.00039235836186739986\n",
      "epoch 22 step 5 loss: 0.757980215549469\n",
      "epoch 22 step 10 loss: 0.6143685102462768\n",
      "epoch 22 step 15 loss: 0.617288339138031\n",
      "epoch 22 step 20 loss: 0.6444407224655151\n",
      "epoch 22 step 25 loss: 0.65490802526474\n",
      "epoch 22 step 30 loss: 0.6319582104682923\n",
      "epoch 22 step 35 loss: 0.6623332142829895\n",
      "epoch 22 step 40 loss: 0.6454234004020691\n",
      "epoch 22 step 45 loss: 0.6721389770507813\n",
      "epoch 23 step 5 loss: 0.7113269090652465\n",
      "epoch 23 step 10 loss: 0.5760996103286743\n",
      "epoch 23 step 15 loss: 0.618694543838501\n",
      "epoch 23 step 20 loss: 0.5961970686912537\n",
      "epoch 23 step 25 loss: 0.6177109241485595\n",
      "epoch 23 step 30 loss: 0.5935286998748779\n",
      "epoch 23 step 35 loss: 0.6058612704277039\n",
      "epoch 23 step 40 loss: 0.636893880367279\n",
      "epoch 23 step 45 loss: 0.624972915649414\n",
      "current lr: 0.00038451119463005185\n",
      "epoch 24 step 5 loss: 0.6939839959144593\n",
      "epoch 24 step 10 loss: 0.5868537425994873\n",
      "epoch 24 step 15 loss: 0.5817437529563904\n",
      "epoch 24 step 20 loss: 0.5958129286766052\n",
      "epoch 24 step 25 loss: 0.6176236867904663\n",
      "epoch 24 step 30 loss: 0.5930983662605286\n",
      "epoch 24 step 35 loss: 0.5939088225364685\n",
      "epoch 24 step 40 loss: 0.6210741400718689\n",
      "epoch 24 step 45 loss: 0.6030980944633484\n",
      "encoder输入: ['蓝', '的', '天', '是', '新郎']\n",
      "decoder输入: ['<go>', '白', '的', '云', '是', '新娘', '<eos>']\n",
      "target目标: ['白', '的', '云', '是', '新娘', '<eos>']\n",
      "预测结果: ['白', '的', '云', '是', '新娘', '<eos>']\n",
      "attention:\n",
      " tensor([[2.3727e-01, 6.7546e-01, 1.0894e-02, 3.4519e-02, 4.1853e-02],\n",
      "        [1.2177e-01, 3.3345e-01, 1.4856e-02, 6.8989e-02, 4.6093e-01],\n",
      "        [1.0896e-01, 5.3320e-02, 1.9862e-02, 2.5902e-02, 7.9196e-01],\n",
      "        [2.2887e-03, 1.1315e-02, 9.4321e-03, 3.2346e-02, 9.4462e-01],\n",
      "        [3.1678e-03, 1.2650e-03, 2.4239e-04, 1.9196e-03, 9.9341e-01],\n",
      "        [8.1886e-03, 1.5932e-03, 1.8270e-03, 4.1177e-02, 9.4721e-01],\n",
      "        [7.8541e-02, 3.9237e-03, 1.2809e-02, 3.5315e-02, 8.6941e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 25 step 5 loss: 0.6519892692565918\n",
      "epoch 25 step 10 loss: 0.5466717004776\n",
      "epoch 25 step 15 loss: 0.5546260833740234\n",
      "epoch 25 step 20 loss: 0.5627657294273376\n",
      "epoch 25 step 25 loss: 0.5468099772930145\n",
      "epoch 25 step 30 loss: 0.533140379190445\n",
      "epoch 25 step 35 loss: 0.5617206335067749\n",
      "epoch 25 step 40 loss: 0.5644690036773682\n",
      "epoch 25 step 45 loss: 0.5863497614860534\n",
      "current lr: 0.0003768209707374508\n",
      "epoch 26 step 5 loss: 0.6308127284049988\n",
      "epoch 26 step 10 loss: 0.5338553607463836\n",
      "epoch 26 step 15 loss: 0.5152884364128113\n",
      "epoch 26 step 20 loss: 0.556699526309967\n",
      "epoch 26 step 25 loss: 0.5506377339363098\n",
      "epoch 26 step 30 loss: 0.5708660125732422\n",
      "epoch 26 step 35 loss: 0.5941509485244751\n",
      "epoch 26 step 40 loss: 0.5715350389480591\n",
      "epoch 26 step 45 loss: 0.5657885313034058\n",
      "epoch 27 step 5 loss: 0.585573548078537\n",
      "epoch 27 step 10 loss: 0.5203652024269104\n",
      "epoch 27 step 15 loss: 0.518748939037323\n",
      "epoch 27 step 20 loss: 0.5048715472221375\n",
      "epoch 27 step 25 loss: 0.5414793252944946\n",
      "epoch 27 step 30 loss: 0.49760929942131044\n",
      "epoch 27 step 35 loss: 0.5349209904670715\n",
      "epoch 27 step 40 loss: 0.5036183595657349\n",
      "epoch 27 step 45 loss: 0.5352051973342895\n",
      "current lr: 0.0003692845513227018\n",
      "epoch 28 step 5 loss: 0.6013101160526275\n",
      "epoch 28 step 10 loss: 0.48747732043266295\n",
      "epoch 28 step 15 loss: 0.5145739674568176\n",
      "epoch 28 step 20 loss: 0.5171677529811859\n",
      "epoch 28 step 25 loss: 0.515008270740509\n",
      "epoch 28 step 30 loss: 0.533729350566864\n",
      "epoch 28 step 35 loss: 0.5217787802219391\n",
      "epoch 28 step 40 loss: 0.5192564904689789\n",
      "epoch 28 step 45 loss: 0.5196954309940338\n",
      "epoch 29 step 5 loss: 0.5454925000667572\n",
      "epoch 29 step 10 loss: 0.4810755431652069\n",
      "epoch 29 step 15 loss: 0.4836345314979553\n",
      "epoch 29 step 20 loss: 0.4783608138561249\n",
      "epoch 29 step 25 loss: 0.5045309126377105\n",
      "epoch 29 step 30 loss: 0.44757588505744933\n",
      "epoch 29 step 35 loss: 0.49048810005187987\n",
      "epoch 29 step 40 loss: 0.49615981578826907\n",
      "epoch 29 step 45 loss: 0.4969745218753815\n",
      "current lr: 0.00036189886029624774\n",
      "encoder输入: ['我', '尝', '尽', '辛酸', '滋味']\n",
      "decoder输入: ['<go>', '飘泊', '在', '茫茫人海', '<eos>']\n",
      "target目标: ['飘泊', '在', '茫茫人海', '<eos>']\n",
      "预测结果: ['飘泊', '在', '茫茫人海', '<eos>']\n",
      "attention:\n",
      " tensor([[4.9513e-03, 9.5632e-01, 2.4959e-02, 8.5704e-03, 5.1966e-03],\n",
      "        [1.0771e-01, 1.7498e-01, 6.7283e-02, 1.5740e-01, 4.9263e-01],\n",
      "        [8.1779e-04, 3.1973e-02, 5.3619e-02, 8.3779e-02, 8.2981e-01],\n",
      "        [2.1017e-01, 1.0448e-01, 6.7298e-03, 4.3495e-02, 6.3513e-01],\n",
      "        [9.5217e-02, 3.1535e-01, 1.9068e-02, 4.9334e-02, 5.2103e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 30 step 5 loss: 0.5590107917785645\n",
      "epoch 30 step 10 loss: 0.45925981402397154\n",
      "epoch 30 step 15 loss: 0.4611485362052917\n",
      "epoch 30 step 20 loss: 0.4895739614963531\n",
      "epoch 30 step 25 loss: 0.4624891340732574\n",
      "epoch 30 step 30 loss: 0.47923803329467773\n",
      "epoch 30 step 35 loss: 0.47843378186225893\n",
      "epoch 30 step 40 loss: 0.48060073852539065\n",
      "epoch 30 step 45 loss: 0.5034833610057831\n",
      "epoch 31 step 5 loss: 0.5292608559131622\n",
      "epoch 31 step 10 loss: 0.4536665201187134\n",
      "epoch 31 step 15 loss: 0.44047202467918395\n",
      "epoch 31 step 20 loss: 0.4385997116565704\n",
      "epoch 31 step 25 loss: 0.45193030834198\n",
      "epoch 31 step 30 loss: 0.46227810382843015\n",
      "epoch 31 step 35 loss: 0.4363728404045105\n",
      "epoch 31 step 40 loss: 0.44354934692382814\n",
      "epoch 31 step 45 loss: 0.46724541783332824\n",
      "current lr: 0.0003546608830903228\n",
      "epoch 32 step 5 loss: 0.5088804244995118\n",
      "epoch 32 step 10 loss: 0.4338021218776703\n",
      "epoch 32 step 15 loss: 0.4599159896373749\n",
      "epoch 32 step 20 loss: 0.45907180309295653\n",
      "epoch 32 step 25 loss: 0.44176832437515257\n",
      "epoch 32 step 30 loss: 0.42978562116622926\n",
      "epoch 32 step 35 loss: 0.4494879961013794\n",
      "epoch 32 step 40 loss: 0.4721894323825836\n",
      "epoch 32 step 45 loss: 0.4495723247528076\n",
      "epoch 33 step 5 loss: 0.5012395739555359\n",
      "epoch 33 step 10 loss: 0.4105487108230591\n",
      "epoch 33 step 15 loss: 0.41714001893997193\n",
      "epoch 33 step 20 loss: 0.42857950925827026\n",
      "epoch 33 step 25 loss: 0.42943825125694274\n",
      "epoch 33 step 30 loss: 0.42334096431732177\n",
      "epoch 33 step 35 loss: 0.44947926998138427\n",
      "epoch 33 step 40 loss: 0.42169188857078554\n",
      "epoch 33 step 45 loss: 0.42375094890594484\n",
      "current lr: 0.00034756766542851634\n",
      "epoch 34 step 5 loss: 0.47979883551597596\n",
      "epoch 34 step 10 loss: 0.4141468107700348\n",
      "epoch 34 step 15 loss: 0.4095785081386566\n",
      "epoch 34 step 20 loss: 0.4221908688545227\n",
      "epoch 34 step 25 loss: 0.414895111322403\n",
      "epoch 34 step 30 loss: 0.4274725794792175\n",
      "epoch 34 step 35 loss: 0.4126171231269836\n",
      "epoch 34 step 40 loss: 0.41320897936820983\n",
      "epoch 34 step 45 loss: 0.4382916629314423\n",
      "encoder输入: ['你', '你', '已经']\n",
      "decoder输入: ['<go>', '叫', '我', '为', '你', '朝', '思', '夜', '想', '<eos>']\n",
      "target目标: ['叫', '我', '为', '你', '朝', '思', '夜', '想', '<eos>']\n",
      "预测结果: ['叫', '我', '为', '你', '朝', '思', '夜', '想', '<eos>']\n",
      "attention:\n",
      " tensor([[0.9274, 0.0345, 0.0382],\n",
      "        [0.1175, 0.0114, 0.8711],\n",
      "        [0.4574, 0.3620, 0.1806],\n",
      "        [0.8341, 0.0263, 0.1395],\n",
      "        [0.8544, 0.0888, 0.0568],\n",
      "        [0.9715, 0.0180, 0.0106],\n",
      "        [0.9932, 0.0036, 0.0032],\n",
      "        [0.9704, 0.0094, 0.0202],\n",
      "        [0.9051, 0.0273, 0.0677],\n",
      "        [0.8937, 0.0975, 0.0088]], grad_fn=<SelectBackward0>)\n",
      "epoch 35 step 5 loss: 0.4636119484901428\n",
      "epoch 35 step 10 loss: 0.38306096792221067\n",
      "epoch 35 step 15 loss: 0.36937764286994934\n",
      "epoch 35 step 20 loss: 0.400816935300827\n",
      "epoch 35 step 25 loss: 0.39139396548271177\n",
      "epoch 35 step 30 loss: 0.38177786469459535\n",
      "epoch 35 step 35 loss: 0.39704511761665345\n",
      "epoch 35 step 40 loss: 0.4125086545944214\n",
      "epoch 35 step 45 loss: 0.4082119226455688\n",
      "current lr: 0.000340616312119946\n",
      "epoch 36 step 5 loss: 0.4387190043926239\n",
      "epoch 36 step 10 loss: 0.377086216211319\n",
      "epoch 36 step 15 loss: 0.37689201831817626\n",
      "epoch 36 step 20 loss: 0.3872370719909668\n",
      "epoch 36 step 25 loss: 0.37926067113876344\n",
      "epoch 36 step 30 loss: 0.3962706089019775\n",
      "epoch 36 step 35 loss: 0.4051602602005005\n",
      "epoch 36 step 40 loss: 0.40418063998222353\n",
      "epoch 36 step 45 loss: 0.39618114233016966\n",
      "epoch 37 step 5 loss: 0.44167526364326476\n",
      "epoch 37 step 10 loss: 0.34561136960983274\n",
      "epoch 37 step 15 loss: 0.3652567803859711\n",
      "epoch 37 step 20 loss: 0.3716674089431763\n",
      "epoch 37 step 25 loss: 0.38295927047729494\n",
      "epoch 37 step 30 loss: 0.345214307308197\n",
      "epoch 37 step 35 loss: 0.37072629332542417\n",
      "epoch 37 step 40 loss: 0.37610111236572263\n",
      "epoch 37 step 45 loss: 0.360325300693512\n",
      "current lr: 0.0003338039858775471\n",
      "epoch 38 step 5 loss: 0.4307096004486084\n",
      "epoch 38 step 10 loss: 0.3460943341255188\n",
      "epoch 38 step 15 loss: 0.36037570238113403\n",
      "epoch 38 step 20 loss: 0.3816427946090698\n",
      "epoch 38 step 25 loss: 0.360608845949173\n",
      "epoch 38 step 30 loss: 0.3621068596839905\n",
      "epoch 38 step 35 loss: 0.37536053657531737\n",
      "epoch 38 step 40 loss: 0.37263196110725405\n",
      "epoch 38 step 45 loss: 0.3651629865169525\n",
      "epoch 39 step 5 loss: 0.3888751745223999\n",
      "epoch 39 step 10 loss: 0.31913577318191527\n",
      "epoch 39 step 15 loss: 0.3530223846435547\n",
      "epoch 39 step 20 loss: 0.33386594653129575\n",
      "epoch 39 step 25 loss: 0.3541164219379425\n",
      "epoch 39 step 30 loss: 0.3526685833930969\n",
      "epoch 39 step 35 loss: 0.35371217131614685\n",
      "epoch 39 step 40 loss: 0.3431354582309723\n",
      "epoch 39 step 45 loss: 0.35909048318862913\n",
      "current lr: 0.0003271279061599962\n",
      "encoder输入: ['树上', '美丽', '的', '花']\n",
      "decoder输入: ['<go>', '开', '的', '多么', '可爱', '<eos>']\n",
      "target目标: ['开', '的', '多么', '可爱', '<eos>']\n",
      "预测结果: ['开', '的', '多么', '可爱', '<eos>']\n",
      "attention:\n",
      " tensor([[0.1911, 0.2419, 0.0126, 0.5543],\n",
      "        [0.2598, 0.2950, 0.0470, 0.3982],\n",
      "        [0.0967, 0.8346, 0.0327, 0.0360],\n",
      "        [0.1562, 0.7894, 0.0094, 0.0450],\n",
      "        [0.3535, 0.4291, 0.0409, 0.1765],\n",
      "        [0.3396, 0.2757, 0.0461, 0.3385]], grad_fn=<SelectBackward0>)\n",
      "epoch 40 step 5 loss: 0.39995684027671813\n",
      "epoch 40 step 10 loss: 0.3309981644153595\n",
      "epoch 40 step 15 loss: 0.3360023498535156\n",
      "epoch 40 step 20 loss: 0.3354360401630402\n",
      "epoch 40 step 25 loss: 0.3353506922721863\n",
      "epoch 40 step 30 loss: 0.3611245810985565\n",
      "epoch 40 step 35 loss: 0.3685497224330902\n",
      "epoch 40 step 40 loss: 0.35015215277671813\n",
      "epoch 40 step 45 loss: 0.3330095410346985\n",
      "epoch 41 step 5 loss: 0.3651084125041962\n",
      "epoch 41 step 10 loss: 0.30109127163887023\n",
      "epoch 41 step 15 loss: 0.309872567653656\n",
      "epoch 41 step 20 loss: 0.3327966332435608\n",
      "epoch 41 step 25 loss: 0.3409509897232056\n",
      "epoch 41 step 30 loss: 0.3438797354698181\n",
      "epoch 41 step 35 loss: 0.3134904742240906\n",
      "epoch 41 step 40 loss: 0.34087437987327573\n",
      "epoch 41 step 45 loss: 0.3326651036739349\n",
      "current lr: 0.00032058534803679624\n",
      "epoch 42 step 5 loss: 0.3774218618869781\n",
      "epoch 42 step 10 loss: 0.3151672422885895\n",
      "epoch 42 step 15 loss: 0.30807403922080995\n",
      "epoch 42 step 20 loss: 0.3257205724716187\n",
      "epoch 42 step 25 loss: 0.33967668414115904\n",
      "epoch 42 step 30 loss: 0.3230758965015411\n",
      "epoch 42 step 35 loss: 0.3223177075386047\n",
      "epoch 42 step 40 loss: 0.35053145289421084\n",
      "epoch 42 step 45 loss: 0.3253107309341431\n",
      "epoch 43 step 5 loss: 0.3578084111213684\n",
      "epoch 43 step 10 loss: 0.3061326742172241\n",
      "epoch 43 step 15 loss: 0.31846275329589846\n",
      "epoch 43 step 20 loss: 0.31550227999687197\n",
      "epoch 43 step 25 loss: 0.28751757740974426\n",
      "epoch 43 step 30 loss: 0.3045388162136078\n",
      "epoch 43 step 35 loss: 0.30765525698661805\n",
      "epoch 43 step 40 loss: 0.31085224747657775\n",
      "epoch 43 step 45 loss: 0.31347622275352477\n",
      "current lr: 0.0003141736410760603\n",
      "epoch 44 step 5 loss: 0.3471952050924301\n",
      "epoch 44 step 10 loss: 0.2931151449680328\n",
      "epoch 44 step 15 loss: 0.30186488628387453\n",
      "epoch 44 step 20 loss: 0.3048576474189758\n",
      "epoch 44 step 25 loss: 0.3176648437976837\n",
      "epoch 44 step 30 loss: 0.31230162978172304\n",
      "epoch 44 step 35 loss: 0.3099183619022369\n",
      "epoch 44 step 40 loss: 0.28920513987541197\n",
      "epoch 44 step 45 loss: 0.32157872915267943\n",
      "encoder输入: ['永远', '的', '爱', '我']\n",
      "decoder输入: ['<go>', '谁', '知道', '你', '的话', '儿', '<eos>']\n",
      "target目标: ['谁', '知道', '你', '的话', '儿', '<eos>']\n",
      "预测结果: ['谁', '知道', '你', '的话', '儿', '<eos>']\n",
      "attention:\n",
      " tensor([[9.6815e-01, 2.8357e-02, 1.1233e-03, 2.3679e-03],\n",
      "        [9.5006e-01, 4.5222e-02, 2.4666e-03, 2.2544e-03],\n",
      "        [1.4280e-01, 2.0533e-02, 6.6064e-01, 1.7603e-01],\n",
      "        [9.0827e-01, 2.8758e-02, 2.1148e-02, 4.1827e-02],\n",
      "        [9.1456e-01, 4.7162e-02, 1.3602e-02, 2.4679e-02],\n",
      "        [9.8679e-01, 1.0914e-02, 2.0512e-03, 2.4816e-04],\n",
      "        [9.8946e-01, 3.5204e-03, 4.1823e-04, 6.6057e-03]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 45 step 5 loss: 0.3527301847934723\n",
      "epoch 45 step 10 loss: 0.29079145193099976\n",
      "epoch 45 step 15 loss: 0.2818244516849518\n",
      "epoch 45 step 20 loss: 0.2852363586425781\n",
      "epoch 45 step 25 loss: 0.27115330994129183\n",
      "epoch 45 step 30 loss: 0.29700987339019774\n",
      "epoch 45 step 35 loss: 0.29638283848762514\n",
      "epoch 45 step 40 loss: 0.2919061124324799\n",
      "epoch 45 step 45 loss: 0.28243152499198915\n",
      "current lr: 0.0003078901682545391\n",
      "epoch 46 step 5 loss: 0.3338802993297577\n",
      "epoch 46 step 10 loss: 0.27063382863998414\n",
      "epoch 46 step 15 loss: 0.27837716937065127\n",
      "epoch 46 step 20 loss: 0.271613147854805\n",
      "epoch 46 step 25 loss: 0.2858473896980286\n",
      "epoch 46 step 30 loss: 0.2838073313236237\n",
      "epoch 46 step 35 loss: 0.306019788980484\n",
      "epoch 46 step 40 loss: 0.3159277617931366\n",
      "epoch 46 step 45 loss: 0.293703681230545\n",
      "epoch 47 step 5 loss: 0.3418502748012543\n",
      "epoch 47 step 10 loss: 0.27432810962200166\n",
      "epoch 47 step 15 loss: 0.2643575519323349\n",
      "epoch 47 step 20 loss: 0.2627280831336975\n",
      "epoch 47 step 25 loss: 0.2782764434814453\n",
      "epoch 47 step 30 loss: 0.2857762277126312\n",
      "epoch 47 step 35 loss: 0.27296793162822724\n",
      "epoch 47 step 40 loss: 0.2770965099334717\n",
      "epoch 47 step 45 loss: 0.2697964429855347\n",
      "current lr: 0.00030173236488944833\n",
      "epoch 48 step 5 loss: 0.30978539288043977\n",
      "epoch 48 step 10 loss: 0.2567862719297409\n",
      "epoch 48 step 15 loss: 0.27536775171756744\n",
      "epoch 48 step 20 loss: 0.26793851256370543\n",
      "epoch 48 step 25 loss: 0.2716877102851868\n",
      "epoch 48 step 30 loss: 0.28367994725704193\n",
      "epoch 48 step 35 loss: 0.2724165111780167\n",
      "epoch 48 step 40 loss: 0.28037589192390444\n",
      "epoch 48 step 45 loss: 0.2868484169244766\n",
      "epoch 49 step 5 loss: 0.30911391973495483\n",
      "epoch 49 step 10 loss: 0.256033656001091\n",
      "epoch 49 step 15 loss: 0.2690029352903366\n",
      "epoch 49 step 20 loss: 0.26727467477321626\n",
      "epoch 49 step 25 loss: 0.25243644416332245\n",
      "epoch 49 step 30 loss: 0.2506580203771591\n",
      "epoch 49 step 35 loss: 0.2587277889251709\n",
      "epoch 49 step 40 loss: 0.24951727390289308\n",
      "epoch 49 step 45 loss: 0.26735207736492156\n",
      "current lr: 0.00029569771759165936\n",
      "encoder输入: ['只有', '那', '春风', '知道', '我']\n",
      "decoder输入: ['<go>', '知道', '我', '寂寞', '<eos>']\n",
      "target目标: ['知道', '我', '寂寞', '<eos>']\n",
      "预测结果: ['知道', '我', '寂寞', '<eos>']\n",
      "attention:\n",
      " tensor([[1.7802e-01, 2.7216e-01, 1.3092e-01, 1.1278e-01, 3.0613e-01],\n",
      "        [2.2027e-03, 1.3353e-02, 8.8335e-03, 4.4685e-02, 9.3093e-01],\n",
      "        [4.2709e-05, 5.3257e-05, 1.3689e-04, 3.2322e-02, 9.6745e-01],\n",
      "        [2.5195e-03, 1.5602e-03, 5.1452e-03, 2.0272e-01, 7.8805e-01],\n",
      "        [3.0291e-01, 1.0482e-01, 1.8472e-01, 5.2386e-02, 3.5516e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 50 step 5 loss: 0.29618053436279296\n",
      "epoch 50 step 10 loss: 0.2544687330722809\n",
      "epoch 50 step 15 loss: 0.2463526964187622\n",
      "epoch 50 step 20 loss: 0.253736212849617\n",
      "epoch 50 step 25 loss: 0.2699267864227295\n",
      "epoch 50 step 30 loss: 0.2549941331148148\n",
      "epoch 50 step 35 loss: 0.2683750331401825\n",
      "epoch 50 step 40 loss: 0.25770420730113985\n",
      "epoch 50 step 45 loss: 0.27172088623046875\n",
      "epoch 51 step 5 loss: 0.2861569434404373\n",
      "epoch 51 step 10 loss: 0.2309594988822937\n",
      "epoch 51 step 15 loss: 0.23634537160396576\n",
      "epoch 51 step 20 loss: 0.2510151892900467\n",
      "epoch 51 step 25 loss: 0.23485777974128724\n",
      "epoch 51 step 30 loss: 0.26179597675800326\n",
      "epoch 51 step 35 loss: 0.24562365412712098\n",
      "epoch 51 step 40 loss: 0.2591347277164459\n",
      "epoch 51 step 45 loss: 0.2383445292711258\n",
      "current lr: 0.00028978376323982616\n",
      "epoch 52 step 5 loss: 0.27146669626235964\n",
      "epoch 52 step 10 loss: 0.25410401821136475\n",
      "epoch 52 step 15 loss: 0.22792358696460724\n",
      "epoch 52 step 20 loss: 0.2563652664422989\n",
      "epoch 52 step 25 loss: 0.23921616971492768\n",
      "epoch 52 step 30 loss: 0.25506602227687836\n",
      "epoch 52 step 35 loss: 0.25046867728233335\n",
      "epoch 52 step 40 loss: 0.26301831007003784\n",
      "epoch 52 step 45 loss: 0.25291587710380553\n",
      "epoch 53 step 5 loss: 0.28071734607219695\n",
      "epoch 53 step 10 loss: 0.23013263642787934\n",
      "epoch 53 step 15 loss: 0.23923316299915315\n",
      "epoch 53 step 20 loss: 0.2292403608560562\n",
      "epoch 53 step 25 loss: 0.223245245218277\n",
      "epoch 53 step 30 loss: 0.23357050716876984\n",
      "epoch 53 step 35 loss: 0.2269018769264221\n",
      "epoch 53 step 40 loss: 0.24063313603401185\n",
      "epoch 53 step 45 loss: 0.25181966125965116\n",
      "current lr: 0.00028398808797502965\n",
      "epoch 54 step 5 loss: 0.26550011336803436\n",
      "epoch 54 step 10 loss: 0.2180478096008301\n",
      "epoch 54 step 15 loss: 0.2476906359195709\n",
      "epoch 54 step 20 loss: 0.2286292403936386\n",
      "epoch 54 step 25 loss: 0.2367926597595215\n",
      "epoch 54 step 30 loss: 0.23873280882835388\n",
      "epoch 54 step 35 loss: 0.23325261771678923\n",
      "epoch 54 step 40 loss: 0.22949880361557007\n",
      "epoch 54 step 45 loss: 0.2406366378068924\n",
      "encoder输入: ['前途渺茫', '何处', '去']\n",
      "decoder输入: ['<go>', '追寻', '往日', '的', '回忆', '<eos>']\n",
      "target目标: ['追寻', '往日', '的', '回忆', '<eos>']\n",
      "预测结果: ['追寻', '往日', '的', '回忆', '<eos>']\n",
      "attention:\n",
      " tensor([[0.0125, 0.4112, 0.5762],\n",
      "        [0.0013, 0.0421, 0.9566],\n",
      "        [0.0163, 0.0817, 0.9020],\n",
      "        [0.4647, 0.4103, 0.1250],\n",
      "        [0.3627, 0.4969, 0.1405],\n",
      "        [0.0990, 0.5291, 0.3719]], grad_fn=<SelectBackward0>)\n",
      "epoch 55 step 5 loss: 0.2562701106071472\n",
      "epoch 55 step 10 loss: 0.21086178123950958\n",
      "epoch 55 step 15 loss: 0.2100783735513687\n",
      "epoch 55 step 20 loss: 0.2081317812204361\n",
      "epoch 55 step 25 loss: 0.23037242293357849\n",
      "epoch 55 step 30 loss: 0.22891375720500945\n",
      "epoch 55 step 35 loss: 0.22897568047046662\n",
      "epoch 55 step 40 loss: 0.22070103287696838\n",
      "epoch 55 step 45 loss: 0.23960589170455932\n",
      "current lr: 0.00027830832621552904\n",
      "epoch 56 step 5 loss: 0.24444853365421296\n",
      "epoch 56 step 10 loss: 0.21448203921318054\n",
      "epoch 56 step 15 loss: 0.22087126970291138\n",
      "epoch 56 step 20 loss: 0.22227863371372222\n",
      "epoch 56 step 25 loss: 0.21244306564331056\n",
      "epoch 56 step 30 loss: 0.22318608462810516\n",
      "epoch 56 step 35 loss: 0.22931349873542786\n",
      "epoch 56 step 40 loss: 0.22873657941818237\n",
      "epoch 56 step 45 loss: 0.2357660114765167\n",
      "epoch 57 step 5 loss: 0.23779089450836183\n",
      "epoch 57 step 10 loss: 0.20798324346542357\n",
      "epoch 57 step 15 loss: 0.20796196460723876\n",
      "epoch 57 step 20 loss: 0.2147434026002884\n",
      "epoch 57 step 25 loss: 0.210868301987648\n",
      "epoch 57 step 30 loss: 0.2011047810316086\n",
      "epoch 57 step 35 loss: 0.22400992214679719\n",
      "epoch 57 step 40 loss: 0.20966300666332244\n",
      "epoch 57 step 45 loss: 0.21884789764881135\n",
      "current lr: 0.00027274215969121844\n",
      "epoch 58 step 5 loss: 0.23814395368099212\n",
      "epoch 58 step 10 loss: 0.2180042952299118\n",
      "epoch 58 step 15 loss: 0.19806169867515563\n",
      "epoch 58 step 20 loss: 0.20596762597560883\n",
      "epoch 58 step 25 loss: 0.20936377048492433\n",
      "epoch 58 step 30 loss: 0.21739684641361237\n",
      "epoch 58 step 35 loss: 0.21430622637271882\n",
      "epoch 58 step 40 loss: 0.21701594591140747\n",
      "epoch 58 step 45 loss: 0.21372251212596893\n",
      "epoch 59 step 5 loss: 0.23278027176856994\n",
      "epoch 59 step 10 loss: 0.1961635559797287\n",
      "epoch 59 step 15 loss: 0.201638326048851\n",
      "epoch 59 step 20 loss: 0.20245597660541534\n",
      "epoch 59 step 25 loss: 0.19807976484298706\n",
      "epoch 59 step 30 loss: 0.21054317951202392\n",
      "epoch 59 step 35 loss: 0.2020730346441269\n",
      "epoch 59 step 40 loss: 0.2110863596200943\n",
      "epoch 59 step 45 loss: 0.2123806059360504\n",
      "current lr: 0.00026728731649739405\n",
      "encoder输入: ['草儿', '绿', '呀', '花儿', '红']\n",
      "decoder输入: ['<go>', '啦', '啦', '<eos>']\n",
      "target目标: ['啦', '啦', '<eos>']\n",
      "预测结果: ['朵朵', '啦', '<eos>']\n",
      "attention:\n",
      " tensor([[1.4375e-03, 3.0817e-02, 2.5010e-01, 2.0608e-01, 5.1157e-01],\n",
      "        [3.3639e-05, 5.1577e-02, 2.3375e-02, 1.0137e-01, 8.2364e-01],\n",
      "        [7.7081e-03, 8.0878e-01, 8.9837e-03, 5.7221e-02, 1.1731e-01],\n",
      "        [7.8461e-04, 2.1078e-01, 2.6463e-02, 3.4163e-01, 4.2035e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 60 step 5 loss: 0.24090351462364196\n",
      "epoch 60 step 10 loss: 0.18881652057170867\n",
      "epoch 60 step 15 loss: 0.2149357467889786\n",
      "epoch 60 step 20 loss: 0.19635072350502014\n",
      "epoch 60 step 25 loss: 0.1907212406396866\n",
      "epoch 60 step 30 loss: 0.21587264835834502\n",
      "epoch 60 step 35 loss: 0.19391648471355438\n",
      "epoch 60 step 40 loss: 0.21552076935768127\n",
      "epoch 60 step 45 loss: 0.21772602796554566\n",
      "epoch 61 step 5 loss: 0.23223718404769897\n",
      "epoch 61 step 10 loss: 0.18727333843708038\n",
      "epoch 61 step 15 loss: 0.1867760956287384\n",
      "epoch 61 step 20 loss: 0.19118314385414123\n",
      "epoch 61 step 25 loss: 0.19343581199645996\n",
      "epoch 61 step 30 loss: 0.19658393859863282\n",
      "epoch 61 step 35 loss: 0.19900260269641876\n",
      "epoch 61 step 40 loss: 0.19397823810577391\n",
      "epoch 61 step 45 loss: 0.20957398414611816\n",
      "current lr: 0.00026194157016744615\n",
      "epoch 62 step 5 loss: 0.21855699717998506\n",
      "epoch 62 step 10 loss: 0.19494234025478363\n",
      "epoch 62 step 15 loss: 0.18485612273216248\n",
      "epoch 62 step 20 loss: 0.19842558205127717\n",
      "epoch 62 step 25 loss: 0.18418703079223633\n",
      "epoch 62 step 30 loss: 0.2004490852355957\n",
      "epoch 62 step 35 loss: 0.20611643195152282\n",
      "epoch 62 step 40 loss: 0.20629942417144775\n",
      "epoch 62 step 45 loss: 0.1963970422744751\n",
      "epoch 63 step 5 loss: 0.21651175916194915\n",
      "epoch 63 step 10 loss: 0.18534195125102998\n",
      "epoch 63 step 15 loss: 0.18669995963573455\n",
      "epoch 63 step 20 loss: 0.1785510778427124\n",
      "epoch 63 step 25 loss: 0.17181812822818757\n",
      "epoch 63 step 30 loss: 0.18390192985534667\n",
      "epoch 63 step 35 loss: 0.18681503534317018\n",
      "epoch 63 step 40 loss: 0.18719697892665862\n",
      "epoch 63 step 45 loss: 0.21382788121700286\n",
      "current lr: 0.00025670273876409724\n",
      "epoch 64 step 5 loss: 0.2110349327325821\n",
      "epoch 64 step 10 loss: 0.17054425776004792\n",
      "epoch 64 step 15 loss: 0.18640074133872986\n",
      "epoch 64 step 20 loss: 0.17927067577838898\n",
      "epoch 64 step 25 loss: 0.1890977591276169\n",
      "epoch 64 step 30 loss: 0.18211610317230226\n",
      "epoch 64 step 35 loss: 0.1976405292749405\n",
      "epoch 64 step 40 loss: 0.19020265638828276\n",
      "epoch 64 step 45 loss: 0.206076517701149\n",
      "encoder输入: ['要', '我', '相', '做伴']\n",
      "decoder输入: ['<go>', '苍凉', '荒漠', '我', '不怕', '<eos>']\n",
      "target目标: ['苍凉', '荒漠', '我', '不怕', '<eos>']\n",
      "预测结果: ['苍凉', '荒漠', '我', '不怕', '<eos>']\n",
      "attention:\n",
      " tensor([[8.3887e-01, 1.0892e-01, 2.6443e-02, 2.5764e-02],\n",
      "        [5.2043e-01, 6.0216e-03, 3.7839e-02, 4.3571e-01],\n",
      "        [1.7111e-01, 4.4528e-02, 2.6918e-01, 5.1518e-01],\n",
      "        [6.0581e-02, 4.6321e-02, 2.3092e-01, 6.6218e-01],\n",
      "        [2.6586e-04, 7.9741e-05, 1.5589e-03, 9.9810e-01],\n",
      "        [5.0991e-04, 7.1727e-03, 8.1047e-03, 9.8421e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 65 step 5 loss: 0.20021783113479613\n",
      "epoch 65 step 10 loss: 0.17804996371269227\n",
      "epoch 65 step 15 loss: 0.17028414607048034\n",
      "epoch 65 step 20 loss: 0.17846448421478273\n",
      "epoch 65 step 25 loss: 0.17418891489505767\n",
      "epoch 65 step 30 loss: 0.1886797934770584\n",
      "epoch 65 step 35 loss: 0.18037261068820953\n",
      "epoch 65 step 40 loss: 0.19085524082183838\n",
      "epoch 65 step 45 loss: 0.1795795291662216\n",
      "current lr: 0.00025156868398881527\n",
      "epoch 66 step 5 loss: 0.20386613607406617\n",
      "epoch 66 step 10 loss: 0.16906608939170836\n",
      "epoch 66 step 15 loss: 0.18952869176864623\n",
      "epoch 66 step 20 loss: 0.1828567922115326\n",
      "epoch 66 step 25 loss: 0.17917720079421998\n",
      "epoch 66 step 30 loss: 0.18004303872585298\n",
      "epoch 66 step 35 loss: 0.1798969715833664\n",
      "epoch 66 step 40 loss: 0.19159971177577972\n",
      "epoch 66 step 45 loss: 0.18113020360469817\n",
      "epoch 67 step 5 loss: 0.18739029467105867\n",
      "epoch 67 step 10 loss: 0.16795334815979004\n",
      "epoch 67 step 15 loss: 0.1686217427253723\n",
      "epoch 67 step 20 loss: 0.16620802283287048\n",
      "epoch 67 step 25 loss: 0.16556868851184844\n",
      "epoch 67 step 30 loss: 0.18011853396892546\n",
      "epoch 67 step 35 loss: 0.17043103277683258\n",
      "epoch 67 step 40 loss: 0.1877562016248703\n",
      "epoch 67 step 45 loss: 0.18296375274658203\n",
      "current lr: 0.00024653731030903895\n",
      "epoch 68 step 5 loss: 0.1963746130466461\n",
      "epoch 68 step 10 loss: 0.17443897426128388\n",
      "epoch 68 step 15 loss: 0.15422926247119903\n",
      "epoch 68 step 20 loss: 0.17254346907138823\n",
      "epoch 68 step 25 loss: 0.18103122413158418\n",
      "epoch 68 step 30 loss: 0.1664789468050003\n",
      "epoch 68 step 35 loss: 0.19093500673770905\n",
      "epoch 68 step 40 loss: 0.1770939826965332\n",
      "epoch 68 step 45 loss: 0.17256400287151336\n",
      "epoch 69 step 5 loss: 0.20020072758197785\n",
      "epoch 69 step 10 loss: 0.1542941778898239\n",
      "epoch 69 step 15 loss: 0.16443207263946533\n",
      "epoch 69 step 20 loss: 0.17303726971149444\n",
      "epoch 69 step 25 loss: 0.17009200155735016\n",
      "epoch 69 step 30 loss: 0.15931980311870575\n",
      "epoch 69 step 35 loss: 0.16220706105232238\n",
      "epoch 69 step 40 loss: 0.16469507813453674\n",
      "epoch 69 step 45 loss: 0.16653407514095306\n",
      "current lr: 0.00024160656410285818\n",
      "encoder输入: ['又', '想起', '从前']\n",
      "decoder输入: ['<go>', '啊', '记得', '在', '雨', '中', '<eos>']\n",
      "target目标: ['啊', '记得', '在', '雨', '中', '<eos>']\n",
      "预测结果: ['啊', '记得', '在', '雨', '中', '<eos>']\n",
      "attention:\n",
      " tensor([[2.4467e-01, 7.1936e-01, 3.5973e-02],\n",
      "        [2.7240e-02, 9.0465e-01, 6.8107e-02],\n",
      "        [8.1773e-01, 1.6290e-01, 1.9362e-02],\n",
      "        [8.9297e-01, 9.4523e-02, 1.2507e-02],\n",
      "        [9.9788e-01, 2.0928e-03, 2.8294e-05],\n",
      "        [5.8914e-01, 2.6322e-01, 1.4764e-01],\n",
      "        [9.4117e-01, 5.3830e-02, 5.0049e-03]], grad_fn=<SelectBackward0>)\n",
      "epoch 70 step 5 loss: 0.19638540744781494\n",
      "epoch 70 step 10 loss: 0.1612066239118576\n",
      "epoch 70 step 15 loss: 0.16373555064201356\n",
      "epoch 70 step 20 loss: 0.16280320882797242\n",
      "epoch 70 step 25 loss: 0.1708475112915039\n",
      "epoch 70 step 30 loss: 0.16902072429656984\n",
      "epoch 70 step 35 loss: 0.16726305484771728\n",
      "epoch 70 step 40 loss: 0.1783216804265976\n",
      "epoch 70 step 45 loss: 0.1689913421869278\n",
      "epoch 71 step 5 loss: 0.1890729159116745\n",
      "epoch 71 step 10 loss: 0.15670944154262542\n",
      "epoch 71 step 15 loss: 0.15239696204662323\n",
      "epoch 71 step 20 loss: 0.15742058157920838\n",
      "epoch 71 step 25 loss: 0.14844765961170198\n",
      "epoch 71 step 30 loss: 0.16889164745807647\n",
      "epoch 71 step 35 loss: 0.15290177762508392\n",
      "epoch 71 step 40 loss: 0.15420126914978027\n",
      "epoch 71 step 45 loss: 0.17418975234031678\n",
      "current lr: 0.00023677443282080102\n",
      "epoch 72 step 5 loss: 0.18664169907569886\n",
      "epoch 72 step 10 loss: 0.14945598244667052\n",
      "epoch 72 step 15 loss: 0.1642007887363434\n",
      "epoch 72 step 20 loss: 0.16330558955669403\n",
      "epoch 72 step 25 loss: 0.16647758483886718\n",
      "epoch 72 step 30 loss: 0.17013067305088042\n",
      "epoch 72 step 35 loss: 0.1587221086025238\n",
      "epoch 72 step 40 loss: 0.1635683298110962\n",
      "epoch 72 step 45 loss: 0.16311781406402587\n",
      "epoch 73 step 5 loss: 0.18110842406749725\n",
      "epoch 73 step 10 loss: 0.14379957616329192\n",
      "epoch 73 step 15 loss: 0.14951696693897248\n",
      "epoch 73 step 20 loss: 0.1511467695236206\n",
      "epoch 73 step 25 loss: 0.1533502995967865\n",
      "epoch 73 step 30 loss: 0.16033864319324492\n",
      "epoch 73 step 35 loss: 0.15522848963737487\n",
      "epoch 73 step 40 loss: 0.15935406982898712\n",
      "epoch 73 step 45 loss: 0.15926546156406401\n",
      "current lr: 0.000232038944164385\n",
      "epoch 74 step 5 loss: 0.17842247486114501\n",
      "epoch 74 step 10 loss: 0.16245826184749604\n",
      "epoch 74 step 15 loss: 0.15726421773433685\n",
      "epoch 74 step 20 loss: 0.1567627817392349\n",
      "epoch 74 step 25 loss: 0.15803723633289338\n",
      "epoch 74 step 30 loss: 0.16277243793010712\n",
      "epoch 74 step 35 loss: 0.15782107710838317\n",
      "epoch 74 step 40 loss: 0.1421433836221695\n",
      "epoch 74 step 45 loss: 0.15647555887699127\n",
      "encoder输入: ['快快乐乐', '在', '它', '心坎', '里']\n",
      "decoder输入: ['<go>', '嘿', '我', '的', '朋友', '<eos>']\n",
      "target目标: ['嘿', '我', '的', '朋友', '<eos>']\n",
      "预测结果: ['嘿', '我', '的', '朋友', '<eos>']\n",
      "attention:\n",
      " tensor([[0.7955, 0.1117, 0.0229, 0.0588, 0.0112],\n",
      "        [0.1319, 0.0549, 0.0138, 0.2148, 0.5846],\n",
      "        [0.4369, 0.0771, 0.0680, 0.0951, 0.3229],\n",
      "        [0.8602, 0.0419, 0.0401, 0.0127, 0.0451],\n",
      "        [0.0502, 0.0050, 0.0218, 0.2707, 0.6523],\n",
      "        [0.5198, 0.1867, 0.0637, 0.0662, 0.1637]], grad_fn=<SelectBackward0>)\n",
      "epoch 75 step 5 loss: 0.18277240097522734\n",
      "epoch 75 step 10 loss: 0.1302344411611557\n",
      "epoch 75 step 15 loss: 0.14635467231273652\n",
      "epoch 75 step 20 loss: 0.14637880474328996\n",
      "epoch 75 step 25 loss: 0.15558779537677764\n",
      "epoch 75 step 30 loss: 0.14732038080692292\n",
      "epoch 75 step 35 loss: 0.1506513774394989\n",
      "epoch 75 step 40 loss: 0.15026444494724273\n",
      "epoch 75 step 45 loss: 0.15283055007457733\n",
      "current lr: 0.0002273981652810973\n",
      "epoch 76 step 5 loss: 0.17082370519638063\n",
      "epoch 76 step 10 loss: 0.14757250547409057\n",
      "epoch 76 step 15 loss: 0.14618605971336365\n",
      "epoch 76 step 20 loss: 0.1537728190422058\n",
      "epoch 76 step 25 loss: 0.15842621624469758\n",
      "epoch 76 step 30 loss: 0.15366139113903046\n",
      "epoch 76 step 35 loss: 0.15672110319137572\n",
      "epoch 76 step 40 loss: 0.14986717700958252\n",
      "epoch 76 step 45 loss: 0.16004701554775239\n",
      "epoch 77 step 5 loss: 0.17636848986148834\n",
      "epoch 77 step 10 loss: 0.14630254209041596\n",
      "epoch 77 step 15 loss: 0.13893254101276398\n",
      "epoch 77 step 20 loss: 0.13711410164833068\n",
      "epoch 77 step 25 loss: 0.14021656811237335\n",
      "epoch 77 step 30 loss: 0.15092034935951232\n",
      "epoch 77 step 35 loss: 0.1557777464389801\n",
      "epoch 77 step 40 loss: 0.14288096874952316\n",
      "epoch 77 step 45 loss: 0.14484128057956697\n",
      "current lr: 0.00022285020197547535\n",
      "epoch 78 step 5 loss: 0.16701654642820357\n",
      "epoch 78 step 10 loss: 0.14562504440546037\n",
      "epoch 78 step 15 loss: 0.14302299171686172\n",
      "epoch 78 step 20 loss: 0.14894089996814727\n",
      "epoch 78 step 25 loss: 0.1390611633658409\n",
      "epoch 78 step 30 loss: 0.1435356318950653\n",
      "epoch 78 step 35 loss: 0.14983169138431549\n",
      "epoch 78 step 40 loss: 0.14725416898727417\n",
      "epoch 78 step 45 loss: 0.15873305201530458\n",
      "epoch 79 step 5 loss: 0.16229085773229598\n",
      "epoch 79 step 10 loss: 0.13752529323101043\n",
      "epoch 79 step 15 loss: 0.13137508183717728\n",
      "epoch 79 step 20 loss: 0.1458756998181343\n",
      "epoch 79 step 25 loss: 0.14184519052505493\n",
      "epoch 79 step 30 loss: 0.1411379188299179\n",
      "epoch 79 step 35 loss: 0.14757016748189927\n",
      "epoch 79 step 40 loss: 0.14075629711151122\n",
      "epoch 79 step 45 loss: 0.15234228372573852\n",
      "current lr: 0.00021839319793596584\n",
      "encoder输入: ['花儿', '谢', '花儿', '开']\n",
      "decoder输入: ['<go>', '谁', '能', '明白', '<eos>']\n",
      "target目标: ['谁', '能', '明白', '<eos>']\n",
      "预测结果: ['谁', '能', '明白', '<eos>']\n",
      "attention:\n",
      " tensor([[1.5476e-02, 1.2374e-02, 7.4734e-01, 2.2481e-01],\n",
      "        [6.1701e-04, 6.1892e-02, 7.7012e-01, 1.6738e-01],\n",
      "        [7.5853e-02, 1.0038e-01, 2.1235e-01, 6.1142e-01],\n",
      "        [4.6403e-03, 1.3868e-01, 5.5383e-01, 3.0285e-01],\n",
      "        [2.0751e-02, 2.1695e-01, 4.0754e-01, 3.5477e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 80 step 5 loss: 0.15773501247167587\n",
      "epoch 80 step 10 loss: 0.13742891252040862\n",
      "epoch 80 step 15 loss: 0.13341474980115892\n",
      "epoch 80 step 20 loss: 0.14140455722808837\n",
      "epoch 80 step 25 loss: 0.13756141662597657\n",
      "epoch 80 step 30 loss: 0.14790205359458924\n",
      "epoch 80 step 35 loss: 0.14156875014305115\n",
      "epoch 80 step 40 loss: 0.15041189193725585\n",
      "epoch 80 step 45 loss: 0.15518406629562378\n",
      "epoch 81 step 5 loss: 0.16398610174655914\n",
      "epoch 81 step 10 loss: 0.14330456256866456\n",
      "epoch 81 step 15 loss: 0.13672803938388825\n",
      "epoch 81 step 20 loss: 0.12595497965812683\n",
      "epoch 81 step 25 loss: 0.13642201125621795\n",
      "epoch 81 step 30 loss: 0.1375224173069\n",
      "epoch 81 step 35 loss: 0.13656116276979446\n",
      "epoch 81 step 40 loss: 0.15023386478424072\n",
      "epoch 81 step 45 loss: 0.1454830527305603\n",
      "current lr: 0.00021402533397724653\n",
      "epoch 82 step 5 loss: 0.14937547594308853\n",
      "epoch 82 step 10 loss: 0.1454043447971344\n",
      "epoch 82 step 15 loss: 0.13211406171321868\n",
      "epoch 82 step 20 loss: 0.14246362298727036\n",
      "epoch 82 step 25 loss: 0.13716478645801544\n",
      "epoch 82 step 30 loss: 0.14373052716255189\n",
      "epoch 82 step 35 loss: 0.13960750102996827\n",
      "epoch 82 step 40 loss: 0.14139885753393172\n",
      "epoch 82 step 45 loss: 0.13756429851055146\n",
      "epoch 83 step 5 loss: 0.15885994583368301\n",
      "epoch 83 step 10 loss: 0.12866823226213456\n",
      "epoch 83 step 15 loss: 0.13731259405612944\n",
      "epoch 83 step 20 loss: 0.13584360778331755\n",
      "epoch 83 step 25 loss: 0.1292734518647194\n",
      "epoch 83 step 30 loss: 0.12710786014795303\n",
      "epoch 83 step 35 loss: 0.1420997202396393\n",
      "epoch 83 step 40 loss: 0.12613216787576675\n",
      "epoch 83 step 45 loss: 0.1323872148990631\n",
      "current lr: 0.0002097448272977016\n",
      "epoch 84 step 5 loss: 0.15447389781475068\n",
      "epoch 84 step 10 loss: 0.12283376902341843\n",
      "epoch 84 step 15 loss: 0.12936720252037048\n",
      "epoch 84 step 20 loss: 0.13446485698223115\n",
      "epoch 84 step 25 loss: 0.13148857057094573\n",
      "epoch 84 step 30 loss: 0.14301969408988952\n",
      "epoch 84 step 35 loss: 0.13921226263046266\n",
      "epoch 84 step 40 loss: 0.13432852774858475\n",
      "epoch 84 step 45 loss: 0.1444126397371292\n",
      "encoder输入: ['时光', '像', '流水', '已经', '五年']\n",
      "decoder输入: ['<go>', '为什么', '我', '还是', '忘不了', '<eos>']\n",
      "target目标: ['为什么', '我', '还是', '忘不了', '<eos>']\n",
      "预测结果: ['为什么', '我', '还是', '忘不了', '<eos>']\n",
      "attention:\n",
      " tensor([[0.6325, 0.2171, 0.0369, 0.0220, 0.0915],\n",
      "        [0.4384, 0.0928, 0.0273, 0.0388, 0.4027],\n",
      "        [0.0060, 0.3317, 0.1032, 0.4669, 0.0923],\n",
      "        [0.5316, 0.1421, 0.2435, 0.0336, 0.0493],\n",
      "        [0.0247, 0.1686, 0.4185, 0.0702, 0.3179],\n",
      "        [0.3495, 0.3319, 0.2099, 0.0303, 0.0784]], grad_fn=<SelectBackward0>)\n",
      "epoch 85 step 5 loss: 0.15053900331258774\n",
      "epoch 85 step 10 loss: 0.12729141265153884\n",
      "epoch 85 step 15 loss: 0.12167880982160569\n",
      "epoch 85 step 20 loss: 0.12434997856616974\n",
      "epoch 85 step 25 loss: 0.14264854192733764\n",
      "epoch 85 step 30 loss: 0.1242796778678894\n",
      "epoch 85 step 35 loss: 0.1365904316306114\n",
      "epoch 85 step 40 loss: 0.12504028528928757\n",
      "epoch 85 step 45 loss: 0.1293753504753113\n",
      "current lr: 0.00020554993075174756\n",
      "epoch 86 step 5 loss: 0.15469153374433517\n",
      "epoch 86 step 10 loss: 0.12655385285615922\n",
      "epoch 86 step 15 loss: 0.12302051931619644\n",
      "epoch 86 step 20 loss: 0.12732724994421005\n",
      "epoch 86 step 25 loss: 0.1348456025123596\n",
      "epoch 86 step 30 loss: 0.1275573790073395\n",
      "epoch 86 step 35 loss: 0.12822741270065308\n",
      "epoch 86 step 40 loss: 0.13558559715747834\n",
      "epoch 86 step 45 loss: 0.13186134546995162\n",
      "epoch 87 step 5 loss: 0.15187952816486358\n",
      "epoch 87 step 10 loss: 0.12376692146062851\n",
      "epoch 87 step 15 loss: 0.12829551696777344\n",
      "epoch 87 step 20 loss: 0.12321179807186126\n",
      "epoch 87 step 25 loss: 0.12041703015565872\n",
      "epoch 87 step 30 loss: 0.1286718115210533\n",
      "epoch 87 step 35 loss: 0.13312558233737945\n",
      "epoch 87 step 40 loss: 0.12668522745370864\n",
      "epoch 87 step 45 loss: 0.12972656190395354\n",
      "current lr: 0.00020143893213671262\n",
      "epoch 88 step 5 loss: 0.14984868019819259\n",
      "epoch 88 step 10 loss: 0.12994292825460435\n",
      "epoch 88 step 15 loss: 0.11673212498426437\n",
      "epoch 88 step 20 loss: 0.1214582234621048\n",
      "epoch 88 step 25 loss: 0.12629984468221664\n",
      "epoch 88 step 30 loss: 0.12843095064163207\n",
      "epoch 88 step 35 loss: 0.13080625385046005\n",
      "epoch 88 step 40 loss: 0.1332330286502838\n",
      "epoch 88 step 45 loss: 0.13133618831634522\n",
      "epoch 89 step 5 loss: 0.13689869791269302\n",
      "epoch 89 step 10 loss: 0.12678212374448777\n",
      "epoch 89 step 15 loss: 0.12457107156515121\n",
      "epoch 89 step 20 loss: 0.12558529078960418\n",
      "epoch 89 step 25 loss: 0.11907455772161483\n",
      "epoch 89 step 30 loss: 0.12499084323644638\n",
      "epoch 89 step 35 loss: 0.13328368067741395\n",
      "epoch 89 step 40 loss: 0.1187378466129303\n",
      "epoch 89 step 45 loss: 0.12379647493362426\n",
      "current lr: 0.00019741015349397837\n",
      "encoder输入: ['我', '想', '把', '心事', '告诉', '你', '知道']\n",
      "decoder输入: ['<go>', '因为', '你', '对', '我', '关心', '对', '我', '好', '<eos>']\n",
      "target目标: ['因为', '你', '对', '我', '关心', '对', '我', '好', '<eos>']\n",
      "预测结果: ['因为', '你', '对', '我', '关心', '对', '我', '好', '<eos>']\n",
      "attention:\n",
      " tensor([[1.3787e-01, 2.7244e-01, 2.1842e-01, 1.9142e-01, 1.1284e-01, 4.1952e-02,\n",
      "         2.5061e-02],\n",
      "        [5.5355e-02, 1.6894e-01, 1.4054e-01, 5.9457e-02, 1.4138e-01, 2.7380e-01,\n",
      "         1.6052e-01],\n",
      "        [1.1481e-03, 1.4130e-03, 2.0497e-03, 1.5650e-02, 2.3280e-01, 1.1678e-01,\n",
      "         6.3016e-01],\n",
      "        [6.9872e-01, 3.9030e-02, 8.5534e-02, 5.8531e-02, 2.2424e-02, 2.2349e-02,\n",
      "         7.3409e-02],\n",
      "        [2.2159e-01, 5.4274e-02, 2.8653e-02, 7.6414e-02, 7.3527e-02, 9.0838e-02,\n",
      "         4.5470e-01],\n",
      "        [8.7588e-03, 1.1628e-04, 5.8111e-04, 6.5383e-03, 2.9860e-01, 2.1018e-01,\n",
      "         4.7523e-01],\n",
      "        [1.4195e-01, 1.0869e-02, 6.9637e-03, 1.8595e-02, 1.5971e-01, 1.7629e-01,\n",
      "         4.8563e-01],\n",
      "        [3.6149e-03, 5.7782e-04, 9.3048e-05, 1.4067e-03, 1.6550e-02, 2.1321e-01,\n",
      "         7.6455e-01],\n",
      "        [2.5037e-02, 1.8181e-03, 1.3047e-03, 4.1652e-02, 7.6645e-01, 6.1358e-02,\n",
      "         1.0238e-01],\n",
      "        [8.1088e-03, 1.6337e-04, 1.2085e-04, 4.2574e-02, 4.7606e-01, 2.1656e-01,\n",
      "         2.5641e-01]], grad_fn=<SelectBackward0>)\n",
      "epoch 90 step 5 loss: 0.14777036160230636\n",
      "epoch 90 step 10 loss: 0.1324530854821205\n",
      "epoch 90 step 15 loss: 0.12152336984872818\n",
      "epoch 90 step 20 loss: 0.12090718001127243\n",
      "epoch 90 step 25 loss: 0.13054841309785842\n",
      "epoch 90 step 30 loss: 0.13003628551959992\n",
      "epoch 90 step 35 loss: 0.12799584716558457\n",
      "epoch 90 step 40 loss: 0.12441960871219634\n",
      "epoch 90 step 45 loss: 0.12359769493341446\n",
      "epoch 91 step 5 loss: 0.14037622213363649\n",
      "epoch 91 step 10 loss: 0.111834716796875\n",
      "epoch 91 step 15 loss: 0.11920859068632125\n",
      "epoch 91 step 20 loss: 0.12109716832637787\n",
      "epoch 91 step 25 loss: 0.12693543434143068\n",
      "epoch 91 step 30 loss: 0.1200180321931839\n",
      "epoch 91 step 35 loss: 0.12364057302474976\n",
      "epoch 91 step 40 loss: 0.11642232835292816\n",
      "epoch 91 step 45 loss: 0.12215596884489059\n",
      "current lr: 0.0001934619504240988\n",
      "epoch 92 step 5 loss: 0.13049545735120774\n",
      "epoch 92 step 10 loss: 0.11559523940086365\n",
      "epoch 92 step 15 loss: 0.135430771112442\n",
      "epoch 92 step 20 loss: 0.12049154937267303\n",
      "epoch 92 step 25 loss: 0.12961724102497102\n",
      "epoch 92 step 30 loss: 0.12163654267787934\n",
      "epoch 92 step 35 loss: 0.12833568304777146\n",
      "epoch 92 step 40 loss: 0.12306974679231644\n",
      "epoch 92 step 45 loss: 0.12386905699968338\n",
      "epoch 93 step 5 loss: 0.13700059354305266\n",
      "epoch 93 step 10 loss: 0.11583170145750046\n",
      "epoch 93 step 15 loss: 0.12429503798484802\n",
      "epoch 93 step 20 loss: 0.12087241560220718\n",
      "epoch 93 step 25 loss: 0.11461943686008454\n",
      "epoch 93 step 30 loss: 0.11590981930494308\n",
      "epoch 93 step 35 loss: 0.11988978683948517\n",
      "epoch 93 step 40 loss: 0.1218723088502884\n",
      "epoch 93 step 45 loss: 0.11684801280498505\n",
      "current lr: 0.0001895927114156168\n",
      "epoch 94 step 5 loss: 0.14290019124746323\n",
      "epoch 94 step 10 loss: 0.12134675085544586\n",
      "epoch 94 step 15 loss: 0.11526601314544678\n",
      "epoch 94 step 20 loss: 0.11318030506372452\n",
      "epoch 94 step 25 loss: 0.11941236853599549\n",
      "epoch 94 step 30 loss: 0.11416741758584976\n",
      "epoch 94 step 35 loss: 0.12509390264749526\n",
      "epoch 94 step 40 loss: 0.12006071954965591\n",
      "epoch 94 step 45 loss: 0.12181296050548554\n",
      "encoder输入: ['也', '有', '那', '眼睛']\n",
      "decoder输入: ['<go>', '眼睛', '不会', '眨', '<eos>']\n",
      "target目标: ['眼睛', '不会', '眨', '<eos>']\n",
      "预测结果: ['眼睛', '不会', '眨', '<eos>']\n",
      "attention:\n",
      " tensor([[1.1594e-01, 1.7347e-01, 6.4049e-01, 7.0103e-02],\n",
      "        [6.4799e-01, 3.1866e-01, 4.7199e-03, 2.8639e-02],\n",
      "        [9.0776e-01, 1.2125e-02, 3.6029e-02, 4.4086e-02],\n",
      "        [1.4405e-01, 7.8236e-04, 4.2096e-02, 8.1308e-01],\n",
      "        [5.3028e-02, 3.5977e-03, 1.5272e-02, 9.2810e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 95 step 5 loss: 0.1381154403090477\n",
      "epoch 95 step 10 loss: 0.10894813388586044\n",
      "epoch 95 step 15 loss: 0.11198024451732635\n",
      "epoch 95 step 20 loss: 0.11019389480352401\n",
      "epoch 95 step 25 loss: 0.11390561163425446\n",
      "epoch 95 step 30 loss: 0.12204915136098862\n",
      "epoch 95 step 35 loss: 0.11476168781518936\n",
      "epoch 95 step 40 loss: 0.11333629637956619\n",
      "epoch 95 step 45 loss: 0.11226883232593536\n",
      "current lr: 0.00018580085718730447\n",
      "epoch 96 step 5 loss: 0.13590820878744125\n",
      "epoch 96 step 10 loss: 0.10940634906291961\n",
      "epoch 96 step 15 loss: 0.11685173362493514\n",
      "epoch 96 step 20 loss: 0.10742570906877517\n",
      "epoch 96 step 25 loss: 0.11774450093507767\n",
      "epoch 96 step 30 loss: 0.11200689673423767\n",
      "epoch 96 step 35 loss: 0.11507219821214676\n",
      "epoch 96 step 40 loss: 0.12287980914115906\n",
      "epoch 96 step 45 loss: 0.12460143715143204\n",
      "epoch 97 step 5 loss: 0.13594311475753784\n",
      "epoch 97 step 10 loss: 0.11130624264478683\n",
      "epoch 97 step 15 loss: 0.11646801382303237\n",
      "epoch 97 step 20 loss: 0.11458536386489868\n",
      "epoch 97 step 25 loss: 0.10966358631849289\n",
      "epoch 97 step 30 loss: 0.1153442233800888\n",
      "epoch 97 step 35 loss: 0.11337817311286927\n",
      "epoch 97 step 40 loss: 0.11271149963140488\n",
      "epoch 97 step 45 loss: 0.10577085167169571\n",
      "current lr: 0.00018208484004355837\n",
      "epoch 98 step 5 loss: 0.12788396328687668\n",
      "epoch 98 step 10 loss: 0.11202104091644287\n",
      "epoch 98 step 15 loss: 0.12165593206882477\n",
      "epoch 98 step 20 loss: 0.11867623180150985\n",
      "epoch 98 step 25 loss: 0.11442559510469437\n",
      "epoch 98 step 30 loss: 0.11101154536008835\n",
      "epoch 98 step 35 loss: 0.11209677457809449\n",
      "epoch 98 step 40 loss: 0.11287441998720169\n",
      "epoch 98 step 45 loss: 0.11663166433572769\n",
      "epoch 99 step 5 loss: 0.12634669095277787\n",
      "epoch 99 step 10 loss: 0.11407039314508438\n",
      "epoch 99 step 15 loss: 0.11488264203071594\n",
      "epoch 99 step 20 loss: 0.11489206999540329\n",
      "epoch 99 step 25 loss: 0.11758501231670379\n",
      "epoch 99 step 30 loss: 0.1075716495513916\n",
      "epoch 99 step 35 loss: 0.10419904440641403\n",
      "epoch 99 step 40 loss: 0.10619684606790543\n",
      "epoch 99 step 45 loss: 0.11141947209835053\n",
      "current lr: 0.0001784431432426872\n",
      "encoder输入: ['恭祝', '大家', '万年', '红']\n",
      "decoder输入: ['<go>', '不再', '回想', '旧时', '梦', '<eos>']\n",
      "target目标: ['不再', '回想', '旧时', '梦', '<eos>']\n",
      "预测结果: ['不再', '回想', '旧时', '梦', '<eos>']\n",
      "attention:\n",
      " tensor([[2.7418e-04, 3.2801e-02, 4.1021e-01, 5.5671e-01],\n",
      "        [2.9329e-05, 7.2834e-03, 2.7168e-01, 7.2101e-01],\n",
      "        [1.5482e-03, 1.4291e-01, 2.2561e-01, 6.2993e-01],\n",
      "        [1.4806e-03, 2.7908e-03, 5.5188e-01, 4.4384e-01],\n",
      "        [4.8773e-02, 2.2327e-01, 3.9278e-02, 6.8867e-01],\n",
      "        [3.5961e-01, 4.4411e-01, 2.5744e-02, 1.7054e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "epoch 100 step 5 loss: 0.12631769329309464\n",
      "epoch 100 step 10 loss: 0.11035191267728806\n",
      "epoch 100 step 15 loss: 0.11500249654054642\n",
      "epoch 100 step 20 loss: 0.11152291446924209\n",
      "epoch 100 step 25 loss: 0.1021238312125206\n",
      "epoch 100 step 30 loss: 0.11166033148765564\n",
      "epoch 100 step 35 loss: 0.1067760095000267\n",
      "epoch 100 step 40 loss: 0.11641341596841812\n",
      "epoch 100 step 45 loss: 0.11458433866500854\n"
     ]
    }
   ],
   "source": [
    "%run finetune.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
